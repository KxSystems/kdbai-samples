{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cb212650-86b7-4298-8bbd-c20a5227fbf0",
      "metadata": {
        "id": "cb212650-86b7-4298-8bbd-c20a5227fbf0"
      },
      "source": [
        "# Advanced RAG with temporal filters using LlamaIndex and KDB.AI vector store\n",
        "\n",
        "##### Note: This example requires a KDB.AI endpoint and API key. Sign up for a free [KDB.AI account](https://kdb.ai/get-started).\n",
        "\n",
        "> [KDB.AI](https://kdb.ai/) is a powerful knowledge-based vector database and search engine that allows you to build scalable, reliable AI applications, using real-time data, by providing advanced search, recommendation and personalization.\n",
        "\n",
        "This example demonstrates how to use KDB.AI to run semantic search, summarization and analysis of financial regulations around some specific moment in time.\n",
        "\n",
        "To access your end point and API keys, sign up to KDB.AI here.\n",
        "\n",
        "To set up your development environment, follow the instructions on the KDB.AI pre-requisites page.\n",
        "\n",
        "The following examples demonstrate some of the ways you can interact with KDB.AI through LlamaIndex."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32f36ddd-aa4d-4284-a236-be3028758ae2",
      "metadata": {
        "id": "32f36ddd-aa4d-4284-a236-be3028758ae2"
      },
      "source": [
        "## Install dependencies with Pip\n",
        "\n",
        "In order to successfully run this sample, note the following steps depending on where you are running this notebook:\n",
        "\n",
        "-***Run Locally / Private Environment:*** The [Setup](https://github.com/KxSystems/kdbai-samples/blob/main/README.md#setup) steps in the repository's `README.md` will guide you on prerequisites and how to run this with Jupyter.\n",
        "\n",
        "\n",
        "-***Colab / Hosted Environment:*** Open this notebook in Colab and run through the cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2QITjsy5Jois",
      "metadata": {
        "id": "2QITjsy5Jois"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index llama-index-embeddings-huggingface llama-index-llms-openai llama-index-readers-file llama-index-vector-stores-kdbai\n",
        "!pip install kdbai_client pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68ba14b7-1208-4494-93ec-ce1930b7bf5b",
      "metadata": {
        "id": "68ba14b7-1208-4494-93ec-ce1930b7bf5b"
      },
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "f4ca21f7-819c-4abb-8479-e7c6f3175f34",
      "metadata": {
        "id": "f4ca21f7-819c-4abb-8479-e7c6f3175f34"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "import re\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import urllib\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from llama_index.core import (\n",
        "    Settings,\n",
        "    SimpleDirectoryReader,\n",
        "    ServiceContext,\n",
        "    StorageContext,\n",
        "    VectorStoreIndex,\n",
        ")\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.vector_stores.kdbai import KDBAIVectorStore\n",
        "\n",
        "import kdbai_client as kdbai\n",
        "\n",
        "OUTDIR = \"pdf\"\n",
        "RESET = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ef2f90f",
      "metadata": {
        "id": "9ef2f90f"
      },
      "source": [
        "#### Set OpenAI API key and choose the LLM and Embedding model to use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "17e19f9f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17e19f9f",
        "outputId": "a1b78aac-017a-4f74-8aa7-47c4dbd65523"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API key: ··········\n"
          ]
        }
      ],
      "source": [
        "LLM = 'gpt-3.5-turbo'\n",
        "# LLM = \"gpt-4-turbo-preview\"  # Expensive !!!\n",
        "\n",
        "EMBEDDING = \"sentence-transformers/all-mpnet-base-v2\"   # Free but takes significant time to generate embeddings (~25 minutes for this notebook)\n",
        "#EMBEDDING = \"text-embedding-3-large\"  # has cost but generates embeddings much faster (~1 minute for this notebook)\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"OpenAI API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ca073f5-3d84-4b0e-8684-1396c1311fb8",
      "metadata": {
        "id": "2ca073f5-3d84-4b0e-8684-1396c1311fb8"
      },
      "source": [
        "## Create KDB.AI session and table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "edf7d774",
      "metadata": {
        "id": "edf7d774"
      },
      "outputs": [],
      "source": [
        "# vector DB imports\n",
        "import os\n",
        "from getpass import getpass\n",
        "import kdbai_client as kdbai\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "816fa95c",
      "metadata": {
        "id": "816fa95c"
      },
      "source": [
        "##### Option 1. KDB.AI Cloud\n",
        "\n",
        "To use KDB.AI Cloud, you will need two session details - a URL endpoint and an API key.\n",
        "To get these you can sign up for free [here](https://trykdb.kx.com/kdbai/signup).\n",
        "\n",
        "You can connect to a KDB.AI Cloud session using `kdbai.Session` and passing the session URL endpoint and API key details from your KDB.AI Cloud portal.\n",
        "\n",
        "If the environment variables `KDBAI_ENDPOINTS` and `KDBAI_API_KEY` exist on your system containing your KDB.AI Cloud portal details, these variables will automatically be used to connect.\n",
        "If these do not exist, it will prompt you to enter your KDB.AI Cloud portal session URL endpoint and API key details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "3991d719",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3991d719",
        "outputId": "a272a78f-e8eb-4af3-e39e-bf2ae7a956e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KDB.AI endpoint: your_kdbai_endpoint\n",
            "KDB.AI API key: ··········\n"
          ]
        }
      ],
      "source": [
        "#Set up KDB.AI endpoing and API key\n",
        "KDBAI_ENDPOINT = (\n",
        "    os.environ[\"KDBAI_ENDPOINT\"]\n",
        "    if \"KDBAI_ENDPOINT\" in os.environ\n",
        "    else input(\"KDB.AI endpoint: \")\n",
        ")\n",
        "KDBAI_API_KEY = (\n",
        "    os.environ[\"KDBAI_API_KEY\"]\n",
        "    if \"KDBAI_API_KEY\" in os.environ\n",
        "    else getpass(\"KDB.AI API key: \")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "6e621244",
      "metadata": {
        "id": "6e621244"
      },
      "outputs": [],
      "source": [
        "#connect to KDB.AI\n",
        "session = kdbai.Session(api_key=KDBAI_API_KEY, endpoint=KDBAI_ENDPOINT)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf750140",
      "metadata": {
        "id": "bf750140"
      },
      "source": [
        "##### Option 2. KDB.AI Server\n",
        "\n",
        "To use KDB.AI Server, you will need download and run your own container.\n",
        "To do this, you will first need to sign up for free [here](https://trykdb.kx.com/kdbaiserver/signup/).\n",
        "\n",
        "You will receive an email with the required license file and bearer token needed to download your instance.\n",
        "Follow instructions in the signup email to get your session up and running.\n",
        "\n",
        "Once the [setup steps](https://code.kx.com/kdbai/gettingStarted/kdb-ai-server-setup.html) are complete you can then connect to your KDB.AI Server session using `kdbai.Session` and passing your local endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77e9b64c",
      "metadata": {
        "id": "77e9b64c"
      },
      "outputs": [],
      "source": [
        "session = kdbai.Session()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d392b5e",
      "metadata": {
        "id": "6d392b5e"
      },
      "source": [
        "### Create the schema for your KDB.AI table\n",
        "\n",
        "***!!! Note:*** The 'dims' parameter in the embedding column must reflect the output dimensions of the embedding model you choose.\n",
        "\n",
        "- Hugging Face 'sentence-transformers/all-mpnet-base-v2' outputs 768 dimensions\n",
        "\n",
        "- OpenAI 'text-embedding-3-large' outputs 3072 dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "9104c851",
      "metadata": {
        "id": "9104c851"
      },
      "outputs": [],
      "source": [
        "\n",
        "schema = dict(\n",
        "    columns=[\n",
        "        dict(name=\"document_id\", pytype=\"bytes\"),\n",
        "        dict(name=\"text\", pytype=\"bytes\"),\n",
        "        dict(\n",
        "            name=\"embedding\",\n",
        "            vectorIndex=dict(type=\"flat\", metric=\"L2\", dims=768),\n",
        "        ),\n",
        "        dict(name=\"title\", pytype=\"bytes\"),\n",
        "        dict(name=\"publication_date\", pytype=\"datetime64[ns]\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "df598cbd",
      "metadata": {
        "id": "df598cbd"
      },
      "outputs": [],
      "source": [
        "KDBAI_TABLE_NAME = \"reports\"\n",
        "\n",
        "# First ensure the table does not already exist\n",
        "if KDBAI_TABLE_NAME in session.list():\n",
        "    session.table(KDBAI_TABLE_NAME).drop()\n",
        "\n",
        "#Create the table\n",
        "table = session.create_table(KDBAI_TABLE_NAME, schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a208460c-2c87-4a3f-9926-65d6dcc4b45d",
      "metadata": {
        "id": "a208460c-2c87-4a3f-9926-65d6dcc4b45d"
      },
      "source": [
        "## Financial reports urls and metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "6143a9ec-7d48-4f61-bb86-a1de427a0279",
      "metadata": {
        "id": "6143a9ec-7d48-4f61-bb86-a1de427a0279"
      },
      "outputs": [],
      "source": [
        "INPUT_URLS = [\n",
        "    \"https://www.govinfo.gov/content/pkg/PLAW-106publ102/pdf/PLAW-106publ102.pdf\",\n",
        "    \"https://www.govinfo.gov/content/pkg/PLAW-111publ203/pdf/PLAW-111publ203.pdf\",\n",
        "]\n",
        "\n",
        "METADATA = {\n",
        "    \"pdf/PLAW-106publ102.pdf\": {\n",
        "        \"title\": \"GRAMM–LEACH–BLILEY ACT, 1999\",\n",
        "        \"publication_date\": pd.to_datetime(\"1999-11-12\"),\n",
        "    },\n",
        "    \"pdf/PLAW-111publ203.pdf\": {\n",
        "        \"title\": \"DODD-FRANK WALL STREET REFORM AND CONSUMER PROTECTION ACT, 2010\",\n",
        "        \"publication_date\": pd.to_datetime(\"2010-07-21\"),\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1e6c6c5-f151-4c01-a9a1-ab1d540402eb",
      "metadata": {
        "id": "e1e6c6c5-f151-4c01-a9a1-ab1d540402eb"
      },
      "source": [
        "## Download PDF files locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "3ee36757-b0b7-4478-a71a-601220048a05",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ee36757-b0b7-4478-a71a-601220048a05",
        "outputId": "8120af31-d9cc-4b04-e913-1a202169800e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.govinfo.gov/content/pkg/PLAW-106publ102/pdf/PLAW-106publ102.pdf...\n",
            "Downloading https://www.govinfo.gov/content/pkg/PLAW-111publ203/pdf/PLAW-111publ203.pdf...\n",
            "CPU times: user 39.2 ms, sys: 11.8 ms, total: 51.1 ms\n",
            "Wall time: 823 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "CHUNK_SIZE = 512 * 1024\n",
        "\n",
        "\n",
        "def download_file(url):\n",
        "    print(\"Downloading %s...\" % url)\n",
        "    out = os.path.join(OUTDIR, os.path.basename(url))\n",
        "    try:\n",
        "        response = urllib.request.urlopen(url)\n",
        "    except urllib.error.URLError as e:\n",
        "        logging.exception(\"Failed to download %s !\" % url)\n",
        "    else:\n",
        "        with open(out, \"wb\") as f:\n",
        "            while True:\n",
        "                chunk = response.read(CHUNK_SIZE)\n",
        "                if chunk:\n",
        "                    f.write(chunk)\n",
        "                else:\n",
        "                    break\n",
        "    return out\n",
        "\n",
        "\n",
        "if RESET:\n",
        "    if os.path.exists(OUTDIR):\n",
        "        shutil.rmtree(OUTDIR)\n",
        "    os.mkdir(OUTDIR)\n",
        "\n",
        "    local_files = [download_file(x) for x in INPUT_URLS]\n",
        "    local_files[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10d52ad8-b9bd-459e-9ce4-c370982a149f",
      "metadata": {
        "id": "10d52ad8-b9bd-459e-9ce4-c370982a149f"
      },
      "source": [
        "## Load local PDF files with LlamaIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "9714258b-f58a-4964-9d3f-0298a98b87e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9714258b-f58a-4964-9d3f-0298a98b87e0",
        "outputId": "2d66ee40-376d-4aaf-e2fa-75cafc4eda2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 12.6 s, sys: 61.5 ms, total: 12.7 s\n",
            "Wall time: 12.9 s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "994"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "def get_metadata(filepath):\n",
        "    return METADATA[filepath]\n",
        "\n",
        "\n",
        "documents = SimpleDirectoryReader(\n",
        "    input_files=local_files,\n",
        "    file_metadata=get_metadata,\n",
        ")\n",
        "\n",
        "docs = documents.load_data()\n",
        "len(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f3ba953-4034-4421-acf0-dbac33dfed67",
      "metadata": {
        "id": "2f3ba953-4034-4421-acf0-dbac33dfed67"
      },
      "source": [
        "## Setup LlamaIndex RAG pipeline using KDB.AI vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "4ed27c4b-a979-4d4f-9f17-7c6bd9844d9a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ed27c4b-a979-4d4f-9f17-7c6bd9844d9a",
        "outputId": "1361ac58-b4c2-4654-94e9-2375397c5e00"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<timed exec>:8: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 23.5 s, sys: 394 ms, total: 23.9 s\n",
            "Wall time: 48.9 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "### Choose the embedding method\n",
        "embed_model = HuggingFaceEmbedding(model_name=EMBEDDING) #Free but takes ~25 minutes when running in Colab\n",
        "#embed_model = OpenAIEmbedding(model=EMBEDDING) #Has cost but takes ~1 minute when running in Colab\n",
        "\n",
        "\n",
        "llm = OpenAI(temperature=0, model=LLM)\n",
        "vector_store = KDBAIVectorStore(table)\n",
        "service_context = ServiceContext.from_defaults(\n",
        "    embed_model=embed_model, llm=llm\n",
        ")\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    docs,\n",
        "    service_context=service_context,\n",
        "    storage_context=storage_context,\n",
        "    transformations=[SentenceSplitter(chunk_size=2048, chunk_overlap=0)],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a0ca610-4038-41c2-a1f9-5c8af9d764ce",
      "metadata": {
        "id": "0a0ca610-4038-41c2-a1f9-5c8af9d764ce"
      },
      "source": [
        "## Setup the LlamaIndex Query Engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "f7d29b82-c1b8-4880-869e-dabc8bdedaa4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7d29b82-c1b8-4880-869e-dabc8bdedaa4",
        "outputId": "d752d1a2-3da2-461e-b5f1-3cde9bfa885a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 60.8 ms, sys: 5.83 ms, total: 66.6 ms\n",
            "Wall time: 67.6 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Using gpt-3.5-turbo, the 16k tokens context size can only fit around 15 pages of document.\n",
        "# Using gpt-4-turbo-preview, the 128k tokens context size can take 100 pages.\n",
        "K = 15\n",
        "\n",
        "query_engine = index.as_query_engine(\n",
        "    similarity_top_k=K,\n",
        "    filter=[(\"<\", \"publication_date\", \"2008-09-15\")],\n",
        "    sort_by=\"publication_date\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e442d238-03cf-41d1-9ea4-9d435bb30278",
      "metadata": {
        "id": "e442d238-03cf-41d1-9ea4-9d435bb30278"
      },
      "source": [
        "## Before the 2008 crisis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "1d791e0e-67b0-4179-a4c4-a1f5fd6d765b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d791e0e-67b0-4179-a4c4-a1f5fd6d765b",
        "outputId": "21d75b76-4faf-44c0-ab4f-ce656d1e4ad6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The main financial regulation in the US before the 2008 financial crisis was the Dodd-Frank Wall Street Reform and Consumer Protection Act of 2010.\n",
            "CPU times: user 410 ms, sys: 8.35 ms, total: 418 ms\n",
            "Wall time: 6.66 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "result = query_engine.query(\n",
        "    \"\"\"\n",
        "What was the main financial regulation in the US before the 2008 financial crisis ?\n",
        "\"\"\"\n",
        ")\n",
        "print(result.response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "ee5c52ed-fc1a-4f4f-8cc4-efbb4e5a067f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee5c52ed-fc1a-4f4f-8cc4-efbb4e5a067f",
        "outputId": "8182be5f-c40e-4dac-8ae9-d282c0958e1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Gramm-Leach-Bliley Act of 1999 sought to enhance competition in the financial services industry by allowing connections between banks, securities firms, and insurance companies. Its effectiveness is evident in setting standards for these connections and streamlining supervision of bank holding companies. Yet, potential drawbacks could stem from challenges related to resource concentration, conflicts of interest, and unsound banking practices. While the Act addressed some concerns, it may not have comprehensively addressed all the factors contributing to the 2008 financial crisis, such as inadequate oversight of specific financial products and institutions pivotal in the crisis.\n",
            "CPU times: user 355 ms, sys: 16.5 ms, total: 371 ms\n",
            "Wall time: 15.2 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "result = query_engine.query(\n",
        "    \"\"\"\n",
        "Is the Gramm-Leach-Bliley Act of 1999 enough to prevent the 2008 crisis. Search the document and explain its strenghts and weaknesses to regulate the US stock market.\n",
        "\"\"\"\n",
        ")\n",
        "print(result.response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c6b52ee-2086-4e50-8e88-6ad6920cc8bc",
      "metadata": {
        "id": "5c6b52ee-2086-4e50-8e88-6ad6920cc8bc"
      },
      "source": [
        "## After the 2008 crisis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "37753e54-959b-43a3-b596-7cef0e94d4ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37753e54-959b-43a3-b596-7cef0e94d4ba",
        "outputId": "c9e00dba-cbd0-4c42-cf01-bd1703f272dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 471 µs, sys: 32 µs, total: 503 µs\n",
            "Wall time: 514 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Using gpt-3.5-turbo, the 16k tokens context size can only fit around 15 pages of document.\n",
        "# Using gpt-4-turbo-preview, the 128k tokens context size can take 100 pages.\n",
        "K = 15\n",
        "\n",
        "query_engine = index.as_query_engine(\n",
        "    similarity_top_k=K,\n",
        "    filter=[(\">=\", \"publication_date\", \"2008-09-15\")],\n",
        "    sort_by=\"publication_date\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "445ebab3-4431-4f75-a07d-c998c98b7cfd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "445ebab3-4431-4f75-a07d-c998c98b7cfd",
        "outputId": "60bb26ba-6459-4c15-8aa6-6ee787d2ebee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On the 15th of September 2008, Lehman Brothers filed for bankruptcy, which marked one of the largest bankruptcies in U.S. history and had significant repercussions on the global financial system.\n",
            "CPU times: user 363 ms, sys: 11.9 ms, total: 375 ms\n",
            "Wall time: 7.56 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "result = query_engine.query(\n",
        "    \"\"\"\n",
        "What happened on the 15th of September 2008 ? Answer from your own knowledge only.\n",
        "\"\"\"\n",
        ")\n",
        "print(result.response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "a05c539e-85c1-4592-808b-07d68e68e032",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a05c539e-85c1-4592-808b-07d68e68e032",
        "outputId": "9dda3be1-3d10-4847-fab6-09d4170a3756"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Dodd-Frank Wall Street Reform and Consumer Protection Act of 2010 was enacted as a new US financial regulation after the 2008 crisis to increase market regulation and improve consumer sentiment.\n",
            "CPU times: user 341 ms, sys: 9.8 ms, total: 351 ms\n",
            "Wall time: 9.44 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "result = query_engine.query(\n",
        "    \"\"\"\n",
        "What was the new US financial regulation enacted after the 2008 crisis to increase the market regulation and to improve consumer sentiment ?\n",
        "\"\"\"\n",
        ")\n",
        "print(result.response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f06802cf-c241-4131-8a5d-529ea3933e59",
      "metadata": {
        "id": "f06802cf-c241-4131-8a5d-529ea3933e59"
      },
      "source": [
        "## In depth analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "67c2240b-7b0d-4bd8-8c19-fcf7e5ba429c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67c2240b-7b0d-4bd8-8c19-fcf7e5ba429c",
        "outputId": "1cabbe83-4743-4d5d-cc88-29bb4a5f9638"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 0 ns, sys: 396 µs, total: 396 µs\n",
            "Wall time: 403 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Using gpt-3.5-turbo, the 16k tokens context size can only fit around 15 pages of document.\n",
        "# Using gpt-4-turbo-preview, the 128k tokens context size can take 100 pages.\n",
        "K = 20\n",
        "\n",
        "query_engine = index.as_query_engine(\n",
        "    similarity_top_k=K, sort_by=\"publication_date\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "b5fcb92b-7e2f-4945-82c7-08bffd20a052",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5fcb92b-7e2f-4945-82c7-08bffd20a052",
        "outputId": "beda7f3d-4654-4471-a064-11e56962c911"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Dodd-Frank Wall Street Reform and Consumer Protection Act of 2010 was a response to the 2008 financial crisis, aiming to strengthen financial regulations. Before the crisis, regulatory oversight was criticized for being insufficient in monitoring large financial institutions, leading to unchecked risky behavior. The Act introduced measures to mitigate risks, such as restrictions on mergers and acquisitions and limits on certain financial activities. It also established the Office of Financial Research and the Financial Stability Oversight Council to enhance monitoring and address systemic risks.\n",
            "\n",
            "To prevent future crises, the Act focused on increasing transparency, strengthening oversight, and enhancing consumer protection. By implementing stricter regulations and oversight mechanisms, it aimed to prevent excessive risk-taking and promote financial stability.\n",
            "\n",
            "In summary, the Dodd-Frank Act significantly revamped financial regulations in the US post-2008 crisis to address regulatory shortcomings and enhance the resilience of the financial system.\n",
            "CPU times: user 654 ms, sys: 26.9 ms, total: 681 ms\n",
            "Wall time: 26.6 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "result = query_engine.query(\n",
        "    \"\"\"\n",
        "Analyse the US financial regulations before and after the 2008 crisis and produce a report of all related arguments to explain what happened, and to ensure that does not happen again.\n",
        "Use both the provided context and your own knowledge but do mention explicitely which one you use.\n",
        "\"\"\"\n",
        ")\n",
        "print(result.response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
