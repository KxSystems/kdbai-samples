{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3280b01a-d3b7-4ef6-9494-789d15bc48ec",
      "metadata": {
        "id": "3280b01a-d3b7-4ef6-9494-789d15bc48ec"
      },
      "source": [
        "# Semantic Search on PDF Documents with qFlat Index\n",
        "\n",
        "##### Note: This example requires a KDB.AI endpoint and API key. Sign up for a free [KDB.AI account](https://kdb.ai/get-started).\n",
        "\n",
        "This example demonstrates how to use KDB.AI to run semantic search on unstructured text documents.\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Tip:</b> This sample uses ‘qFlat’ , a new vector index choice in KDB.AI. It will support the same API options as the existing ‘Flat’ index but with the significant difference that the index is stored on-disk and memory-mapped as required. This means data inserts will have negligible memory and cpu footprints. The vector index can grow and be searched as long as there is disk space available and works great for datasets with up to 1,000,000 vectors. Among other cases, this stands out as a great index for memory contrained situations such as edge devices.\n",
        "</div>\n",
        "\n",
        "Semantic search allows users to perform searches based on the meaning or similarity of the data rather than exact matches. It works by converting the query into a vector representation and then finding similar vectors in the database. This way, even if the query and the data in the database are not identical, the system can identify and retrieve the most relevant results based on their semantic meaning.\n",
        "\n",
        "### Aim\n",
        "In this tutorial, we'll walk you through the process of performing semantic search on documents, taking PDFs as example, using KDB.AI as the vector store. We will cover the following topics:\n",
        "\n",
        "0. Setup\n",
        "1. Load PDF Data\n",
        "2. KDB.AI Table Creation\n",
        "3. LlamaIndex index & query_engine setup\n",
        "4. Retrieve Similar Sentences & RAG\n",
        "5. Delete the KDB.AI Table\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75362bc9",
      "metadata": {
        "id": "75362bc9"
      },
      "source": [
        "## 0. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dda3d787",
      "metadata": {
        "id": "dda3d787"
      },
      "source": [
        "### Install dependencies\n",
        "\n",
        "In order to successfully run this sample, note the following steps depending on where you are running this notebook:\n",
        "\n",
        "-***Run Locally / Private Environment:*** The [Setup](https://github.com/KxSystems/kdbai-samples/blob/main/README.md#setup) steps in the repository's `README.md` will guide you on prerequisites and how to run this with Jupyter.\n",
        "\n",
        "\n",
        "-***Colab / Hosted Environment:*** Open this notebook in Colab and run through the cells."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b19c5107-001e-40c2-bfe7-6c9c99e4846d",
      "metadata": {
        "id": "b19c5107-001e-40c2-bfe7-6c9c99e4846d"
      },
      "source": [
        "### Set Environment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bad9d73",
      "metadata": {
        "id": "8bad9d73"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index llama-index-llms-openai llama-index-embeddings-openai llama-index-readers-file llama-index-vector-stores-kdbai\n",
        "!pip install kdbai_client\n",
        "!pip install pandas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21979389",
      "metadata": {
        "id": "21979389"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "rjfp-08NPdvC",
      "metadata": {
        "id": "rjfp-08NPdvC"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "import re\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import urllib\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from llama_index.core import (\n",
        "    Settings,\n",
        "    SimpleDirectoryReader,\n",
        "    StorageContext,\n",
        "    VectorStoreIndex,\n",
        ")\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.vector_stores.kdbai import KDBAIVectorStore\n",
        "\n",
        "import kdbai_client as kdbai\n",
        "\n",
        "OUTDIR = \"pdf\"\n",
        "RESET = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "f23f6513",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f23f6513",
        "outputId": "f7ab1ea9-14aa-45b2-fd7f-3cb6bde9bad3"
      },
      "outputs": [],
      "source": [
        "### !!! Only run this cell if you need to download the data into your environment, for example in Colab\n",
        "### This downloads research paper pdf into your environment\n",
        "if os.path.exists(\"./data/research_paper.pdf\") == False:\n",
        "  !mkdir ./data\n",
        "  !wget -P ./data https://raw.githubusercontent.com/KxSystems/kdbai-samples/main/document_search/data/research_paper.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "yCCdm-QDPtDZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCCdm-QDPtDZ",
        "outputId": "eb8d2a16-cfe6-41be-bded-729c43bd09ee"
      },
      "outputs": [],
      "source": [
        "# OpenAI API Key: https://platform.openai.com/api\n",
        "os.environ[\"OPENAI_API_KEY\"] = (\n",
        "    os.environ[\"OPENAI_API_KEY\"]\n",
        "    if \"OPENAI_API_KEY\" in os.environ\n",
        "    else getpass(\"OpenAI API Key: \")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "HCI37LxrPywl",
      "metadata": {
        "id": "HCI37LxrPywl"
      },
      "outputs": [],
      "source": [
        "# Set up LlamaIndex Parameters\n",
        "\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "EMBEDDING_MODEL  = \"text-embedding-3-small\"\n",
        "GENERATION_MODEL = 'gpt-4o-mini'\n",
        "\n",
        "llm = OpenAI(model=GENERATION_MODEL)\n",
        "embed_model = OpenAIEmbedding(model=EMBEDDING_MODEL)\n",
        "\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8594c911",
      "metadata": {
        "id": "8594c911"
      },
      "source": [
        "### Configure Console"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "b870117b",
      "metadata": {
        "id": "b870117b"
      },
      "outputs": [],
      "source": [
        "pd.set_option(\"display.max_colwidth\", 300)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a425b33",
      "metadata": {
        "id": "8a425b33"
      },
      "source": [
        "### Define Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "9a135635",
      "metadata": {
        "id": "9a135635"
      },
      "outputs": [],
      "source": [
        "def show_df(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    print(df.shape)\n",
        "    return df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48826990",
      "metadata": {
        "id": "48826990"
      },
      "source": [
        "## 1. Load PDF Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2992812-4705-489d-974f-b7b44132343a",
      "metadata": {
        "id": "b2992812-4705-489d-974f-b7b44132343a"
      },
      "source": [
        "### Read Text From PDF Document\n",
        "\n",
        "We LlamaIndex SimpleDirectorReader to read in our PDF file.\n",
        "\n",
        "The PDF we are using is [this research paper](https://arxiv.org/pdf/2308.05801.pdf) presenting information on the formation of Interstellar Objects in the Milky Way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "NWa3S2iwQd_K",
      "metadata": {
        "id": "NWa3S2iwQd_K"
      },
      "outputs": [],
      "source": [
        "reader = SimpleDirectoryReader(\n",
        "    input_dir=\"data\",\n",
        ")\n",
        "documents = reader.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70505eae-4138-4ba8-80e9-fc13c37d0b32",
      "metadata": {
        "id": "70505eae-4138-4ba8-80e9-fc13c37d0b32"
      },
      "source": [
        "### Define KDB.AI Session\n",
        "\n",
        "KDB.AI comes in two offerings:\n",
        "\n",
        "1. [KDB.AI Cloud](https://trykdb.kx.com/kdbai/signup/) - For experimenting with smaller generative AI projects with a vector database in our cloud.\n",
        "2. [KDB.AI Server](https://trykdb.kx.com/kdbaiserver/signup/) - For evaluating large scale generative AI applications on-premises or on your own cloud provider.\n",
        "\n",
        "Depending on which you use there will be different setup steps and connection details required.\n",
        "\n",
        "##### Option 1. KDB.AI Cloud\n",
        "\n",
        "To use KDB.AI Cloud, you will need two session details - a URL endpoint and an API key.\n",
        "To get these you can sign up for free [here](https://trykdb.kx.com/kdbai/signup).\n",
        "\n",
        "You can connect to a KDB.AI Cloud session using `kdbai.Session` and passing the session URL endpoint and API key details from your KDB.AI Cloud portal.\n",
        "\n",
        "If the environment variables `KDBAI_ENDPOINTS` and `KDBAI_API_KEY` exist on your system containing your KDB.AI Cloud portal details, these variables will automatically be used to connect.\n",
        "If these do not exist, it will prompt you to enter your KDB.AI Cloud portal session URL endpoint and API key details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "401f8162",
      "metadata": {
        "id": "401f8162"
      },
      "outputs": [],
      "source": [
        "KDBAI_ENDPOINT = (\n",
        "    os.environ[\"KDBAI_ENDPOINT\"]\n",
        "    if \"KDBAI_ENDPOINT\" in os.environ\n",
        "    else input(\"KDB.AI endpoint: \")\n",
        ")\n",
        "KDBAI_API_KEY = (\n",
        "    os.environ[\"KDBAI_API_KEY\"]\n",
        "    if \"KDBAI_API_KEY\" in os.environ\n",
        "    else getpass(\"KDB.AI API key: \")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b3a4932",
      "metadata": {
        "id": "3b3a4932"
      },
      "outputs": [],
      "source": [
        "session = kdbai.Session(api_key=KDBAI_API_KEY, endpoint=KDBAI_ENDPOINT)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b53a7384",
      "metadata": {
        "id": "b53a7384"
      },
      "source": [
        "##### Option 2. KDB.AI Server\n",
        "\n",
        "To use KDB.AI Server, you will need download and run your own container.\n",
        "To do this, you will first need to sign up for free [here](https://trykdb.kx.com/kdbaiserver/signup/).\n",
        "\n",
        "You will receive an email with the required license file and bearer token needed to download your instance.\n",
        "Follow instructions in the signup email to get your session up and running.\n",
        "\n",
        "Once the [setup steps](https://code.kx.com/kdbai/gettingStarted/kdb-ai-server-setup.html) are complete you can then connect to your KDB.AI Server session using `kdbai.Session` and passing your local endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "f48fc536",
      "metadata": {
        "id": "f48fc536"
      },
      "outputs": [],
      "source": [
        "# session = kdbai.Session(endpoint=\"http://localhost:8082\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48c6525c",
      "metadata": {
        "id": "48c6525c"
      },
      "source": [
        "### Define Vector DB Table Schema\n",
        "\n",
        "The next step is to define a schema for our KDB.AI table where we will store our embeddings. Our table will have two columns.\n",
        "\n",
        "At this point you will select the index and metric you want to use for searching.\n",
        "\n",
        "In this case, we will use the qFlat index, Euclidean Distance (L2) for the search metric, and we specify the number of dimensions of our embeddings (384)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "eArvp20fSDc6",
      "metadata": {
        "id": "eArvp20fSDc6"
      },
      "outputs": [],
      "source": [
        "#Set up the schema and indexes for KDB.AI table, specifying embeddings column with 384 dimensions, Euclidean Distance, and flat index\n",
        "pdf_schema = [\n",
        "    {\"name\": \"document_id\", \"type\": \"bytes\"},\n",
        "    {\"name\": \"text\", \"type\": \"bytes\"},\n",
        "    {\"name\": \"embeddings\", \"type\": \"float64s\"}\n",
        "]\n",
        "\n",
        "indexes = [\n",
        "    {\n",
        "        \"name\": \"qflat_index\",\n",
        "        \"type\": \"qFlat\",\n",
        "        \"column\": \"embeddings\",\n",
        "        \"params\": {\"dims\": 1536, \"metric\": \"L2\"},\n",
        "    }\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "518cfe1e",
      "metadata": {
        "id": "518cfe1e"
      },
      "source": [
        "### Create Vector DB Table\n",
        "\n",
        "Use the KDB.AI `create_table` function to create a table that matches the defined schema in the vector database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "6e670f9e",
      "metadata": {
        "id": "6e670f9e"
      },
      "outputs": [],
      "source": [
        "# get the database connection. Default database name is 'default'\n",
        "database = session.database('default')\n",
        "\n",
        "# First ensure the table does not already exist\n",
        "try:\n",
        "    database.table(\"pdf\").drop()\n",
        "except kdbai.KDBAIException:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "e1d190db-7c19-418e-9140-3dff04c9d4c0",
      "metadata": {
        "id": "e1d190db-7c19-418e-9140-3dff04c9d4c0"
      },
      "outputs": [],
      "source": [
        "table = database.create_table(\"pdf\", pdf_schema, indexes=indexes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "466068bc",
      "metadata": {
        "id": "466068bc"
      },
      "source": [
        "We can use `query` to see our table exists but is empty."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74e7332e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "74e7332e",
        "outputId": "53fc8178-89bb-4fb4-c862-03b9f5bf6301"
      },
      "outputs": [],
      "source": [
        "table.query()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YvcNh1v_Wixe",
      "metadata": {
        "id": "YvcNh1v_Wixe"
      },
      "source": [
        "## 3. LlamaIndex index & query_engine setup\n",
        "Define the index: using KDB.AI as the vector store, chunk, embed, and load the document into KDB.AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "He42izi1Soee",
      "metadata": {
        "id": "He42izi1Soee"
      },
      "outputs": [],
      "source": [
        "vector_store = KDBAIVectorStore(table)\n",
        "\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents,\n",
        "    storage_context=storage_context,\n",
        "    transformations=[SentenceSplitter(chunk_size=1000, chunk_overlap=0)],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e31a4ecd",
      "metadata": {
        "id": "e31a4ecd"
      },
      "source": [
        "### Verify Data Has Been Inserted\n",
        "\n",
        "Running `table.query()` should show us that data has been added."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee6ecb8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "id": "ee6ecb8d",
        "outputId": "56edf391-d474-4f9f-c085-0f4601763abe"
      },
      "outputs": [],
      "source": [
        "show_df(table.query())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tiZ5HWsEThcT",
      "metadata": {
        "id": "tiZ5HWsEThcT"
      },
      "source": [
        "#### Set up the LlamaIndex Query Engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "u_IlkIcuTn3e",
      "metadata": {
        "id": "u_IlkIcuTn3e"
      },
      "outputs": [],
      "source": [
        "query_engine = index.as_query_engine(\n",
        "    similarity_top_k=5,\n",
        "    vector_store_kwargs={\n",
        "                    \"index\" : \"qflat_index\",\n",
        "                },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bf8650d",
      "metadata": {
        "id": "8bf8650d"
      },
      "source": [
        "## 4. Retrieve Similar Sentences & RAG\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31ddb725-e0e7-4c00-a22b-3234eacf6bd1",
      "metadata": {
        "id": "31ddb725-e0e7-4c00-a22b-3234eacf6bd1"
      },
      "source": [
        "Now that the embeddings are stored in KDB.AI, we can perform semantic search using through the LlamaIndex query engine.\n",
        "\n",
        "### Search 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "b24c1179",
      "metadata": {
        "id": "b24c1179"
      },
      "outputs": [],
      "source": [
        "search_term1 = \"number of interstellar objects in the milky way\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QbyVfwB8VTcg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbyVfwB8VTcg",
        "outputId": "87417a96-d924-424e-ef5b-2dec6ff8d68a"
      },
      "outputs": [],
      "source": [
        "retrieved_chunks = query_engine.retrieve(search_term1)\n",
        "print(retrieved_chunks)\n",
        "for i in retrieved_chunks:\n",
        "    print(i.node.get_text())\n",
        "    print(\"____________________\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9R4vgFZMVvv9",
      "metadata": {
        "id": "9R4vgFZMVvv9"
      },
      "source": [
        "We can see these sentences do reference our search term 'number of interstellar objects in the milky way' in some way."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "n0n7OglvVvvA",
      "metadata": {
        "id": "n0n7OglvVvvA"
      },
      "source": [
        "### Now we can perform RAG, passing the retrieved chunks from above to the LLM for a generate response:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ttZpktxET3tq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttZpktxET3tq",
        "outputId": "85f355ee-8355-4eb2-c7ce-56a86b8de138"
      },
      "outputs": [],
      "source": [
        "result = query_engine.query(search_term1)\n",
        "print(result.response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91762de7",
      "metadata": {
        "id": "91762de7"
      },
      "source": [
        "### Search 2\n",
        "\n",
        "Let's try another search term."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "e7486a9c",
      "metadata": {
        "id": "e7486a9c"
      },
      "outputs": [],
      "source": [
        "search_term2 = \"how does planet formation occur\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6765075c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6765075c",
        "outputId": "bae77687-8399-4264-9007-c134f36a849f"
      },
      "outputs": [],
      "source": [
        "retrieved_chunks = query_engine.retrieve(search_term2)\n",
        "for i in retrieved_chunks:\n",
        "    print(i.node.get_text())\n",
        "    print(\"____________________\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25ce337f",
      "metadata": {
        "id": "25ce337f"
      },
      "source": [
        "Again, we can see these sentences do reference our search term 'how does planet formation occur' in some way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d3ce969",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d3ce969",
        "outputId": "f6043cd7-0f4c-475c-cbf4-961945db77b9"
      },
      "outputs": [],
      "source": [
        "result = query_engine.query(search_term2)\n",
        "print(result.response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6e93878",
      "metadata": {
        "id": "f6e93878"
      },
      "source": [
        "## 5. Delete the KDB.AI Table\n",
        "\n",
        "Once finished with the table, it is best practice to drop it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "d74b6f20",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d74b6f20",
        "outputId": "13103bc6-9740-4dd3-95af-6b1396174818"
      },
      "outputs": [],
      "source": [
        "table.drop()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "346d56db",
      "metadata": {
        "id": "346d56db"
      },
      "source": [
        "## Take Our Survey\n",
        "\n",
        "We hope you found this sample helpful! Your feedback is important to us, and we would appreciate it if you could take a moment to fill out our brief survey. Your input helps us improve our content.\n",
        "\n",
        "[**Take the Survey**](https://delighted.com/t/ejgOzTpo)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
