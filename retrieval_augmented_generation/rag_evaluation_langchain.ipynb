{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48eeba82",
   "metadata": {},
   "source": [
    "# RAG Evaluation with LangChain and KDB.AI\n",
    "\n",
    "This notebook serves as a guide to utilizing LangChain tooling for evaluating a basic Retrieval-Augmented Generation (RAG) system. \n",
    "\n",
    "The evaluation process involves employing [LangChain's String Evaluators](https://python.langchain.com/docs/guides/evaluation/string/) to assess both conciseness and correctness. KDB.AI serves as the primary knowledge base, enabling the retrieval of semantically relevant content for the evaluation.\n",
    "\n",
    "## Aim\n",
    "\n",
    "1. Build basic RAG pipeline\n",
    "2. Calculate conciseness\n",
    "3. Calculate correctness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccfea1b-e0ec-425e-aab8-48726b6cf96e",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "\n",
    "### Install packages \n",
    "\n",
    "Before running this notebook, ensure you have installed the required dependencies provided in the `requirements.txt`. Refer to the [README](https://github.com/KxSystems/kdbai-samples/blob/main/README.md#install-python-packages) for instructions on using `pip install` to set up the necessary environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1651bf-3d05-41b7-8eb5-3a3546d8723a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff441409-4f98-49df-892e-e324fe05320c",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "617b1b87-4310-4f51-8491-9f273bd91e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "import kdbai_client as kdbai\n",
    "import time\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099a2d3c-46f5-40b7-8603-a88fca8fdd2e",
   "metadata": {},
   "source": [
    "## 1. Build basic RAG pipeline\n",
    "\n",
    "Load a PDF document that contains a state of the union address. Then build a generic QA system using LangChain with KDB.AI as the vector store.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d9390b-4159-4939-a897-9bb9e7ca8fcc",
   "metadata": {},
   "source": [
    "### Set API Keys\n",
    "\n",
    "To follow this example you will need to request both an [OpenAI API Key](https://platform.openai.com/apps).\n",
    "\n",
    "You can create both for free by registering using the link provided. Once you have the credentials you can add them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "644c0326-933a-499b-9a85-f4d1139c5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = (\n",
    "    os.environ[\"OPENAI_API_KEY\"]\n",
    "    if \"OPENAI_API_KEY\" in os.environ\n",
    "    else getpass(\"OpenAI API Key: \")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5101ee7b-7086-4a71-b63c-ed79f4fbb3e6",
   "metadata": {},
   "source": [
    "### KDB.AI Cloud\n",
    "To use KDB.AI Cloud, you will need two session details - a URL endpoint and an API key. To get these you can sign up for free here.\n",
    "\n",
    "You can connect to a KDB.AI Cloud session using kdbai.Session and passing the session URL endpoint and API key details from your KDB.AI Cloud portal.\n",
    "\n",
    "If the environment variables KDBAI_ENDPOINTS and KDBAI_API_KEY exist on your system containing your KDB.AI Cloud portal details, these variables will automatically be used to connect. If these do not exist, it will prompt you to enter your KDB.AI Cloud portal session URL endpoint and API key details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d8ceb98-fab4-48ef-abc9-b11c9a346b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "KDBAI_ENDPOINT = (\n",
    "    os.environ[\"KDBAI_ENDPOINT\"]\n",
    "    if \"KDBAI_ENDPOINT\" in os.environ\n",
    "    else input(\"KDB.AI endpoint: \")\n",
    ")\n",
    "KDBAI_API_KEY = (\n",
    "    os.environ[\"KDBAI_API_KEY\"]\n",
    "    if \"KDBAI_API_KEY\" in os.environ\n",
    "    else getpass(\"KDB.AI API key: \")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3530dbe-a428-440e-801f-e7843f70df19",
   "metadata": {},
   "source": [
    "### Load data and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b64393c0-799e-49b1-953f-e545cbcf1b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain packages\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import KDBAI\n",
    "from langchain import HuggingFaceHub\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "doc = TextLoader(\"data/state_of_the_union.txt\").load()\n",
    "# Chunk the documents into 500 character chunks using langchain's text splitter \"RucursiveCharacterTextSplitter\"\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "\n",
    "# split_documents produces a list of all the chunks created, printing out first chunk for example\n",
    "pages = [p.page_content for p in text_splitter.split_documents(doc)]\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf28334-439d-4e72-a10c-5f302facc1de",
   "metadata": {},
   "source": [
    "### Connect to KDB.AI and save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10c13997-9c4d-40d3-9c87-b628332f743f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['09c86122-d028-42de-b318-c7349209bcd6',\n",
       " 'c30d113d-2fef-4b28-ae5f-84e67fab3109',\n",
       " '4e307828-0ff6-469e-9f57-30fd2c031f55',\n",
       " 'db7c750a-dbd2-411a-9e16-e0663f4c88cd',\n",
       " 'df645be4-73d7-4ffc-977e-b0d6885f9794',\n",
       " 'a9a7db05-08dc-41cd-8b43-aabbfffa1d9c',\n",
       " 'c60efca0-5f6e-4259-b9a7-ad48b8cc41e8',\n",
       " '54aac53b-ed54-4526-a13a-f764c955eaa1',\n",
       " '78faf54c-e332-481c-9cf5-8831dd607410',\n",
       " '65d5dea7-49a3-4cf7-a1e7-a0652327d0eb',\n",
       " '9aee930a-0c03-4627-bab1-d761ae8a5640',\n",
       " '8856d2a8-0416-4ad7-8d6f-0d1e2cf5b1c4',\n",
       " 'eea29139-b64b-4afd-904c-b32082792c62',\n",
       " '9030e40b-0ddc-4ba8-9d40-8ac69e457cf8',\n",
       " '842a14c0-58e1-4065-9096-8866cc94ed35',\n",
       " '68fe53be-9518-4a6d-80fa-8a590132f1d9',\n",
       " 'ddc10548-c5a3-4310-90e7-b1e05a34f446',\n",
       " '50d6ac94-62a2-4ba7-a3cb-811d7b064de3',\n",
       " 'b4571df1-ac2a-4b3f-aa50-93d55a877b97',\n",
       " '5f42a5d4-fbc7-4ba9-a98a-d27eb44c7c8f',\n",
       " 'ace0f1c5-f8b2-4180-a566-d3555dc5cb80',\n",
       " '346382ce-0532-47e5-a072-aad82561335b',\n",
       " '628ab41c-8394-4a5f-a0a3-850094c27988',\n",
       " 'dad0bb8e-d974-414b-a694-85649ad67662',\n",
       " '89d2ad9b-33a6-4f51-9865-f24e898c5680',\n",
       " '8d3790db-72bd-4c89-bb52-dd08992c8c34',\n",
       " 'caf29f4c-b69c-4ff0-8204-4930dada5f14',\n",
       " '05922731-cc2b-483c-a41d-d3335c5b1681',\n",
       " '77719264-f2f1-4ebd-b7ce-9dac985d4430',\n",
       " 'ba1a1519-3cb1-4d3f-a02b-678ed3d1219b',\n",
       " '7a42c3aa-e72c-4238-8e51-cd945a77401d',\n",
       " 'f877d892-43d7-4a7b-b0fa-e4da795dcb29',\n",
       " 'a596e7d2-bfe1-450e-b55c-35f81981b5a9',\n",
       " '4c87bf25-f6a1-4a2f-936c-f7a85dd26b25',\n",
       " '3f5b453a-e48c-4a81-bd22-9f0a73c5cede',\n",
       " '843dc46f-9e82-4002-89b1-09b9d3910735',\n",
       " 'e4016663-c5b2-4170-85ad-3e5d569e91b5',\n",
       " 'd9334e96-c8d0-40ff-819b-728e085d6f8a',\n",
       " '3ae4b9fd-96fc-4206-8d6a-96d8107e11aa',\n",
       " '7416e01a-df2e-4f67-a8e0-f72466eeae64',\n",
       " '279dc148-010e-4e92-a046-5fcddb22b09f',\n",
       " 'e62ae849-1d52-49b6-bf6e-9f3ae0cc6f44',\n",
       " '2a9b7360-7185-45bd-ad00-87d99b0344a5',\n",
       " '61b449e5-388e-4276-96a7-556d60073879',\n",
       " '98a2eb4d-d4c9-4d40-af5f-e9d6f39325ba',\n",
       " '4ba55939-acbe-43c0-8a91-a50ac882f65d',\n",
       " 'e2161b68-9ea2-48cc-ab9a-374cd5bb7cee',\n",
       " '0284bdeb-d644-4d25-a65a-2c335f12262c',\n",
       " 'a8fc215e-185c-4e75-bd3d-a99623b05933',\n",
       " '834a544b-a180-4d56-ba61-2411f3d56a43',\n",
       " '5555f95b-251b-42be-9823-0177e1ba5cc4',\n",
       " '779aba06-f4cc-44f2-bf71-dff041f22ae9',\n",
       " 'db611292-f15f-4996-ba85-fb474db3708f',\n",
       " '2913d3e0-ab0d-4133-ae8d-cfb8f4deba19',\n",
       " '30000a50-c167-43e7-8be8-5ef575617ab7',\n",
       " '352069fd-a997-4206-bc97-bdd2c282ebca',\n",
       " '3124b402-ea76-420a-a51c-fc5bc725b25f',\n",
       " '21d33c24-4106-40e7-bdf6-eaffd5db3640',\n",
       " '72d4bd58-89b1-4de5-b132-ea4da9197526',\n",
       " 'c41f72fd-0ccb-45ad-bf54-1b219d758c0b',\n",
       " 'b2596c78-7a99-47dd-b3d5-2024ee42122c',\n",
       " '41d8b16f-0bc4-4ec5-81c3-cde932eca5db',\n",
       " 'd6d3e085-d0e1-4cff-a971-d14a066e9195',\n",
       " '77a9ad94-de03-40b6-aaae-0c5e212c06da',\n",
       " 'de8986e4-3db2-483e-9917-a548745626e1',\n",
       " '1a0c6381-1109-4dd7-83d9-f743c1e1fbea',\n",
       " '729ee76b-bb41-4c6a-9d88-50d5e84ed71c',\n",
       " 'ee1c8eb7-84cb-475a-9d2c-63daf43247ab',\n",
       " '0af2770d-db8f-45d6-8741-1408aad3159a',\n",
       " '5ccc2cf7-7517-441d-82cc-b5168adae0da',\n",
       " '4643baef-f3f6-4149-984b-40bce9beb75e',\n",
       " '127ffd2c-72de-4c70-94b4-9a71f2550010',\n",
       " '8e5430f1-f5bd-4ef3-871f-2924d29a438e',\n",
       " 'becdabe2-7a4f-4531-94c7-c3cd151cad5f',\n",
       " '42c5706c-f3ca-4fb0-9fbc-add1d1a4c20d',\n",
       " '4ea72046-e497-4728-b8cc-3098d518645c',\n",
       " '9eb62d15-7f54-46c9-9876-cad951428c2f',\n",
       " 'a803fb78-0535-4e9e-b4f4-8c473340524c',\n",
       " '849eb489-12de-44f0-8c79-cf2358282622',\n",
       " 'ac3df2b2-f866-43b1-9612-a19873a49495',\n",
       " 'a35bde95-995e-4b5a-840f-b263d3dbc307',\n",
       " 'e70c7668-4cf1-4774-b532-630fc1f826a8',\n",
       " 'df677143-001a-4989-aed8-3a746ba70cf4',\n",
       " '8764e1f2-4128-4ea1-a0b7-dd362e212368',\n",
       " '4e81db56-c47c-405a-8671-5aadeebc0c49',\n",
       " 'b9936cc0-a29f-4dc1-a90b-56826b3bb84b',\n",
       " 'b2787373-a0e9-4d8d-82a0-0eda52f6c8fb',\n",
       " '5533fa49-78d5-46e8-b8c8-8a76907bf678',\n",
       " '0c8df148-fcbd-4e63-9987-1b190a6dff2e']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = kdbai.Session(api_key=KDBAI_API_KEY, endpoint=KDBAI_ENDPOINT)\n",
    "\n",
    "## Define table schema\n",
    "rag_schema = {\n",
    "    \"columns\": [\n",
    "        {\"name\": \"id\", \"pytype\": \"str\"},\n",
    "        {\"name\": \"text\", \"pytype\": \"bytes\"},\n",
    "        {\n",
    "            \"name\": \"embeddings\",\n",
    "            \"pytype\": \"float32\",\n",
    "            \"vectorIndex\": {\"dims\": 1536, \"metric\": \"L2\", \"type\": \"flat\"},\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "# First ensure the table does not already exist\n",
    "try:\n",
    "    session.table(\"rag_langchain\").drop()\n",
    "    time.sleep(3)\n",
    "except kdbai.KDBAIException:\n",
    "    pass\n",
    "\n",
    "table = session.create_table(\"rag_langchain\", rag_schema)\n",
    "\n",
    "# Save the data to KDB.AI\n",
    "vecdb_kdbai = KDBAI(table, embeddings)\n",
    "vecdb_kdbai.add_texts(texts=pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d373d51-a4fd-4973-a8af-f13b2259d21f",
   "metadata": {},
   "source": [
    "### Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dca709a-d403-4fcf-90fb-7716ec820fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Because we know that when the middle class grows, the poor have a ladder up and the wealthy do very well. \\n\\nAmerica used to have the best roads, bridges, and airports on Earth. \\n\\nNow our infrastructure is ranked 13th in the world. \\n\\nWe won’t be able to compete for the jobs of the 21st Century if we don’t fix that. \\n\\nThat’s why it was so important to pass the Bipartisan Infrastructure Law—the most sweeping investment to rebuild America in history.', metadata={'id': 'dad0bb8e-d974-414b-a694-85649ad67662', 'embeddings': array([ 0.00343209,  0.01247914,  0.00845823, ..., -0.02029975,\n",
       "        -0.0327919 , -0.01868618], dtype=float32)})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What improvements could be made in infrastructure?\"\n",
    "# query holds results of the similarity search, the closest related chunks to the query.\n",
    "query_sim = vecdb_kdbai.similarity_search(query)\n",
    "query_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92633be8-2f0b-4995-95cc-76ef6381bf5b",
   "metadata": {},
   "source": [
    "### Question-answering bot using GPT-3.5\n",
    "\n",
    "The code below defines a question-answering bot that combines OpenAI's GPT-3.5 Turbo for generating responses and a retriever that accesses the KDB.AI vector database to find relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b9ecda2-36e5-4127-80c0-13d208f8f770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What improvements could be made in infrastructure?\n",
      "-----\n",
      "Some improvements that could be made in infrastructure include:\n",
      "\n",
      "1. Rebuilding and repairing highways and bridges that are in disrepair.\n",
      "2. Building a national network of 500,000 electric vehicle charging stations.\n",
      "3. Replacing poisonous lead pipes to ensure clean water for every American.\n",
      "4. Providing affordable high-speed internet access for all Americans, including urban, suburban, rural, and tribal communities.\n",
      "5. Modernizing airports, ports, and waterways.\n",
      "6. Investing in renewable energy production, such as solar and wind, to double America's clean energy production.\n",
      "7. Lowering the cost of electric vehicles and promoting their use.\n",
      "8. Weatherizing homes and businesses to improve energy efficiency.\n",
      "9. Investing in emerging technologies and American manufacturing to compete with global competitors like China.\n",
      "10. Ensuring that infrastructure projects are made in America, supporting domestic manufacturing and supply chains.\n"
     ]
    }
   ],
   "source": [
    "#gpt-3.5 as retriever\n",
    "K = 10\n",
    "qabot = RetrievalQA.from_chain_type(\n",
    "    chain_type=\"stuff\",\n",
    "    llm=ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0.0),\n",
    "    retriever=vecdb_kdbai.as_retriever(search_kwargs=dict(k=K)),\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "# testing it out \n",
    "print(query)\n",
    "print(\"-----\")\n",
    "pred = qabot(dict(query=query))[\"result\"]\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9964fa1f-c8d4-40cd-86e8-c4f4fb671e14",
   "metadata": {},
   "source": [
    "## 2. Calculate Conciseness\n",
    "\n",
    "Let's measure the conciseness of this answer the QA bot returns using LangChain's `load_evaluator` function with the `criteria` set to concisesness. In this example we use GPT-4 as the LLM that performs the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7866960-9256-4df2-8087-49dcf43c3124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reasoning': 'The criterion for this task is conciseness. To evaluate the '\n",
      "              \"submission on this basis, let's consider the following:\\n\"\n",
      "              '\\n'\n",
      "              '1. The submission begins with a brief introduction to the '\n",
      "              'topic, which sets the context for the following points. It does '\n",
      "              'not provide any unnecessary information.\\n'\n",
      "              '\\n'\n",
      "              '2. Each point in the list provides a clear and specific '\n",
      "              'improvement that could be made to infrastructure. These points '\n",
      "              'are directly related to the question and do not contain any '\n",
      "              'extraneous details or explanations.\\n'\n",
      "              '\\n'\n",
      "              '3. The submission does not include any additional sentences or '\n",
      "              'paragraphs outside of the introduced improvements. This '\n",
      "              'suggests that the writer was focused on providing a direct '\n",
      "              'answer to the question without adding unnecessary information.\\n'\n",
      "              '\\n'\n",
      "              'Based on the above reasoning, it can be concluded that the '\n",
      "              'submission is concise and to the point. \\n'\n",
      "              '\\n'\n",
      "              'Therefore, the answer is:\\n'\n",
      "              '\\n'\n",
      "              'Y',\n",
      " 'score': 1,\n",
      " 'value': 'Y'}\n"
     ]
    }
   ],
   "source": [
    "#gpt-4 as evaluator\n",
    "from pprint import pprint as print\n",
    "from langchain.evaluation import load_evaluator\n",
    "\n",
    "evaluation_llm = ChatOpenAI(model=\"gpt-4\")\n",
    "evaluator = load_evaluator(\"criteria\", criteria=\"conciseness\", llm=evaluation_llm)\n",
    "\n",
    "eval_result = evaluator.evaluate_strings(\n",
    "    prediction=pred,\n",
    "    input=query,\n",
    ")\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8e4e74-876c-4dae-9e0d-42f20698ea43",
   "metadata": {},
   "source": [
    "### 3. Calculate Correctness\n",
    "\n",
    "We can use the same `load_evaluator` function to calculate correctness simply changing the `criteria` to correctness.\n",
    "\n",
    "Let's try a different query this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6776b8ba-208f-47d3-ab7c-bc2e897fd48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('How many jobs were created in the country due the electric vehicle '\n",
      " 'manufacturing industry?')\n",
      "'-----'\n",
      "('The passage states that Ford is investing $11 billion to build electric '\n",
      " 'vehicles, creating 11,000 jobs across the country. Additionally, GM is '\n",
      " 'making the largest investment in its history—$7 billion to build electric '\n",
      " 'vehicles, creating 4,000 jobs in Michigan. Therefore, a total of 15,000 jobs '\n",
      " 'were created in the country due to the electric vehicle manufacturing '\n",
      " 'industry mentioned in the passage.')\n"
     ]
    }
   ],
   "source": [
    "query2 = \"How many jobs were created in the country due the electric vehicle manufacturing industry?\"\n",
    "print(query2)\n",
    "print(\"-----\")\n",
    "pred2 = qabot(dict(query=query2))[\"result\"]\n",
    "print(pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778a8127-9c1e-45e8-b8b6-38e9ab2c7a3c",
   "metadata": {},
   "source": [
    "When using this option we can pass a reference for the evaluator to check for correctness against. Let's pass a reference that matches the information returned as well as one that doesn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "708d3386-f28d-4a6a-bb7c-10a15e8574af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reasoning': 'The criterion for this assessment is correctness, accuracy, and '\n",
      "              'factuality. We need to verify if the submitted answer is '\n",
      "              'correct and factual based on the given input and the '\n",
      "              'reference.\\n'\n",
      "              '\\n'\n",
      "              'The input asks for the number of jobs created in the country '\n",
      "              'due to the electric vehicle manufacturing industry. \\n'\n",
      "              '\\n'\n",
      "              'The submission provided a detailed answer, stating that Ford '\n",
      "              \"and GM's investments in electric vehicle manufacturing resulted \"\n",
      "              'in a total of 15,000 jobs across the country. \\n'\n",
      "              '\\n'\n",
      "              'Comparing this with the reference, which states that 15,000 '\n",
      "              'jobs were created due to the manufacturing of electric '\n",
      "              \"vehicles, we can see that the submission's information aligns \"\n",
      "              'with the reference, indicating it is accurate and factual. \\n'\n",
      "              '\\n'\n",
      "              'Therefore, the submission meets the criteria of correctness, '\n",
      "              'accuracy, and factuality.\\n'\n",
      "              '\\n'\n",
      "              'Y',\n",
      " 'score': 1,\n",
      " 'value': 'Y'}\n"
     ]
    }
   ],
   "source": [
    "# Reference matches\n",
    "evaluator2 = load_evaluator(\"labeled_criteria\", criteria=\"correctness\", llm=evaluation_llm,requires_reference=True)\n",
    "\n",
    "eval_result2 = evaluator2.evaluate_strings(\n",
    "    prediction=pred2,\n",
    "    input=query2,\n",
    "    reference=\"15000 jobs were created due to manufacturing of electric vehicles.\"\n",
    ")\n",
    "\n",
    "print(eval_result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2172b83f-61ca-4963-8225-0378580a67a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reasoning': 'The criterion to assess is the correctness, accuracy, and '\n",
      "              'factualness of the submission.\\n'\n",
      "              '\\n'\n",
      "              '1. Correctness: The submission provides details about the '\n",
      "              'number of jobs created due to the investment in electric '\n",
      "              'vehicle manufacturing by Ford and GM. These details align with '\n",
      "              'the input question.\\n'\n",
      "              '\\n'\n",
      "              '2. Accuracy: The submission states that a total of 15,000 jobs '\n",
      "              'were created. This is the sum of the 11,000 from Ford and 4,000 '\n",
      "              'from GM.\\n'\n",
      "              '\\n'\n",
      "              '3. Factualness: The reference provided states that 12,000 jobs '\n",
      "              'were created due to the manufacturing of electric vehicles, '\n",
      "              \"which contradicts the submission's claim of 15,000 jobs. \\n\"\n",
      "              '\\n'\n",
      "              'Based on this analysis, the submission fails to meet the '\n",
      "              'factualness criterium, even though it is correct and accurate '\n",
      "              'according to the information provided in the submission '\n",
      "              'itself.\\n'\n",
      "              '\\n'\n",
      "              'N',\n",
      " 'score': 0,\n",
      " 'value': 'N'}\n"
     ]
    }
   ],
   "source": [
    "# Reference contradicts\n",
    "eval_result3 = evaluator2.evaluate_strings(\n",
    "    prediction=pred2,\n",
    "    input=query2,\n",
    "    reference=\"12000 jobs were created due to manufacturing of electric vehicles.\"\n",
    ")\n",
    "\n",
    "print(eval_result3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
