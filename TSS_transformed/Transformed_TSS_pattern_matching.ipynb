{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b52fbdd6-10c5-4f52-b015-ce0f812c7d94",
      "metadata": {
        "id": "b52fbdd6-10c5-4f52-b015-ce0f812c7d94"
      },
      "source": [
        "# Pattern Matching on Sensor Data\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Tip:</b> We have new features for highly optimized time series analytics.\n",
        "\n",
        "See documentation and notebooks on ***Temporal Similarity Search (TSS):***\n",
        "\n",
        "- Transformed TSS: [Documentation](https://code.kx.com/kdbai/reference/transformed-tss.html)\n",
        "\n",
        "- Non-Transformed TSS: [Documentation](https://code.kx.com/kdbai/use/non-transformed-tss.html) \n",
        "\n",
        "</div>\n",
        "\n",
        "##### Note: This example requires a KDB.AI endpoint and API key. Sign up for a free [KDB.AI account](https://kdb.ai/get-started).\n",
        "\n",
        "This example explores the process of conducting pattern matching on time series manufacturing data using *Transformed Temporal Similarity Search* in KDB.AI.\n",
        "\n",
        "Our goal is to identify and retrieve historical time series that exhibit specific patterns. This matching capability is instrumental in a wide array of manufacturing scenarios, including quality control, process optimization, and predictive maintenance. For instance, imagine a scenario where we have time series data representing machinery performance, and we need to pinpoint instances of unusual behaviour, such as spikes, drops, or recurring trends.\n",
        "\n",
        "We will guide you through a straightforward approach that leverages the raw time series data directly, without the need for complex modeling or domain-specific expertise. This approach is particularly attractive because it doesn't require additional resources for model creation. The sample will demonstrate that this simplistic method can yield satisfactory results.\n",
        "\n",
        "### Aim\n",
        "\n",
        "This tutorial will walk through the process of storing time series data in a vector database, generating time series vector embeddings. We will use KDB.AI's vector database to find patterns that match an input query pattern. We will cover the following topics:\n",
        "\n",
        "1. Load Sensor Data\n",
        "1. Create Sensor Vector Embeddings\n",
        "1. Store Embeddings in KDB.AI\n",
        "1. Search For Similar Sequences To A Target Sensor Sequence\n",
        "1. Delete the KDB.AI Table\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f232d6de-c110-460a-a69f-e8cf852355b6",
      "metadata": {
        "id": "f232d6de-c110-460a-a69f-e8cf852355b6"
      },
      "source": [
        "## 0. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07954b1a",
      "metadata": {
        "id": "07954b1a"
      },
      "source": [
        "### Install dependencies\n",
        "\n",
        "In order to successfully run this sample, note the following steps depending on where you are running this notebook:\n",
        "\n",
        "-***Run Locally / Private Environment:*** The [Setup](https://github.com/KxSystems/kdbai-samples/blob/main/README.md#setup) steps in the repository's `README.md` will guide you on prerequisites and how to run this with Jupyter.\n",
        "\n",
        "\n",
        "-***Colab / Hosted Environment:*** Open this notebook in Colab and run through the cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e77efaa7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e77efaa7",
        "outputId": "ac35dc82-2065-4f41-d0f6-d9dffac08749"
      },
      "outputs": [],
      "source": [
        "!pip install kdbai_client\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7e18f8ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e18f8ce",
        "outputId": "bcecd79f-3aad-413f-df16-0c2d1981aa35"
      },
      "outputs": [],
      "source": [
        "### !!! Only run this cell if you need to download the data into your environment, for example in Colab\n",
        "### This downloads sensor data\n",
        "!mkdir ./data\n",
        "!wget -P ./data https://raw.githubusercontent.com/KxSystems/kdbai-samples/main/pattern_matching/data/archive.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38e158a3",
      "metadata": {
        "id": "38e158a3"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ea686a15",
      "metadata": {
        "id": "ea686a15"
      },
      "outputs": [],
      "source": [
        "# read data\n",
        "from zipfile import ZipFile\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "07814a98",
      "metadata": {
        "id": "07814a98"
      },
      "outputs": [],
      "source": [
        "# plotting\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9f76e651",
      "metadata": {
        "id": "9f76e651"
      },
      "outputs": [],
      "source": [
        "# vector DB\n",
        "import os\n",
        "import kdbai_client as kdbai\n",
        "from getpass import getpass\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e7b4076",
      "metadata": {
        "id": "3e7b4076"
      },
      "source": [
        "### Ignore Warning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "33c637f0",
      "metadata": {
        "id": "33c637f0"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "warnings.simplefilter(\"ignore\", UserWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6d03b85",
      "metadata": {
        "id": "e6d03b85"
      },
      "source": [
        "### Define Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "75ff66c8",
      "metadata": {
        "id": "75ff66c8"
      },
      "outputs": [],
      "source": [
        "def show_df(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    print(df.shape)\n",
        "    return df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff790798",
      "metadata": {
        "id": "ff790798"
      },
      "source": [
        "## 1. Load Sensor Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7911ab4",
      "metadata": {
        "id": "b7911ab4"
      },
      "source": [
        "### Dataset Overview\n",
        "\n",
        "The dataset that will be used for this example is the [Water Pump Sensor Dataset](https://www.kaggle.com/datasets/nphantawee/pump-sensor-data) available on Kaggle. The datatset consist of a `sensor.csv` file which has raw values from 52 sensors from a town water pump.\n",
        "\n",
        "As the `sensors.csv` file is >100mb, we cannot host this file on GitHub and must instead zip this file up and extract it locally.\n",
        "\n",
        "### Extract the Data From a ZipFile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5cdbf217",
      "metadata": {
        "id": "5cdbf217"
      },
      "outputs": [],
      "source": [
        "def extract_zip(file_name):\n",
        "    with ZipFile(file_name, \"r\") as zipf:\n",
        "        zipf.extractall(\"data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2b6142d3-667a-4f65-abe2-b33f95fdd46f",
      "metadata": {
        "id": "2b6142d3-667a-4f65-abe2-b33f95fdd46f"
      },
      "outputs": [],
      "source": [
        "extract_zip(\"data/archive.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e5ff469",
      "metadata": {
        "id": "1e5ff469"
      },
      "source": [
        "You should now have a sensor.csv file."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c7476f1",
      "metadata": {
        "id": "2c7476f1"
      },
      "source": [
        "### Read In The Sensor Data From The CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3c876844",
      "metadata": {
        "id": "3c876844"
      },
      "outputs": [],
      "source": [
        "raw_sensors_df = pd.read_csv(\"data/sensor.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "12d3c00a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "12d3c00a",
        "outputId": "4f2229c2-e66f-4b2b-ee27-3d4c46ed343b"
      },
      "outputs": [],
      "source": [
        "show_df(raw_sensors_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e584484f",
      "metadata": {
        "id": "e584484f"
      },
      "source": [
        "### Pre-process The Data\n",
        "\n",
        "Let's do some preparation on the dataset to clean it up. We will remove duplicates, drop  irrelevant columns and handle missing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "04f68700",
      "metadata": {
        "id": "04f68700"
      },
      "outputs": [],
      "source": [
        "# Drop duplicates\n",
        "sensors_df = raw_sensors_df.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6382c72b",
      "metadata": {
        "id": "6382c72b"
      },
      "outputs": [],
      "source": [
        "# Remove columns that are unnecessary/bad data\n",
        "sensors_df = sensors_df.drop([\"Unnamed: 0\", \"sensor_15\", \"sensor_50\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "3e338bae",
      "metadata": {
        "id": "3e338bae"
      },
      "outputs": [],
      "source": [
        "# convert timestamp to datetime format\n",
        "sensors_df[\"timestamp\"] = pd.to_datetime(sensors_df[\"timestamp\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "19fc8b10",
      "metadata": {
        "id": "19fc8b10"
      },
      "outputs": [],
      "source": [
        "# Removes rows with any NaN values\n",
        "sensors_df = sensors_df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2f35a91a",
      "metadata": {
        "id": "2f35a91a"
      },
      "outputs": [],
      "source": [
        "# Reset the index\n",
        "sensors_df = sensors_df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ad0f0794-38db-44b2-bcae-63b399b89729",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "ad0f0794-38db-44b2-bcae-63b399b89729",
        "outputId": "27798e03-95e2-47ae-f557-85d133704c42"
      },
      "outputs": [],
      "source": [
        "show_df(sensors_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f65d5494",
      "metadata": {
        "id": "f65d5494"
      },
      "source": [
        "This dataset has 52 sensor columns - for the purposes of this example we will only select the first one `sensor_00` for simplicity."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57757b69",
      "metadata": {
        "id": "57757b69"
      },
      "source": [
        "### Explore The Data For One Sensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "53f2b312",
      "metadata": {
        "id": "53f2b312"
      },
      "outputs": [],
      "source": [
        "# Extract the readings from the BROKEN state of the pump\n",
        "broken_sensors_df = sensors_df[sensors_df[\"machine_status\"] == \"BROKEN\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "cafa18ba-2ad5-4285-a773-9648fc97188f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "cafa18ba-2ad5-4285-a773-9648fc97188f",
        "outputId": "b64c6066-480a-42ec-a111-3c57b87a7e55"
      },
      "outputs": [],
      "source": [
        "# Plot time series for each sensor with BROKEN state marked with X in red color\n",
        "plt.figure(figsize=(18, 3))\n",
        "plt.plot(\n",
        "    broken_sensors_df[\"timestamp\"],\n",
        "    broken_sensors_df[\"sensor_00\"],\n",
        "    linestyle=\"none\",\n",
        "    marker=\"X\",\n",
        "    color=\"red\",\n",
        "    markersize=12,\n",
        ")\n",
        "plt.plot(sensors_df[\"timestamp\"], sensors_df[\"sensor_00\"], color=\"blue\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69439514",
      "metadata": {
        "id": "69439514"
      },
      "source": [
        "We can see above that over time the sensor values stay generally around 2.5 with a few noisy dropoff spikes. We have plotted the column `machine_status=BROKEN` in red here which corresponds with a lot of these spikes indicating the reason for the dropoffs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c998fbc",
      "metadata": {
        "id": "1c998fbc"
      },
      "source": [
        "## 2. Create Sensor Vector Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aee5954a",
      "metadata": {
        "id": "aee5954a"
      },
      "source": [
        "Next, let's create embeddings for these values. We have chosen a simple approach that leverages the raw time series data directly, without the need for complex modelling or domain-specific expertise."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "755dc49f",
      "metadata": {
        "id": "755dc49f"
      },
      "source": [
        "### Extract One Sensors Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "663fd80b",
      "metadata": {
        "id": "663fd80b"
      },
      "outputs": [],
      "source": [
        "sensor0_df = sensors_df[[\"timestamp\", \"sensor_00\"]]\n",
        "sensor0_df = sensor0_df.reset_index(drop=True).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "b6Ave7lCNVok",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "b6Ave7lCNVok",
        "outputId": "f509aaff-9a7f-4383-9cb9-9c5599ed785e"
      },
      "outputs": [],
      "source": [
        "# This is our sensor data to be ingested into KDB.AI\n",
        "sensor0_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ninBxQZpTk4J",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ninBxQZpTk4J",
        "outputId": "ce930f45-bf8b-49a7-8a52-e051a122ae19"
      },
      "outputs": [],
      "source": [
        "sensor0_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd231f29-6435-4e9d-8732-af8d2d065c2b",
      "metadata": {
        "id": "cd231f29-6435-4e9d-8732-af8d2d065c2b"
      },
      "source": [
        "### Group The Sensor0 Values into Time Windows\n",
        "\n",
        "The code below divides the original time series data into overlapping windows, with each window containing a specified number of rows and a step size determining how they are shifted along the timeline. It also extracts a timestamp from each window as we will want to store this as metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "fe8670dc",
      "metadata": {
        "id": "fe8670dc"
      },
      "outputs": [],
      "source": [
        "# Set the window size (number of rows in each window)\n",
        "window_size = 100\n",
        "step_size = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "2ed2d459",
      "metadata": {
        "id": "2ed2d459"
      },
      "outputs": [],
      "source": [
        "# define windows\n",
        "windows = [\n",
        "    sensor0_df.iloc[i : i + window_size]\n",
        "    for i in range(0, len(sensor0_df) - window_size + 1, step_size)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "bf7e6d88",
      "metadata": {
        "id": "bf7e6d88"
      },
      "outputs": [],
      "source": [
        "# Iterate through the windows & extract column values\n",
        "start_times = [w[\"timestamp\"].iloc[0] for w in windows]\n",
        "end_times = [w[\"timestamp\"].iloc[-1] for w in windows]\n",
        "sensor0_values = [w[\"sensor_00\"].tolist() for w in windows]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "wPOuC-sFP-Sm",
      "metadata": {
        "id": "wPOuC-sFP-Sm"
      },
      "outputs": [],
      "source": [
        "# Create a new DataFrame from the collected data\n",
        "embedding_df = pd.DataFrame(\n",
        "    {\"timestamp\": start_times, \"sensor_00\": sensor0_values}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "o9iKgg0vSlrp",
      "metadata": {
        "id": "o9iKgg0vSlrp"
      },
      "outputs": [],
      "source": [
        "embedding_df = embedding_df.reset_index(drop=True).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "acf95914",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "acf95914",
        "outputId": "257194b2-1ca3-4de0-a7eb-56f7a38f80d9"
      },
      "outputs": [],
      "source": [
        "# Show the resulting DataFrame\n",
        "show_df(embedding_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "-R9FbU1SivBR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R9FbU1SivBR",
        "outputId": "cdc8fb43-a58f-4da2-d6fc-2e2e28d2f498"
      },
      "outputs": [],
      "source": [
        "# When is the first time a sensor is 'broken'?\n",
        "broken_sensors_df[\"timestamp\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f7daaa8",
      "metadata": {
        "id": "5f7daaa8"
      },
      "source": [
        "## 3. Store Embeddings in KDB.AI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd6edb73-e4c9-40c7-a295-e9063dc83e42",
      "metadata": {
        "id": "cd6edb73-e4c9-40c7-a295-e9063dc83e42"
      },
      "source": [
        "With the embeddings created, we need to store them in a vector database to enable efficient searching.\n",
        "\n",
        "### Define KDB.AI Session\n",
        "\n",
        "KDB.AI comes in two offerings:\n",
        "\n",
        "1. [KDB.AI Cloud](https://trykdb.kx.com/kdbai/signup/) - For experimenting with smaller generative AI projects with a vector database in our cloud.\n",
        "2. [KDB.AI Server](https://trykdb.kx.com/kdbaiserver/signup/) - For evaluating large scale generative AI applications on-premises or on your own cloud provider.\n",
        "\n",
        "Depending on which you use there will be different setup steps and connection details required.\n",
        "\n",
        "##### Option 1. KDB.AI Cloud\n",
        "\n",
        "To use KDB.AI Cloud, you will need two session details - a URL endpoint and an API key.\n",
        "To get these you can sign up for free [here](https://trykdb.kx.com/kdbai/signup).\n",
        "\n",
        "You can connect to a KDB.AI Cloud session using `kdbai.Session` and passing the session URL endpoint and API key details from your KDB.AI Cloud portal.\n",
        "\n",
        "If the environment variables `KDBAI_ENDPOINTS` and `KDBAI_API_KEY` exist on your system containing your KDB.AI Cloud portal details, these variables will automatically be used to connect.\n",
        "If these do not exist, it will prompt you to enter your KDB.AI Cloud portal session URL endpoint and API key details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "c4a372cd",
      "metadata": {
        "id": "c4a372cd"
      },
      "outputs": [],
      "source": [
        "KDBAI_ENDPOINT = (\n",
        "    os.environ[\"KDBAI_ENDPOINT\"]\n",
        "    if \"KDBAI_ENDPOINT\" in os.environ\n",
        "    else input(\"KDB.AI endpoint: \")\n",
        ")\n",
        "KDBAI_API_KEY = (\n",
        "    os.environ[\"KDBAI_API_KEY\"]\n",
        "    if \"KDBAI_API_KEY\" in os.environ\n",
        "    else getpass(\"KDB.AI API key: \")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "748f33c4",
      "metadata": {
        "id": "748f33c4"
      },
      "outputs": [],
      "source": [
        "session = kdbai.Session(api_key=KDBAI_API_KEY, endpoint=KDBAI_ENDPOINT)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "773ecda1",
      "metadata": {
        "id": "773ecda1"
      },
      "source": [
        "##### Option 2. KDB.AI Server\n",
        "\n",
        "To use KDB.AI Server, you will need download and run your own container.\n",
        "To do this, you will first need to sign up for free [here](https://trykdb.kx.com/kdbaiserver/signup/).\n",
        "\n",
        "You will receive an email with the required license file and bearer token needed to download your instance.\n",
        "Follow instructions in the signup email to get your session up and running.\n",
        "\n",
        "Once the [setup steps](https://code.kx.com/kdbai/gettingStarted/kdb-ai-server-setup.html) are complete you can then connect to your KDB.AI Server session using `kdbai.Session` and passing your local endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "20441109",
      "metadata": {
        "id": "20441109"
      },
      "outputs": [],
      "source": [
        "# session = kdbai.Session(endpoint=\"http://localhost:8082\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1c0b1d1",
      "metadata": {
        "id": "f1c0b1d1"
      },
      "source": [
        "### Define Vector DB Table Schema\n",
        "\n",
        "The next step is to define a schema for our KDB.AI table where we will store our embeddings. Our table will have three colums: index, timestamp, and sensor_00. Sensor_00 is where the time series embeddings will be stored and searched using Transformed Temporal Similarity Search.\n",
        "\n",
        "The key is that the 100 dimension windows will be compressed to 8 dimensions with Transformed TSS, making search much faster and significantly reducing the memory footprint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "uoF9ZEW_WCTT",
      "metadata": {
        "id": "uoF9ZEW_WCTT"
      },
      "outputs": [],
      "source": [
        "# Set up the schema and indexes for KDB.AI table, specifying embeddings column with 384 dimensions, Euclidean Distance, and flat index\n",
        "sensor_schema = [\n",
        "    {\"name\": \"index\", \"type\": \"int64\"},\n",
        "    {\"name\": \"timestamp\", \"type\": \"datetime64[ns]\"},\n",
        "    {\"name\": \"sensor_00\", \"type\": \"float64s\"}\n",
        "]\n",
        "\n",
        "indexes = [\n",
        "    {\n",
        "        \"name\": \"flat_index\",\n",
        "        \"type\": \"flat\",\n",
        "        \"column\": \"sensor_00\",\n",
        "        \"params\": {\"dims\": 8, \"metric\": \"L2\"},\n",
        "    }\n",
        "]\n",
        "\n",
        "embedding_conf = {'sensor_00': {\"dims\": 8, \"type\": \"tsc\", \"on_insert_error\": \"reject_all\" }}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e345361-a3b3-4d59-bca1-0c0c6f63f910",
      "metadata": {
        "id": "8e345361-a3b3-4d59-bca1-0c0c6f63f910"
      },
      "source": [
        "### Create Vector DB Table\n",
        "\n",
        "Use the KDB.AI `create_table` function to create a table that matches the defined schema in the vector database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "2a518fd3",
      "metadata": {
        "id": "2a518fd3"
      },
      "outputs": [],
      "source": [
        "# get the database connection. Default database name is 'default'\n",
        "database = session.database('default')\n",
        "\n",
        "# First ensure the table does not already exist\n",
        "try:\n",
        "    database.table(\"sensors\").drop()\n",
        "    time.sleep(5)\n",
        "except kdbai.KDBAIException:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "151df13c",
      "metadata": {
        "id": "151df13c"
      },
      "outputs": [],
      "source": [
        "# Create the table called \"sensors\"\n",
        "table = database.create_table(\"sensors\",\n",
        "                              schema = sensor_schema,\n",
        "                              indexes = indexes,\n",
        "                              embedding_configurations = embedding_conf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "BP-kQ5OAw1gM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "BP-kQ5OAw1gM",
        "outputId": "68fa4725-b67f-46da-a0ea-ff4c17372d27"
      },
      "outputs": [],
      "source": [
        "table.query()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f489316",
      "metadata": {
        "id": "9f489316"
      },
      "source": [
        "### Add Embedded Data to KDB.AI Table\n",
        "\n",
        "When adding larger amounts of data, you may need insert data into an index in chunks. It is a good idea to first get an idea of how large the dataset to insert is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "slWtKGGjXE4Y",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slWtKGGjXE4Y",
        "outputId": "13d95ea1-7f63-42a0-bbe6-badb18d612da"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "n = 1000  # number of rows per batch\n",
        "\n",
        "for i in tqdm(range(0, embedding_df.shape[0], n)):\n",
        "    table.insert(embedding_df[i:i+n].reset_index(drop=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f498123",
      "metadata": {
        "id": "3f498123"
      },
      "source": [
        "### Verify Data Has Been Inserted\n",
        "\n",
        "Running `table.query()` should show us that data has been added.\n",
        "\n",
        "Note that while we only see the three columns including our 100 dimension vector/time series window, the 100 dimension time series window has been compressed to 8 dimensions, and that compressed time series windows will be used for similarity search in the backend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "6b185eca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "6b185eca",
        "outputId": "5b76adca-fba6-4961-8bc0-807e4da1aec7"
      },
      "outputs": [],
      "source": [
        "show_df(table.query())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b643fd4",
      "metadata": {
        "id": "8b643fd4"
      },
      "source": [
        "## 4. Search For Similar Sequences To A Target Sensor Sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2358732",
      "metadata": {
        "id": "d2358732"
      },
      "source": [
        "Now our data is loaded successfully, we can perform pattern matching on our historical sensor data using KDB.AI `search`.\n",
        "\n",
        "### Define an Example Pattern to Query\n",
        "\n",
        "The first step is to select a pattern that will be used to query.\n",
        "\n",
        "We chose this by selecting a start time, filtering to get the vector's values for that record, and then storing this in a variable called `q`. Any pattern could be selected here.\n",
        "\n",
        "The resulting query pattern is also displayed as a line plot for visual inspection and analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "xS9ZqcDgw7oo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xS9ZqcDgw7oo",
        "outputId": "7f4a008c-9cf6-463d-dd0c-ff89d37b1523"
      },
      "outputs": [],
      "source": [
        "broken_sensors_df[\"timestamp\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j6V-1VrTQyLR",
      "metadata": {
        "id": "j6V-1VrTQyLR"
      },
      "outputs": [],
      "source": [
        "## This is our query vector, using the 17100th sliding window as an example (this is just before the first instance when the sensor is in a failed state)\n",
        "q = embedding_df['sensor_00'][17100]\n",
        "#q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "oyThHxZHxNvI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "oyThHxZHxNvI",
        "outputId": "362be697-7db2-49ac-ff58-5f565357c1df"
      },
      "outputs": [],
      "source": [
        "# Visualise the query pattern\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(embedding_df['sensor_00'][17100], marker=\"o\", linestyle=\"-\")\n",
        "plt.xlabel(\"Timestamp\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.title(\"Query & Similar Patterns\")\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels for readability\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d9a6640",
      "metadata": {},
      "source": [
        "#### Let's return the top 100 matches to this query vector to see if we can identify the other instances of a failed state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "hAqCTOiqT7Sx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "hAqCTOiqT7Sx",
        "outputId": "73178590-613d-4528-d484-8e9f38b7620d"
      },
      "outputs": [],
      "source": [
        "nn1_result = table.search(vectors={'flat_index': [q]}, n=100, filter=[(\">\",\"index\", 18000)])\n",
        "nn1_result[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6769cc80",
      "metadata": {},
      "source": [
        "#### Since every timestamp/row has a 100 dimension window, we will have matches that are close to one another and are matching upon the same 'anomaly' pattern. To ensure we are returning only unique pattern matches we will remove any matches within a range of 200 points from our next closest match. This will ensure we are only capturing each potential failed state one time within our final results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "nGZ7tqyvm9MY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGZ7tqyvm9MY",
        "outputId": "4c144c37-9702-430c-eb1a-531869a00af3"
      },
      "outputs": [],
      "source": [
        "def filter_results(df, range_size=200):\n",
        "\n",
        "    final_results = []\n",
        "    removed_indices = set()\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        current_index = row['index']\n",
        "\n",
        "        # If this index hasn't been removed\n",
        "        if current_index not in removed_indices:\n",
        "            final_results.append(row)\n",
        "\n",
        "            # Mark indices within range for removal\n",
        "            lower_bound = max(0, current_index - range_size // 2)\n",
        "            upper_bound = current_index + range_size // 2\n",
        "            removed_indices.update(range(lower_bound, upper_bound + 1))\n",
        "\n",
        "    # Create a new dataframe from the final results\n",
        "    final_df = pd.DataFrame(final_results)\n",
        "\n",
        "    return final_df\n",
        "\n",
        "filtered_df = filter_results(nn1_result[0])\n",
        "\n",
        "# Display the filtered results\n",
        "print(filtered_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0ed5417",
      "metadata": {},
      "source": [
        "#### For our reference, these are all of the times when the sensor returns a failed state:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "oWyeUYjUjhzG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWyeUYjUjhzG",
        "outputId": "5a205e5a-14a2-4ec3-e599-8205ccab625b"
      },
      "outputs": [],
      "source": [
        "broken_sensors_df[\"timestamp\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b2b5081",
      "metadata": {},
      "source": [
        "### Results:\n",
        "\n",
        "We see that our final results closely capture each of the timestamps of the failed states within a few indexes. There is only one captured pattern that is not within the failed states: 110667. If you go back near the beginning of this notebook you will see within the pattern a large drop in the signal near this index - this could show a time that needs to be investigated as a potential missed failed state. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85686375",
      "metadata": {},
      "source": [
        "## Visualize the matching patterns of other 'failed' states:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "yUeWeCsZyBvi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "yUeWeCsZyBvi",
        "outputId": "82527ed4-eff2-4e4d-f375-7f48513fd861"
      },
      "outputs": [],
      "source": [
        "for i in filtered_df['index']:\n",
        "    plt.plot(embedding_df['sensor_00'][i], marker=\"o\", linestyle=\"-\")\n",
        "plt.xlabel(\"Timestamp\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.title(\"Query & Similar Patterns\")\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels for readability\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7bdd5d5",
      "metadata": {
        "id": "c7bdd5d5"
      },
      "source": [
        "## 5. Delete the KDB.AI Table\n",
        "\n",
        "Once finished with the table, it is best practice to drop it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84213681",
      "metadata": {
        "id": "84213681",
        "outputId": "745a9807-9557-4238-82bb-1102f95c6f00"
      },
      "outputs": [],
      "source": [
        "table.drop()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6078c94e",
      "metadata": {
        "id": "6078c94e"
      },
      "source": [
        "## Take Our Survey\n",
        "\n",
        "We hope you found this sample helpful! Your feedback is important to us, and we would appreciate it if you could take a moment to fill out our brief survey. Your input helps us improve our content.\n",
        "\n",
        "[**Take the Survey**](https://delighted.com/t/go0ElNsJ)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
