{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cccbf27b-625b-4ba2-aa93-2ad45e9c1738",
   "metadata": {},
   "source": [
    "### KX Advanced RAG with CUDF, NeMo and NIM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2385ee77-a868-4823-9b5c-6ae8243003ea",
   "metadata": {},
   "source": [
    "We have developed an KX Advanced RAG using NVIDIA's RAPIDS, NeMo and NIM Framework.  \n",
    "This RAG demostration uses KX software integrated with latest NVIDIA GPU's and tech stack to answer some of the most industry curated queries with utmost speed and accuracy also providing references.\n",
    "\n",
    "Process:\n",
    "1. The data is from over 2.5 million documents which can be downloaded in the JSON format from here - https://www.kaggle.com/datasets/Cornell-University/arxiv\n",
    "2. Data processing has been done using RAPIDS cuDF.\n",
    "3. Embedding have been generated using NeMo Retriever and ingested it into our KDB.AI Vector DB.\n",
    "4. Additionally we have used NIM (NVIDIA Inferencing Microservices) LLM's to for the RAG Q&A.\n",
    "\n",
    "Prerequisites:  \n",
    "1. KDB.AI - https://code.kx.com/kdbai/latest\n",
    "2. NVIDIA GPU with Drivers and toolkit - https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html\n",
    "3. NVIDIA RAPIDS - https://docs.rapids.ai/install/\n",
    "4. NVIDIA NIM LLM Setup - https://docs.nvidia.com/nim/large-language-models/latest/getting-started.html\n",
    "5. NVIDIA NeMo Retriever Setup - https://docs.nvidia.com/nim/nemo-retriever/text-embedding/latest/getting-started.html\n",
    "\n",
    "Models:\n",
    "1. Emebedding - nv-embedqa-e5-v5 (pre fine-tuned by NVIDIA)\n",
    "2. LLM - llama-3.1-70b-instruct (inferenced and optimized by NVIDIA NIM)\n",
    "\n",
    "A detailed architecture and setup instruction document is provided separately as well for reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ad7b08-268a-4fb8-970f-da64d514dd87",
   "metadata": {},
   "source": [
    "### Loading modules\n",
    "\n",
    "In case KDB+ along with qflat is being used in place of KDB.AI, please make sure the files qflat.so and qflat.q are present in the pwd.  \n",
    "Below there is a reference to ollama and sentence_tranformers in case anyone wants to use this RAG with open source embedding and LLM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e14d6c-fb22-499f-8d34-1e3b697c92b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import cudf\n",
    "import kdbai_client as kdbai\n",
    "\n",
    "from openai import OpenAI\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from typing import List\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98462c20-12aa-4f7a-acdb-dc68a672fe8e",
   "metadata": {},
   "source": [
    "### Defining Arguments\n",
    "\n",
    "The input dataset from arxiv needs to be present in the data folder in the current directory.  \n",
    "Emebdding and LLM models along with the preferred batch size and other details are preset here.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e076014-ce0d-47ff-b58e-63cb2daa0f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'data/arxiv-metadata-oai-snapshot.json'\n",
    "LIMIT = None\n",
    "EMBEDDING = 'nvidia/nv-embedqa-e5-v5'\n",
    "DEVICE = 'cuda'\n",
    "BATCH_SIZE = 8191\n",
    "LLM = 'meta/llama-3.1-70b-instruct'\n",
    "TEMPERATURE = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942967db-9ce0-4125-8aec-ade6b1bba74c",
   "metadata": {},
   "source": [
    "### Resetting the knowledge database if needed\n",
    "\n",
    "RESET parameter is used to recreate the data and embeddings from the input json data and store it in the database, when set to True.  \n",
    "If the data and embeddings are already created and stored, this parameter can be set to False to avoid recreating the data which takes time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33653f34-ddd4-43af-bd1a-6aae538dd24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESET = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3976264-c10a-454f-9558-b37ae4fec36b",
   "metadata": {},
   "source": [
    "### Load the ArXiv research paper dataset from JSON into a Pandas dataframe\n",
    "\n",
    "Here we have used RAPIDS cuDF to create a dataframe for the input data which enhances the processing speed by three times.  \n",
    "We have encoded the string columns to make it more memory efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "453298a9-c356-4ddc-88f9-d5bb9f2a0aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37 s, sys: 10.7 s, total: 47.7 s\n",
      "Wall time: 47.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if RESET:\n",
    "    COLS = ['id', 'update_date', 'submitter', 'authors', 'title', 'categories', 'abstract']\n",
    "    df = cudf.read_json(DATASET, orient='records', lines=True).sort_values('update_date', ascending=False)[COLS]\n",
    "    df['update_date'] = cudf.to_datetime(df['update_date'])\n",
    "    texts = []\n",
    "    for record in df.to_dict('records'):\n",
    "        texts.append(\"Title: %s\\nDate: %s\\nAuthors: %s\\nAbstract: %s\\n\" % (record['title'], record['update_date'], record['authors'], record['abstract']))\n",
    "    df['text'] = texts\n",
    "    df = df.iloc[:LIMIT].reset_index(drop=True)\n",
    "    df = df.to_pandas()\n",
    "    for c in df.columns:\n",
    "        if type(df[c].iloc[0]) is str:\n",
    "            df[c] = df[c].str.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8d9118f-a9f1-4073-b827-468a69c6bdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2530760 entries, 0 to 2530759\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Dtype         \n",
      "---  ------       -----         \n",
      " 0   id           object        \n",
      " 1   update_date  datetime64[ns]\n",
      " 2   year         int32         \n",
      " 3   submitter    object        \n",
      " 4   authors      object        \n",
      " 5   title        object        \n",
      " 6   categories   object        \n",
      " 7   abstract     object        \n",
      " 8   text         object        \n",
      "dtypes: datetime64[ns](1), int32(1), object(7)\n",
      "memory usage: 164.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create the 'year' column from 'update_date'\n",
    "df['year'] = df['update_date'].dt.year\n",
    "\n",
    "# Reorder the columns to place 'year' as the 3rd column\n",
    "cols = list(df.columns)\n",
    "cols.insert(2, cols.pop(cols.index('year')))\n",
    "df = df[cols]\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29ef8ac6-3229-4e74-84bb-3ca80d6a050e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>update_date</th>\n",
       "      <th>year</th>\n",
       "      <th>submitter</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'1209.2995'</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>2024</td>\n",
       "      <td>b'Leonid Positselski'</td>\n",
       "      <td>b'Leonid Positselski'</td>\n",
       "      <td>b'Contraherent cosheaves on schemes'</td>\n",
       "      <td>b'math.CT math.AG'</td>\n",
       "      <td>b'  Contraherent cosheaves are globalizations ...</td>\n",
       "      <td>b'Title: Contraherent cosheaves on schemes\\nDa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'1301.6261'</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>2024</td>\n",
       "      <td>b'Ruslan Maksimau'</td>\n",
       "      <td>b'Ruslan Maksimau'</td>\n",
       "      <td>b'Canonical basis, KLR-algebras and parity she...</td>\n",
       "      <td>b'math.RT'</td>\n",
       "      <td>b'  We give a construction of a basis of the p...</td>\n",
       "      <td>b'Title: Canonical basis, KLR-algebras and par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'1307.6013'</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>2024</td>\n",
       "      <td>b'Ruslan Maksimau'</td>\n",
       "      <td>b'Ruslan Maksimau'</td>\n",
       "      <td>b'Quiver Schur algebras and Koszul duality'</td>\n",
       "      <td>b'math.RT'</td>\n",
       "      <td>b'  We prove that the category of graded finit...</td>\n",
       "      <td>b'Title: Quiver Schur algebras and Koszul dual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'1511.03484'</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>2024</td>\n",
       "      <td>b'Oleg Andreev'</td>\n",
       "      <td>b'Oleg Andreev'</td>\n",
       "      <td>b'Some Aspects of Three-Quark Potentials'</td>\n",
       "      <td>b'hep-ph hep-lat hep-th nucl-th'</td>\n",
       "      <td>b'  We analytically evaluate the expectation v...</td>\n",
       "      <td>b'Title: Some Aspects of Three-Quark Potential...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'1607.01080'</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>2024</td>\n",
       "      <td>b'Robert Szczelina'</td>\n",
       "      <td>b\"Robert Szczelina and Piotr Zgliczy\\\\'nski\"</td>\n",
       "      <td>b'Algorithm for rigorous integration of Delay ...</td>\n",
       "      <td>b'math.DS'</td>\n",
       "      <td>b\"  We present an algorithm for the rigorous i...</td>\n",
       "      <td>b\"Title: Algorithm for rigorous integration of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id update_date  year              submitter  \\\n",
       "0   b'1209.2995'  2024-07-26  2024  b'Leonid Positselski'   \n",
       "1   b'1301.6261'  2024-07-26  2024     b'Ruslan Maksimau'   \n",
       "2   b'1307.6013'  2024-07-26  2024     b'Ruslan Maksimau'   \n",
       "3  b'1511.03484'  2024-07-26  2024        b'Oleg Andreev'   \n",
       "4  b'1607.01080'  2024-07-26  2024    b'Robert Szczelina'   \n",
       "\n",
       "                                        authors  \\\n",
       "0                         b'Leonid Positselski'   \n",
       "1                            b'Ruslan Maksimau'   \n",
       "2                            b'Ruslan Maksimau'   \n",
       "3                               b'Oleg Andreev'   \n",
       "4  b\"Robert Szczelina and Piotr Zgliczy\\\\'nski\"   \n",
       "\n",
       "                                               title  \\\n",
       "0               b'Contraherent cosheaves on schemes'   \n",
       "1  b'Canonical basis, KLR-algebras and parity she...   \n",
       "2        b'Quiver Schur algebras and Koszul duality'   \n",
       "3          b'Some Aspects of Three-Quark Potentials'   \n",
       "4  b'Algorithm for rigorous integration of Delay ...   \n",
       "\n",
       "                         categories  \\\n",
       "0                b'math.CT math.AG'   \n",
       "1                        b'math.RT'   \n",
       "2                        b'math.RT'   \n",
       "3  b'hep-ph hep-lat hep-th nucl-th'   \n",
       "4                        b'math.DS'   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  b'  Contraherent cosheaves are globalizations ...   \n",
       "1  b'  We give a construction of a basis of the p...   \n",
       "2  b'  We prove that the category of graded finit...   \n",
       "3  b'  We analytically evaluate the expectation v...   \n",
       "4  b\"  We present an algorithm for the rigorous i...   \n",
       "\n",
       "                                                text  \n",
       "0  b'Title: Contraherent cosheaves on schemes\\nDa...  \n",
       "1  b'Title: Canonical basis, KLR-algebras and par...  \n",
       "2  b'Title: Quiver Schur algebras and Koszul dual...  \n",
       "3  b'Title: Some Aspects of Three-Quark Potential...  \n",
       "4  b\"Title: Algorithm for rigorous integration of...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb57100f-9fcc-425b-a6b1-4a21ec78cc44",
   "metadata": {},
   "source": [
    "### Setup for NeMo Retriever Embedding\n",
    "\n",
    "Here we create a function to call the NeMo Retriever Embedding model which is prehosted locally and calling the API reference  \n",
    "The model used NV-EmbedQA-E5-v5 which is one of the most advanced pre-tuned model from NVIDIA with an average reacall of 62.07%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61168f30-ad5a-43c4-9068-62099af9b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "nemoClient = OpenAI(\n",
    "  api_key=\"no-key-required\",\n",
    "  base_url=\"http://0.0.0.0:8001/v1\"\n",
    ")\n",
    "\n",
    "def get_embedding(text, model=\"nvidia/nv-embedqa-e5-v5\"):\n",
    "   return nemoClient.embeddings.create(input = [text], model=model, extra_body={\"input_type\": \"query\", \"truncate\": \"END\"}).data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6342e09-1827-4e79-9ca4-2800411c49bd",
   "metadata": {},
   "source": [
    "### Embed the text (title, authors, date, abstract) for each research paper\n",
    "\n",
    "Below we generate the dense embeddings using the above model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13c8ec30-f259-467d-b95d-988d6485c625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.34 s, sys: 0 ns, total: 1.34 s\n",
      "Wall time: 1.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df['text']= df['text'].str.decode('utf-8')\n",
    "\n",
    "# This step decodes the text column from thich embeddings need to be created before sending it to the Nemo Retriver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c54fb98-105c-416b-b838-59d2ed4773c7",
   "metadata": {},
   "source": [
    "#### Creating Function to generate embeddings in batches\n",
    "\n",
    "Here we create a function to generate embeddings from the text column in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "066d2039-3411-4235-8b84-4c6662ca4063",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingProcessor:\n",
    "    def __init__(self, \n",
    "                 batch_size: int = 2,\n",
    "                 concurrency: int = 32,\n",
    "                 api_key=\"no-key-required\",\n",
    "                 base_url: str = \"http://0.0.0.0:8001/v1\"):\n",
    "        self.batch_size = batch_size\n",
    "        self.semaphore = asyncio.Semaphore(concurrency)\n",
    "        self.client = AsyncOpenAI(base_url=base_url,api_key=api_key)\n",
    "        self.start_time = time.time()\n",
    "        self.processed_count = 0\n",
    "        self.latencies = []\n",
    "\n",
    "    async def process_batch(self, batch: List[str]):\n",
    "        \n",
    "        async with self.semaphore:  # Control concurrent requests\n",
    "            start_time = time.time()\n",
    "            try:\n",
    "                response = await self.client.embeddings.create(\n",
    "                    input=batch,\n",
    "                    model=\"nvidia/nv-embedqa-e5-v5\",\n",
    "                    encoding_format=\"float\",\n",
    "                    extra_body={\"input_type\": \"query\", \"truncate\": \"END\"}\n",
    "                )\n",
    "                end_time = time.time()\n",
    "                self.latencies.append((end_time - start_time) * 1000)\n",
    "                self.processed_count += len(batch)\n",
    "                \n",
    "                if self.processed_count % 100000 == 0:\n",
    "                    elapsed = time.time() - self.start_time\n",
    "                    throughput = self.processed_count / elapsed\n",
    "                    print(f\"Processed {self.processed_count} texts. Throughput: {throughput:.2f} texts/sec\")\n",
    "                \n",
    "                return [emb.embedding for emb in response.data]\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing batch: {e}\")\n",
    "                return None\n",
    "\n",
    "    async def process_dataframe(self, df: pd.DataFrame):\n",
    "        batches = [df[i:i + self.batch_size]['text'].tolist() \n",
    "                  for i in range(0, len(df), self.batch_size)]\n",
    "\n",
    "        tasks = [self.process_batch(batch) for batch in batches]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        throughput = self.processed_count / elapsed_time\n",
    "        \n",
    "        print(\"\\nPerformance Summary:\")\n",
    "        print(f\"Total texts processed: {self.processed_count}\")\n",
    "        print(f\"Total time: {elapsed_time:.2f} seconds\")\n",
    "        print(f\"Average throughput: {throughput:.2f} texts/second\")\n",
    "        print(f\"Average latency: {np.mean(self.latencies):.2f} ms\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "async def main():\n",
    "    processor = EmbeddingProcessor(\n",
    "        batch_size=32,\n",
    "        concurrency=64,\n",
    "        api_key=\"no-key-required\",\n",
    "        base_url=\"http://0.0.0.0:8001/v1\"\n",
    "    )\n",
    "    \n",
    "    embeddings = await processor.process_dataframe(df)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70555cd3-1105-41fc-81dc-35fd656ded78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100000 texts. Throughput: 363.81 texts/sec\n",
      "Processed 200000 texts. Throughput: 367.02 texts/sec\n",
      "Processed 300000 texts. Throughput: 367.54 texts/sec\n",
      "Processed 400000 texts. Throughput: 367.12 texts/sec\n",
      "Processed 500000 texts. Throughput: 366.48 texts/sec\n",
      "Processed 600000 texts. Throughput: 365.63 texts/sec\n",
      "Processed 700000 texts. Throughput: 364.61 texts/sec\n",
      "Processed 800000 texts. Throughput: 364.85 texts/sec\n",
      "Processed 900000 texts. Throughput: 363.74 texts/sec\n",
      "Processed 1000000 texts. Throughput: 363.78 texts/sec\n",
      "Processed 1100000 texts. Throughput: 362.59 texts/sec\n",
      "Processed 1200000 texts. Throughput: 362.22 texts/sec\n",
      "Processed 1300000 texts. Throughput: 360.57 texts/sec\n",
      "Processed 1400000 texts. Throughput: 360.29 texts/sec\n",
      "Processed 1500000 texts. Throughput: 358.67 texts/sec\n",
      "Processed 1600000 texts. Throughput: 358.41 texts/sec\n",
      "Processed 1700000 texts. Throughput: 358.15 texts/sec\n",
      "Processed 1800000 texts. Throughput: 357.89 texts/sec\n",
      "Processed 1900000 texts. Throughput: 357.61 texts/sec\n",
      "Processed 2000000 texts. Throughput: 356.11 texts/sec\n",
      "Processed 2100000 texts. Throughput: 355.80 texts/sec\n",
      "Processed 2200000 texts. Throughput: 355.48 texts/sec\n",
      "Processed 2300000 texts. Throughput: 355.10 texts/sec\n",
      "Processed 2400000 texts. Throughput: 354.74 texts/sec\n",
      "Processed 2500000 texts. Throughput: 354.39 texts/sec\n",
      "\n",
      "Performance Summary:\n",
      "Total texts processed: 2530760\n",
      "Total time: 7136.16 seconds\n",
      "Average throughput: 354.64 texts/second\n",
      "Average latency: 4645.73 ms\n",
      "CPU times: user 1h 58min 40s, sys: 1min 4s, total: 1h 59min 44s\n",
      "Wall time: 1h 58min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "results = asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8674f8-3e01-4626-850e-1ddd8b3b548f",
   "metadata": {},
   "source": [
    "#### Storing embeddings in the dataframe\n",
    "\n",
    "Here we save the embeddings created above into the dataframe as a embeddings column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb7441e1-f9ad-43d9-8d00-8cc6996d73c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 9s, sys: 6.91 s, total: 1min 16s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df['embeddings'] = [item for sublist in results for item in sublist]\n",
    "df['embeddings'] = [np.array(x) for x in df['embeddings']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa9303c-fce3-48d2-97ee-137a51171244",
   "metadata": {},
   "source": [
    "#### Encoding back the text column in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cea7a3a3-46b7-4130-abb3-66901fa2913d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.34 s, sys: 674 ms, total: 2.02 s\n",
      "Wall time: 2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>update_date</th>\n",
       "      <th>year</th>\n",
       "      <th>submitter</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract</th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'1209.2995'</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>2024</td>\n",
       "      <td>b'Leonid Positselski'</td>\n",
       "      <td>b'Leonid Positselski'</td>\n",
       "      <td>b'Contraherent cosheaves on schemes'</td>\n",
       "      <td>b'math.CT math.AG'</td>\n",
       "      <td>b'  Contraherent cosheaves are globalizations ...</td>\n",
       "      <td>b'Title: Contraherent cosheaves on schemes\\nDa...</td>\n",
       "      <td>[-0.0279541015625, 0.03924560546875, 0.0154342...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'1301.6261'</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>2024</td>\n",
       "      <td>b'Ruslan Maksimau'</td>\n",
       "      <td>b'Ruslan Maksimau'</td>\n",
       "      <td>b'Canonical basis, KLR-algebras and parity she...</td>\n",
       "      <td>b'math.RT'</td>\n",
       "      <td>b'  We give a construction of a basis of the p...</td>\n",
       "      <td>b'Title: Canonical basis, KLR-algebras and par...</td>\n",
       "      <td>[0.009613037109375, -0.037689208984375, -0.026...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'1307.6013'</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>2024</td>\n",
       "      <td>b'Ruslan Maksimau'</td>\n",
       "      <td>b'Ruslan Maksimau'</td>\n",
       "      <td>b'Quiver Schur algebras and Koszul duality'</td>\n",
       "      <td>b'math.RT'</td>\n",
       "      <td>b'  We prove that the category of graded finit...</td>\n",
       "      <td>b'Title: Quiver Schur algebras and Koszul dual...</td>\n",
       "      <td>[-0.0078887939453125, 0.005535125732421875, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'1511.03484'</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>2024</td>\n",
       "      <td>b'Oleg Andreev'</td>\n",
       "      <td>b'Oleg Andreev'</td>\n",
       "      <td>b'Some Aspects of Three-Quark Potentials'</td>\n",
       "      <td>b'hep-ph hep-lat hep-th nucl-th'</td>\n",
       "      <td>b'  We analytically evaluate the expectation v...</td>\n",
       "      <td>b'Title: Some Aspects of Three-Quark Potential...</td>\n",
       "      <td>[0.0433349609375, -0.030487060546875, 0.041198...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'1607.01080'</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>2024</td>\n",
       "      <td>b'Robert Szczelina'</td>\n",
       "      <td>b\"Robert Szczelina and Piotr Zgliczy\\\\'nski\"</td>\n",
       "      <td>b'Algorithm for rigorous integration of Delay ...</td>\n",
       "      <td>b'math.DS'</td>\n",
       "      <td>b\"  We present an algorithm for the rigorous i...</td>\n",
       "      <td>b\"Title: Algorithm for rigorous integration of...</td>\n",
       "      <td>[0.0171356201171875, -0.00780487060546875, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id update_date  year              submitter  \\\n",
       "0   b'1209.2995'  2024-07-26  2024  b'Leonid Positselski'   \n",
       "1   b'1301.6261'  2024-07-26  2024     b'Ruslan Maksimau'   \n",
       "2   b'1307.6013'  2024-07-26  2024     b'Ruslan Maksimau'   \n",
       "3  b'1511.03484'  2024-07-26  2024        b'Oleg Andreev'   \n",
       "4  b'1607.01080'  2024-07-26  2024    b'Robert Szczelina'   \n",
       "\n",
       "                                        authors  \\\n",
       "0                         b'Leonid Positselski'   \n",
       "1                            b'Ruslan Maksimau'   \n",
       "2                            b'Ruslan Maksimau'   \n",
       "3                               b'Oleg Andreev'   \n",
       "4  b\"Robert Szczelina and Piotr Zgliczy\\\\'nski\"   \n",
       "\n",
       "                                               title  \\\n",
       "0               b'Contraherent cosheaves on schemes'   \n",
       "1  b'Canonical basis, KLR-algebras and parity she...   \n",
       "2        b'Quiver Schur algebras and Koszul duality'   \n",
       "3          b'Some Aspects of Three-Quark Potentials'   \n",
       "4  b'Algorithm for rigorous integration of Delay ...   \n",
       "\n",
       "                         categories  \\\n",
       "0                b'math.CT math.AG'   \n",
       "1                        b'math.RT'   \n",
       "2                        b'math.RT'   \n",
       "3  b'hep-ph hep-lat hep-th nucl-th'   \n",
       "4                        b'math.DS'   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  b'  Contraherent cosheaves are globalizations ...   \n",
       "1  b'  We give a construction of a basis of the p...   \n",
       "2  b'  We prove that the category of graded finit...   \n",
       "3  b'  We analytically evaluate the expectation v...   \n",
       "4  b\"  We present an algorithm for the rigorous i...   \n",
       "\n",
       "                                                text  \\\n",
       "0  b'Title: Contraherent cosheaves on schemes\\nDa...   \n",
       "1  b'Title: Canonical basis, KLR-algebras and par...   \n",
       "2  b'Title: Quiver Schur algebras and Koszul dual...   \n",
       "3  b'Title: Some Aspects of Three-Quark Potential...   \n",
       "4  b\"Title: Algorithm for rigorous integration of...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.0279541015625, 0.03924560546875, 0.0154342...  \n",
       "1  [0.009613037109375, -0.037689208984375, -0.026...  \n",
       "2  [-0.0078887939453125, 0.005535125732421875, 0....  \n",
       "3  [0.0433349609375, -0.030487060546875, 0.041198...  \n",
       "4  [0.0171356201171875, -0.00780487060546875, -0....  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df['text'] = df['text'].str.encode('utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df40f42-edf9-4017-b24a-29ad63fe6dd7",
   "metadata": {},
   "source": [
    "### Saving / Loading Parquet File Holding DF Embeddings\n",
    "\n",
    "Following methods are used to save the dataframe with embeddings into parquet file created and also to load the saved parquet file reference.  \n",
    "Since the dataset is huge and embedding creation using the most advanced models takes time, so this helps save time to recreate the same dataset all over again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319e1535-3d64-43b4-af53-328adb78566d",
   "metadata": {},
   "source": [
    "#### Saving the DF into parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0adfd38b-f283-4ce7-981e-e2ee102fc3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 34s, sys: 30.2 s, total: 2min 4s\n",
      "Wall time: 2min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "file_path = 'data/KXA_NeMo_Embeddings.parquet'\n",
    "df.to_parquet(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d6f7f8-0afc-406e-99b3-b695e66aea22",
   "metadata": {},
   "source": [
    "#### Loading the Parquet File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e463419-499b-40ef-bcc0-2e085b6affba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 15.1 s, total: 1min 19s\n",
      "Wall time: 41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "parquet_file_name = \"data/KXA_NeMo_Embeddings.parquet\"\n",
    "df = pq.read_table(parquet_file_name).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6092aa1-4777-48a7-ae0b-99b36147ae12",
   "metadata": {},
   "source": [
    "### Setup for KDB.AI\n",
    "\n",
    "Defining and Loading the KDB.AI session  \n",
    "Creating the schema KX_RAG_NVIDIA for generating the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa3a286-8d5e-4d16-b7bb-b38338eec924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KDBAI table \"kxRagDocs_qflat_full\", KDBAI table \"kxRagDocs_qhnsw_full\", KDBAI table \"kxRagDocs_qhnsw\"]\n"
     ]
    }
   ],
   "source": [
    "session = kdbai.Session(endpoint='http://localhost:8083')\n",
    "db = session.database('KX_RAG_NVIDIA')\n",
    "print(db.tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997f14b2-2466-4551-86fe-fcd1b17c136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure no database called KX_RAG_NVIDIA exists\n",
    "if RESET:\n",
    "    try:\n",
    "        session.database(\"KX_RAG_NVIDIA\").drop()\n",
    "    except kdbai.KDBAIException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d2d333-fae6-4ccc-9bed-2e236bdc0bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Create the database\n",
    "if RESET:\n",
    "    db = session.create_database(\"KX_RAG_NVIDIA\")\n",
    "    print(db.tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16d31f9-c4d4-4873-9c56-f1f51577ef64",
   "metadata": {},
   "source": [
    "### Defining Schema and Creating KDB.AI Table\n",
    "\n",
    "Here we define the schema of the table and the qflat index details  \n",
    "Next we check for the pre-existing table and drop in case we want to re-create it based on the RESET parameter\n",
    "Finally we generate the table with the defined schema and index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "568cd3cf-e0bb-41e9-8aa4-1662c7c7504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the schema\n",
    "kxRagDocs_schema = [\n",
    "            {\"name\": \"id\", \"type\": \"bytes\"},\n",
    "            {\"name\": \"update_date\", \"type\": \"datetime64[ns]\"},\n",
    "            {\"name\": \"year\", \"type\": \"int16\"},\n",
    "            {\"name\": \"submitter\", \"type\": \"bytes\"},\n",
    "            {\"name\": \"authors\", \"type\": \"bytes\"},\n",
    "            {\"name\": \"title\", \"type\": \"bytes\"},\n",
    "            {\"name\": \"categories\", \"type\": \"bytes\"},\n",
    "            {\"name\": \"abstract\", \"type\": \"bytes\"},\n",
    "            {\"name\": \"text\", \"type\": \"str\"},\n",
    "            {\"name\": \"embeddings\", \"type\": \"float32s\"},\n",
    "         ]\n",
    "\n",
    "# Define the qflat index\n",
    "qflat_ind = [\n",
    "    {\n",
    "        'name': 'qflat_index',\n",
    "        'type': 'qFlat',\n",
    "        'column': 'embeddings',\n",
    "        'params': {'dims': 1024, 'metric': 'L2'},\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "492c1991-f83b-488c-a25f-b8ae1aacd239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First ensure the table does not already exist\n",
    "if RESET:\n",
    "    try:\n",
    "        db.table(\"kxRagDocs_qflat_full\").drop()\n",
    "    except kdbai.KDBAIException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fb5eecfb-b46c-4f28-8fe4-f7be869ad890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, update_date, year, submitter, authors, title, categories, abstract, text, embeddings]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Create the table and print the schema\n",
    "if RESET:\n",
    "    table_flat = db.create_table(table=\"kxRagDocs_qflat_full\", schema=kxRagDocs_schema, indexes=qflat_ind)\n",
    "    print(table_qflat.query())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9304cabd-74d6-4b47-80f7-41b8aa39b0cb",
   "metadata": {},
   "source": [
    "### Loading the data into KDB.AI table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c9502a0a-5e02-4e1c-b6b4-05e8b8526bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:37<00:00, 52.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 2s, sys: 36.2 s, total: 2min 38s\n",
      "Wall time: 2min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if RESET:\n",
    "    batch_size = 1_000_000\n",
    "    for i in tqdm(range(0, len(df), batch_size)):\n",
    "        batch = df[i:i + batch_size]\n",
    "        table_qflat.insert(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1650e16f-4d4a-40b1-a01b-eece96360f2e",
   "metadata": {},
   "source": [
    "### Calling the KDB.AI table into the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5fb523b8-2fc5-4ce8-b1c3-4370cb2fd940",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = db.table(\"kxRagDocs_qflat_full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a103ef-0ce9-4701-8bec-f5502282524a",
   "metadata": {},
   "source": [
    "### Creating Embeddings and querying the table\n",
    "\n",
    "First we create embeddings from a text we pass and then search the table with nearest neighbours set to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c4de8fee-c4f2-4f7d-befd-2df2c634ea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = get_embedding(\"I am running a Hedge Fund, tell me how to generate alpha with Streaming Analytics and AI applied on structured data (market tick data) and unstructured data (news feeds, twitter, 10-K reports...) ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "df5061ed-6077-44e3-9488-9333a93deb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.4 s, sys: 2.59 s, total: 18 s\n",
      "Wall time: 17.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__nn_distance</th>\n",
       "      <th>id</th>\n",
       "      <th>update_date</th>\n",
       "      <th>year</th>\n",
       "      <th>submitter</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract</th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.005645</td>\n",
       "      <td>b'2401.05337'</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>2024</td>\n",
       "      <td>b'Pierre Renucci'</td>\n",
       "      <td>b'Pierre Renucci'</td>\n",
       "      <td>b'Optimal Linear Signal: An Unsupervised Machi...</td>\n",
       "      <td>b'q-fin.ST cs.LG'</td>\n",
       "      <td>b\"  This study presents an unsupervised machin...</td>\n",
       "      <td>Title: Optimal Linear Signal: An Unsupervised ...</td>\n",
       "      <td>[0.040924072, 0.020080566, -0.030319214, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.014038</td>\n",
       "      <td>b'2310.05551'</td>\n",
       "      <td>2024-04-25</td>\n",
       "      <td>2024</td>\n",
       "      <td>b'Yushi Cao'</td>\n",
       "      <td>b'Zhiming Li, Junzhe Jiang, Yushi Cao, Aixin C...</td>\n",
       "      <td>b'PST: Improving Quantitative Trading via Prog...</td>\n",
       "      <td>b'cs.CE cs.AI cs.PL'</td>\n",
       "      <td>b'  Deep reinforcement learning (DRL) has revo...</td>\n",
       "      <td>Title: PST: Improving Quantitative Trading via...</td>\n",
       "      <td>[0.016921997, 0.009155273, -0.040527344, 0.012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.019814</td>\n",
       "      <td>b'2405.02302'</td>\n",
       "      <td>2024-05-07</td>\n",
       "      <td>2024</td>\n",
       "      <td>b'Ravi Kashyap'</td>\n",
       "      <td>b'Ravi Kashyap'</td>\n",
       "      <td>b'The Democratization of Wealth Management: He...</td>\n",
       "      <td>b'cs.CR q-fin.CP q-fin.PM q-fin.RM q-fin.TR'</td>\n",
       "      <td>b'  We develop several innovations designed to...</td>\n",
       "      <td>Title: The Democratization of Wealth Managemen...</td>\n",
       "      <td>[0.008140564, -0.0058517456, 0.013183594, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.023954</td>\n",
       "      <td>b'2402.18485'</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>2024</td>\n",
       "      <td>b'Wentao Zhang'</td>\n",
       "      <td>b'Wentao Zhang, Lingxuan Zhao, Haochong Xia, S...</td>\n",
       "      <td>b'A Multimodal Foundation Agent for Financial ...</td>\n",
       "      <td>b'q-fin.TR cs.AI'</td>\n",
       "      <td>b\"  Financial trading is a crucial component o...</td>\n",
       "      <td>Title: A Multimodal Foundation Agent for Finan...</td>\n",
       "      <td>[0.029037476, -0.0009021759, -0.00024068356, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.032185</td>\n",
       "      <td>b'2403.12285'</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>2024</td>\n",
       "      <td>b'Giorgos Iacovides'</td>\n",
       "      <td>b'Thanos Konstantinidis, Giorgos Iacovides, Mi...</td>\n",
       "      <td>b'FinLlama: Financial Sentiment Classification...</td>\n",
       "      <td>b'cs.CL cs.LG q-fin.ST q-fin.TR'</td>\n",
       "      <td>b\"  There are multiple sources of financial ne...</td>\n",
       "      <td>Title: FinLlama: Financial Sentiment Classific...</td>\n",
       "      <td>[0.0047569275, 0.0149383545, -0.016433716, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.039879</td>\n",
       "      <td>b'2402.12659'</td>\n",
       "      <td>2024-06-21</td>\n",
       "      <td>2024</td>\n",
       "      <td>b'Qianqian Xie'</td>\n",
       "      <td>b'Qianqian Xie, Weiguang Han, Zhengyu Chen, Ru...</td>\n",
       "      <td>b'FinBen: A Holistic Financial Benchmark for L...</td>\n",
       "      <td>b'cs.CL cs.AI cs.CE'</td>\n",
       "      <td>b\"  LLMs have transformed NLP and shown promis...</td>\n",
       "      <td>Title: FinBen: A Holistic Financial Benchmark ...</td>\n",
       "      <td>[0.0137786865, 0.022064209, -0.03677368, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.047519</td>\n",
       "      <td>b'2406.02604'</td>\n",
       "      <td>2024-06-06</td>\n",
       "      <td>2024</td>\n",
       "      <td>b'Bivas Dinda Ph. D.'</td>\n",
       "      <td>b'Bivas Dinda'</td>\n",
       "      <td>b'Gated recurrent neural network with TPE Baye...</td>\n",
       "      <td>b'cs.LG cs.AI cs.NE q-fin.CP'</td>\n",
       "      <td>b\"  The recent advancement of deep learning ar...</td>\n",
       "      <td>Title: Gated recurrent neural network with TPE...</td>\n",
       "      <td>[-0.011642456, 0.02758789, -0.0015649796, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.049817</td>\n",
       "      <td>b'2405.18936'</td>\n",
       "      <td>2024-06-05</td>\n",
       "      <td>2024</td>\n",
       "      <td>b\"Zolt\\\\'an Eisler\"</td>\n",
       "      <td>b'Zoltan Eisler and Johannes Muhle-Karbe'</td>\n",
       "      <td>b'Optimizing Broker Performance Evaluation thr...</td>\n",
       "      <td>b'q-fin.TR q-fin.MF'</td>\n",
       "      <td>b'  Minimizing execution costs for large order...</td>\n",
       "      <td>Title: Optimizing Broker Performance Evaluatio...</td>\n",
       "      <td>[0.016784668, -0.01927185, -0.020446777, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.050184</td>\n",
       "      <td>b'2407.09557'</td>\n",
       "      <td>2024-07-16</td>\n",
       "      <td>2024</td>\n",
       "      <td>b'Amir Mirzaeinia'</td>\n",
       "      <td>b'Alireza Mohammadshafie, Akram Mirzaeinia, Ha...</td>\n",
       "      <td>b'Deep Reinforcement Learning Strategies in Fi...</td>\n",
       "      <td>b'q-fin.TR cs.AI cs.LG'</td>\n",
       "      <td>b'  Recent deep reinforcement learning (DRL) m...</td>\n",
       "      <td>Title: Deep Reinforcement Learning Strategies ...</td>\n",
       "      <td>[-0.02670288, -0.009063721, -0.0011358261, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.068121</td>\n",
       "      <td>b'2401.14199'</td>\n",
       "      <td>2024-02-07</td>\n",
       "      <td>2024</td>\n",
       "      <td>b'Junwei Su'</td>\n",
       "      <td>b'Junwei Su, Shan Wu, Jinhui Li'</td>\n",
       "      <td>b'MTRGL:Effective Temporal Correlation Discern...</td>\n",
       "      <td>b'cs.LG econ.GN q-fin.EC q-fin.TR'</td>\n",
       "      <td>b'  In this study, we explore the synergy of d...</td>\n",
       "      <td>Title: MTRGL:Effective Temporal Correlation Di...</td>\n",
       "      <td>[0.02407837, -0.0057868958, 0.016357422, 0.017...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   __nn_distance             id update_date  year              submitter  \\\n",
       "0       1.005645  b'2401.05337'  2024-01-12  2024      b'Pierre Renucci'   \n",
       "1       1.014038  b'2310.05551'  2024-04-25  2024           b'Yushi Cao'   \n",
       "2       1.019814  b'2405.02302'  2024-05-07  2024        b'Ravi Kashyap'   \n",
       "3       1.023954  b'2402.18485'  2024-07-01  2024        b'Wentao Zhang'   \n",
       "4       1.032185  b'2403.12285'  2024-03-20  2024   b'Giorgos Iacovides'   \n",
       "5       1.039879  b'2402.12659'  2024-06-21  2024        b'Qianqian Xie'   \n",
       "6       1.047519  b'2406.02604'  2024-06-06  2024  b'Bivas Dinda Ph. D.'   \n",
       "7       1.049817  b'2405.18936'  2024-06-05  2024    b\"Zolt\\\\'an Eisler\"   \n",
       "8       1.050184  b'2407.09557'  2024-07-16  2024     b'Amir Mirzaeinia'   \n",
       "9       1.068121  b'2401.14199'  2024-02-07  2024           b'Junwei Su'   \n",
       "\n",
       "                                             authors  \\\n",
       "0                                  b'Pierre Renucci'   \n",
       "1  b'Zhiming Li, Junzhe Jiang, Yushi Cao, Aixin C...   \n",
       "2                                    b'Ravi Kashyap'   \n",
       "3  b'Wentao Zhang, Lingxuan Zhao, Haochong Xia, S...   \n",
       "4  b'Thanos Konstantinidis, Giorgos Iacovides, Mi...   \n",
       "5  b'Qianqian Xie, Weiguang Han, Zhengyu Chen, Ru...   \n",
       "6                                     b'Bivas Dinda'   \n",
       "7          b'Zoltan Eisler and Johannes Muhle-Karbe'   \n",
       "8  b'Alireza Mohammadshafie, Akram Mirzaeinia, Ha...   \n",
       "9                   b'Junwei Su, Shan Wu, Jinhui Li'   \n",
       "\n",
       "                                               title  \\\n",
       "0  b'Optimal Linear Signal: An Unsupervised Machi...   \n",
       "1  b'PST: Improving Quantitative Trading via Prog...   \n",
       "2  b'The Democratization of Wealth Management: He...   \n",
       "3  b'A Multimodal Foundation Agent for Financial ...   \n",
       "4  b'FinLlama: Financial Sentiment Classification...   \n",
       "5  b'FinBen: A Holistic Financial Benchmark for L...   \n",
       "6  b'Gated recurrent neural network with TPE Baye...   \n",
       "7  b'Optimizing Broker Performance Evaluation thr...   \n",
       "8  b'Deep Reinforcement Learning Strategies in Fi...   \n",
       "9  b'MTRGL:Effective Temporal Correlation Discern...   \n",
       "\n",
       "                                     categories  \\\n",
       "0                             b'q-fin.ST cs.LG'   \n",
       "1                          b'cs.CE cs.AI cs.PL'   \n",
       "2  b'cs.CR q-fin.CP q-fin.PM q-fin.RM q-fin.TR'   \n",
       "3                             b'q-fin.TR cs.AI'   \n",
       "4              b'cs.CL cs.LG q-fin.ST q-fin.TR'   \n",
       "5                          b'cs.CL cs.AI cs.CE'   \n",
       "6                 b'cs.LG cs.AI cs.NE q-fin.CP'   \n",
       "7                          b'q-fin.TR q-fin.MF'   \n",
       "8                       b'q-fin.TR cs.AI cs.LG'   \n",
       "9            b'cs.LG econ.GN q-fin.EC q-fin.TR'   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  b\"  This study presents an unsupervised machin...   \n",
       "1  b'  Deep reinforcement learning (DRL) has revo...   \n",
       "2  b'  We develop several innovations designed to...   \n",
       "3  b\"  Financial trading is a crucial component o...   \n",
       "4  b\"  There are multiple sources of financial ne...   \n",
       "5  b\"  LLMs have transformed NLP and shown promis...   \n",
       "6  b\"  The recent advancement of deep learning ar...   \n",
       "7  b'  Minimizing execution costs for large order...   \n",
       "8  b'  Recent deep reinforcement learning (DRL) m...   \n",
       "9  b'  In this study, we explore the synergy of d...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Title: Optimal Linear Signal: An Unsupervised ...   \n",
       "1  Title: PST: Improving Quantitative Trading via...   \n",
       "2  Title: The Democratization of Wealth Managemen...   \n",
       "3  Title: A Multimodal Foundation Agent for Finan...   \n",
       "4  Title: FinLlama: Financial Sentiment Classific...   \n",
       "5  Title: FinBen: A Holistic Financial Benchmark ...   \n",
       "6  Title: Gated recurrent neural network with TPE...   \n",
       "7  Title: Optimizing Broker Performance Evaluatio...   \n",
       "8  Title: Deep Reinforcement Learning Strategies ...   \n",
       "9  Title: MTRGL:Effective Temporal Correlation Di...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [0.040924072, 0.020080566, -0.030319214, -0.02...  \n",
       "1  [0.016921997, 0.009155273, -0.040527344, 0.012...  \n",
       "2  [0.008140564, -0.0058517456, 0.013183594, -0.0...  \n",
       "3  [0.029037476, -0.0009021759, -0.00024068356, 0...  \n",
       "4  [0.0047569275, 0.0149383545, -0.016433716, -0....  \n",
       "5  [0.0137786865, 0.022064209, -0.03677368, -0.01...  \n",
       "6  [-0.011642456, 0.02758789, -0.0015649796, 0.02...  \n",
       "7  [0.016784668, -0.01927185, -0.020446777, -0.02...  \n",
       "8  [-0.02670288, -0.009063721, -0.0011358261, -0....  \n",
       "9  [0.02407837, -0.0057868958, 0.016357422, 0.017...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "table.search(vectors={'qflat_index': [emb]}, n=10, filter=[[\"like\",\"text\",\"*trading*\"],[\"like\",\"text\",\"*finance*\"],[\">\",\"year\",2023]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "61bc5d4d-7377-4e31-bb5c-f8d209a481e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CountDocs\n",
      "0    2530760\n"
     ]
    }
   ],
   "source": [
    "print(table.query(aggs={'CountDocs': ('count', 'year')}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744ca3c5-f1aa-49c6-b2e1-944743c56ec8",
   "metadata": {},
   "source": [
    "### Setup for NIM LLM\n",
    "\n",
    "Here we create a fucntion to call the NIM LLM model which is prehosted locally and calling the API reference  \n",
    "The model used is Llama 3.1 70b Instruct model which is already NVIDIA optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0629b883-7f65-4454-aa7d-377c5a146a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "nimClient = OpenAI(\n",
    "    api_key=\"no-key-required\",\n",
    "    base_url = \"http://0.0.0.0:8000/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca2aff5-2fec-4cc7-8947-4e7c2c70c32c",
   "metadata": {},
   "source": [
    "### Defining function to record the time in generating responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a570e70a-d7bd-4f6a-8b7c-46357e91306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_time(message,start,end):\n",
    "    time_diff = end - start\n",
    "    td = timedelta(seconds=time_diff)\n",
    "    hours = td.seconds // 3600\n",
    "    minutes = (td.seconds % 3600) // 60\n",
    "    seconds = time_diff % 60\n",
    "    print(f'{message}: {hours}h {minutes}m {seconds:.4f}s \\n')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0581cf40-678f-48df-9393-ad59d4c74629",
   "metadata": {},
   "source": [
    "### Defining functions for calling LLM and retrieving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3e8bed60-a3fc-4b47-9dd6-ebf1daa78e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, model=LLM, temperature=TEMPERATURE):\n",
    "    prompt = [dict(role='user', content=prompt)]\n",
    "    tstart = time.perf_counter()\n",
    "    response = nimClient.chat.completions.create(model=model, messages=prompt, temperature=temperature, max_tokens=2048, stream=False)\n",
    "    h_time('LLM Response',tstart,time.perf_counter())\n",
    "    return response\n",
    "\n",
    "def retrieve(q, k=10, filters=[]):\n",
    "    tstart = time.perf_counter()\n",
    "    emb = get_embedding(q)\n",
    "    h_time('Embedding the User Query',tstart,time.perf_counter())\n",
    "    \n",
    "    tstart = time.perf_counter()\n",
    "    ctx = table.search(vectors={'qflat_index': [emb]}, n=10, filter=filters)[0]\n",
    "    h_time('KDB.AI Similarity Search',tstart,time.perf_counter())\n",
    "    return ctx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4bc443-7643-49c6-b994-99e16ec4141d",
   "metadata": {},
   "source": [
    "### Defining Prompt and RAG Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7f19592c-5c9c-4fcc-a8d3-4cf8014f98ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = '''\n",
    "JSON context: %s\n",
    "\n",
    "Question: %s\n",
    "\n",
    "You are a quantitative trader. Answer the question using the provided JSON context only.\n",
    "Justify your answer with clear examples and precise references (date, authors, title) from the JSON context only.\n",
    "\n",
    "Answer:'''\n",
    "\n",
    "HISTORY = ''\n",
    "\n",
    "def prompt(q, k=10, model=LLM, temperature=TEMPERATURE, filter=[], augment=False, history=''):\n",
    "    ragS = time.perf_counter()\n",
    "    if augment:\n",
    "        tips = llm('Answer the question: %s' % q, model=LLM, temperature=TEMPERATURE).choices[0].message.content\n",
    "        q = q + '\\n\\n' + tips\n",
    "        \n",
    "    ctx = retrieve(q, k=k, filters=filter)[['title', 'update_date', 'authors', 'text']].to_json(orient='records', date_format='iso')\n",
    "    \n",
    "    p = PROMPT_TEMPLATE % (ctx, q)\n",
    "    \n",
    "    answer = llm(history + '\\n\\n\\n' + p, model=model, temperature=temperature)\n",
    "\n",
    "    h_time('Total RAG response time',ragS,time.perf_counter())\n",
    "    print('---------------------------------------------- \\n')\n",
    "    print('Assistant: ' + answer.choices[0].message.content)\n",
    "\n",
    "    return answer, ctx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe86f792-cfaf-41c5-bac0-ec580e7f475c",
   "metadata": {},
   "source": [
    "### Try to answer a strategic business problem with RAG applied on the ArXiv dataset (beware of LLM hallucinations and fake references...)\n",
    "\n",
    "Based on the above parameters we ask the LLM the below query and filter the responses based on document data only related to tradin by passing the trading keyword.\n",
    "As a result we can see the curated response from the LLM also generating the references which were considered fot this response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8b044e8f-6712-45af-b042-521291fee108",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding the User Query: 0h 0m 0.0118s \n",
      "\n",
      "KDB.AI Similarity Search: 0h 0m 18.0739s \n",
      "\n",
      "LLM Response: 0h 0m 12.1843s \n",
      "\n",
      "Total RAG response time: 0h 0m 30.2710s \n",
      "\n",
      "---------------------------------------------- \n",
      "\n",
      "Assistant: To generate alpha with Streaming Analytics and AI applied on structured data (market tick data) and unstructured data (news feeds, twitter, 10-K reports...), I would recommend the following approaches:\n",
      "\n",
      "1. **Utilize a multimodal foundation agent**: Implement a multimodal foundation agent like FinAgent (Wentao Zhang et al., \"A Multimodal Foundation Agent for Financial Trading: Tool-Augmented, Diversified, and Generalist\", 2024-07-01) that can process a diverse range of data, including numerical, textual, and visual data. This agent can accurately analyze the financial market and make informed decisions.\n",
      "\n",
      "2. **Apply sentiment analysis on unstructured data**: Use a finance-specific Large Language Model (LLM) framework like FinLlama (Thanos Konstantinidis et al., \"FinLlama: Financial Sentiment Classification for Algorithmic Trading Applications\", 2024-03-20) to analyze financial news articles and quantify sentiment strength. This can provide traders with nuanced insights into financial news.\n",
      "\n",
      "3. **Incorporate temporal correlation discerning**: Employ a novel framework like MTRGL (Junwei Su et al., \"MTRGL:Effective Temporal Correlation Discerning through Multi-modal Temporal Relational Graph Learning\", 2024-02-07) to discern temporal correlations among entities, integrating time series data and discrete features into a temporal graph.\n",
      "\n",
      "4. **Optimize broker performance evaluation**: Use a methodology like the one presented by Zoltan Eisler and Johannes Muhle-Karbe (\"Optimizing Broker Performance Evaluation through Intraday Modeling of Execution Cost\", 2024-06-05) to evaluate the effectiveness of broker execution algorithms using trading data, focusing on linear and quadratic costs.\n",
      "\n",
      "5. **Leverage deep reinforcement learning strategies**: Investigate the behavior of deep reinforcement learning (DRL) algorithms in finance, as done by Alireza Mohammadshafie et al. (\"Deep Reinforcement Learning Strategies in Finance: Insights into Asset Holding, Trading Behavior, and Purchase Diversity\", 2024-07-16), to gain insights into their decision-making processes and optimize their performance.\n",
      "\n",
      "By combining these approaches, you can effectively generate alpha with Streaming Analytics and AI applied on structured and unstructured data.\n",
      "CPU times: user 15.6 s, sys: 2.63 s, total: 18.3 s\n",
      "Wall time: 30.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Q = 'I am running a Hedge Fund, tell me how to generate alpha with Streaming Analytics and AI applied on structured data (market tick data) and unstructured data (news feeds, twitter, 10-K reports...) ?'\n",
    "K = 20\n",
    "\n",
    "answer, ctx = prompt(Q, k=K, filter=[[\"like\",\"text\",\"*trading*\"],[\"like\",\"text\",\"*finance*\"],[\">\",\"year\",2023]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c08389c0-2a42-4ad9-afb0-e2d676a29d45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"title\":\"Optimal Linear Signal: An Unsupervised Machine Learning Framework to\\n  Optimize PnL with Linear Signals\",\"update_date\":\"2024-01-12T00:00:00.000\",\"authors\":\"Pierre Renucci\",\"text\":\"Title: Optimal Linear Signal: An Unsupervised Machine Learning Framework to\\n  Optimize PnL with Linear Signals\\nDate: 2024-01-12 00:00:00\\nAuthors: Pierre Renucci\\nAbstract:   This study presents an unsupervised machine learning approach for optimizing\\nProfit and Loss (PnL) in quantitative finance. Our algorithm, akin to an\\nunsupervised variant of linear regression, maximizes the Sharpe Ratio of PnL\\ngenerated from signals constructed linearly from exogenous variables. The\\nmethodology employs a linear relationship between exogenous variables and the\\ntrading signal, with the objective of maximizing the Sharpe Ratio through\\nparameter optimization. Empirical application on an ETF representing U.S.\\nTreasury bonds demonstrates the model's effectiveness, supported by\\nregularization techniques to mitigate overfitting. The study concludes with\\npotential avenues for further development, including generalized time steps and\\nenhanced corrective terms.\\n\\n\"},{\"title\":\"PST: Improving Quantitative Trading via Program Sketch-based Tuning\",\"update_date\":\"2024-04-25T00:00:00.000\",\"authors\":\"Zhiming Li, Junzhe Jiang, Yushi Cao, Aixin Cui, Bozhi Wu, Bo Li, Yang\\n  Liu, Dongning Sun\",\"text\":\"Title: PST: Improving Quantitative Trading via Program Sketch-based Tuning\\nDate: 2024-04-25 00:00:00\\nAuthors: Zhiming Li, Junzhe Jiang, Yushi Cao, Aixin Cui, Bozhi Wu, Bo Li, Yang\\n  Liu, Dongning Sun\\nAbstract:   Deep reinforcement learning (DRL) has revolutionized quantitative finance by\\nachieving decent performance without significant human expert knowledge.\\nDespite its achievements, we observe that the current state-of-the-art DRL\\nmodels are still ineffective in identifying the market trend, causing them to\\nmiss good trading opportunities or suffer from large drawdowns when\\nencountering market crashes. To tackle this limitation, a natural idea is to\\nembed human expert knowledge regarding the market trend. Whereas, such\\nknowledge is abstract and hard to be quantified. In this paper, we propose a\\nuniversal neuro-symbolic tuning framework, called program sketch-based tuning\\n(PST). Particularly, PST first proposes using a novel symbolic program sketch\\nto embed the abstract human expert knowledge of market trends. Then we utilize\\nthe program sketch to tune a trained DRL policy according to the different\\nmarket trend of the moment. Finally, in order to optimize this neural-symbolic\\nframework, we propose a novel hybrid optimization method. Extensive evaluations\\non two popular quantitative trading tasks demonstrate that PST can\\nsignificantly enhance the performance of previous state-of-the-art DRL\\nstrategies while being extremely lightweight.\\n\\n\"},{\"title\":\"The Democratization of Wealth Management: Hedged Mutual Fund Blockchain\\n  Protocol\",\"update_date\":\"2024-05-07T00:00:00.000\",\"authors\":\"Ravi Kashyap\",\"text\":\"Title: The Democratization of Wealth Management: Hedged Mutual Fund Blockchain\\n  Protocol\\nDate: 2024-05-07 00:00:00\\nAuthors: Ravi Kashyap\\nAbstract:   We develop several innovations designed to bring the best practices of\\ntraditional investment funds to the blockchain landscape. Our innovations\\ncombine the superior mechanisms of mutual funds and hedge funds. Specifically,\\nwe illustrate how fund prices can be updated regularly like mutual funds and\\nperformance fees can be charged like hedge funds. We show how mutually hedged\\nblockchain investment funds can operate with investor protection schemes - high\\nwater marks - and measures to offset trading slippage when redemptions happen.\\nWe provide detailed steps - including mathematical formulations and instructive\\npointers - to implement these ideas as blockchain smart contracts. We discuss\\nhow our designs overcome several blockchain bottlenecks and how we can make\\nsmart contracts smarter. We provide numerical illustrations of several\\nscenarios related to the mechanisms we have tailored for blockchain\\nimplementation.\\n  The concepts we have developed for blockchain implementation can also be\\nuseful in traditional financial funds to calculate performance fees in a\\nsimplified manner. We highlight two main issues with the operation of mutual\\nfunds and hedge funds and show how blockchain technology can alleviate those\\nconcerns. The ideas developed here illustrate on one hand, how blockchain can\\nsolve many issues faced by the traditional world and on the other hand, how\\nmany innovations from traditional finance can benefit decentralized finance and\\nspeed its adoption. This becomes an example of symbiosis between decentralized\\nand traditional finance - bringing these two realms closer and breaking down\\nbarriers between such artificial distinctions - wherein the future will be\\nabout providing better risk adjusted wealth appreciation opportunities to end\\ncustomers through secure, reliable, accessible and transparent services -\\nwithout getting too caught up about how such services are being rendered.\\n\\n\"},{\"title\":\"A Multimodal Foundation Agent for Financial Trading: Tool-Augmented,\\n  Diversified, and Generalist\",\"update_date\":\"2024-07-01T00:00:00.000\",\"authors\":\"Wentao Zhang, Lingxuan Zhao, Haochong Xia, Shuo Sun, Jiaze Sun, Molei\\n  Qin, Xinyi Li, Yuqing Zhao, Yilei Zhao, Xinyu Cai, Longtao Zheng, Xinrun\\n  Wang, Bo An\",\"text\":\"Title: A Multimodal Foundation Agent for Financial Trading: Tool-Augmented,\\n  Diversified, and Generalist\\nDate: 2024-07-01 00:00:00\\nAuthors: Wentao Zhang, Lingxuan Zhao, Haochong Xia, Shuo Sun, Jiaze Sun, Molei\\n  Qin, Xinyi Li, Yuqing Zhao, Yilei Zhao, Xinyu Cai, Longtao Zheng, Xinrun\\n  Wang, Bo An\\nAbstract:   Financial trading is a crucial component of the markets, informed by a\\nmultimodal information landscape encompassing news, prices, and Kline charts,\\nand encompasses diverse tasks such as quantitative trading and high-frequency\\ntrading with various assets. While advanced AI techniques like deep learning\\nand reinforcement learning are extensively utilized in finance, their\\napplication in financial trading tasks often faces challenges due to inadequate\\nhandling of multimodal data and limited generalizability across various tasks.\\nTo address these challenges, we present FinAgent, a multimodal foundational\\nagent with tool augmentation for financial trading. FinAgent's market\\nintelligence module processes a diverse range of data-numerical, textual, and\\nvisual-to accurately analyze the financial market. Its unique dual-level\\nreflection module not only enables rapid adaptation to market dynamics but also\\nincorporates a diversified memory retrieval system, enhancing the agent's\\nability to learn from historical data and improve decision-making processes.\\nThe agent's emphasis on reasoning for actions fosters trust in its financial\\ndecisions. Moreover, FinAgent integrates established trading strategies and\\nexpert insights, ensuring that its trading approaches are both data-driven and\\nrooted in sound financial principles. With comprehensive experiments on 6\\nfinancial datasets, including stocks and Crypto, FinAgent significantly\\noutperforms 9 state-of-the-art baselines in terms of 6 financial metrics with\\nover 36% average improvement on profit. Specifically, a 92.27% return (a 84.39%\\nrelative improvement) is achieved on one dataset. Notably, FinAgent is the\\nfirst advanced multimodal foundation agent designed for financial trading\\ntasks.\\n\\n\"},{\"title\":\"FinLlama: Financial Sentiment Classification for Algorithmic Trading\\n  Applications\",\"update_date\":\"2024-03-20T00:00:00.000\",\"authors\":\"Thanos Konstantinidis, Giorgos Iacovides, Mingxue Xu, Tony G.\\n  Constantinides, Danilo Mandic\",\"text\":\"Title: FinLlama: Financial Sentiment Classification for Algorithmic Trading\\n  Applications\\nDate: 2024-03-20 00:00:00\\nAuthors: Thanos Konstantinidis, Giorgos Iacovides, Mingxue Xu, Tony G.\\n  Constantinides, Danilo Mandic\\nAbstract:   There are multiple sources of financial news online which influence market\\nmovements and trader's decisions. This highlights the need for accurate\\nsentiment analysis, in addition to having appropriate algorithmic trading\\ntechniques, to arrive at better informed trading decisions. Standard lexicon\\nbased sentiment approaches have demonstrated their power in aiding financial\\ndecisions. However, they are known to suffer from issues related to context\\nsensitivity and word ordering. Large Language Models (LLMs) can also be used in\\nthis context, but they are not finance-specific and tend to require significant\\ncomputational resources. To facilitate a finance specific LLM framework, we\\nintroduce a novel approach based on the Llama 2 7B foundational model, in order\\nto benefit from its generative nature and comprehensive language manipulation.\\nThis is achieved by fine-tuning the Llama2 7B model on a small portion of\\nsupervised financial sentiment analysis data, so as to jointly handle the\\ncomplexities of financial lexicon and context, and further equipping it with a\\nneural network based decision mechanism. Such a generator-classifier scheme,\\nreferred to as FinLlama, is trained not only to classify the sentiment valence\\nbut also quantify its strength, thus offering traders a nuanced insight into\\nfinancial news articles. Complementing this, the implementation of\\nparameter-efficient fine-tuning through LoRA optimises trainable parameters,\\nthus minimising computational and memory requirements, without sacrificing\\naccuracy. Simulation results demonstrate the ability of the proposed FinLlama\\nto provide a framework for enhanced portfolio management decisions and\\nincreased market returns. These results underpin the ability of FinLlama to\\nconstruct high-return portfolios which exhibit enhanced resilience, even during\\nvolatile periods and unpredictable market events.\\n\\n\"},{\"title\":\"FinBen: A Holistic Financial Benchmark for Large Language Models\",\"update_date\":\"2024-06-21T00:00:00.000\",\"authors\":\"Qianqian Xie, Weiguang Han, Zhengyu Chen, Ruoyu Xiang, Xiao Zhang,\\n  Yueru He, Mengxi Xiao, Dong Li, Yongfu Dai, Duanyu Feng, Yijing Xu, Haoqiang\\n  Kang, Ziyan Kuang, Chenhan Yuan, Kailai Yang, Zheheng Luo, Tianlin Zhang,\\n  Zhiwei Liu, Guojun Xiong, Zhiyang Deng, Yuechen Jiang, Zhiyuan Yao, Haohang\\n  Li, Yangyang Yu, Gang Hu, Jiajia Huang, Xiao-Yang Liu, Alejandro Lopez-Lira,\\n  Benyou Wang, Yanzhao Lai, Hao Wang, Min Peng, Sophia Ananiadou, and Jimin\\n  Huang\",\"text\":\"Title: FinBen: A Holistic Financial Benchmark for Large Language Models\\nDate: 2024-06-21 00:00:00\\nAuthors: Qianqian Xie, Weiguang Han, Zhengyu Chen, Ruoyu Xiang, Xiao Zhang,\\n  Yueru He, Mengxi Xiao, Dong Li, Yongfu Dai, Duanyu Feng, Yijing Xu, Haoqiang\\n  Kang, Ziyan Kuang, Chenhan Yuan, Kailai Yang, Zheheng Luo, Tianlin Zhang,\\n  Zhiwei Liu, Guojun Xiong, Zhiyang Deng, Yuechen Jiang, Zhiyuan Yao, Haohang\\n  Li, Yangyang Yu, Gang Hu, Jiajia Huang, Xiao-Yang Liu, Alejandro Lopez-Lira,\\n  Benyou Wang, Yanzhao Lai, Hao Wang, Min Peng, Sophia Ananiadou, and Jimin\\n  Huang\\nAbstract:   LLMs have transformed NLP and shown promise in various fields, yet their\\npotential in finance is underexplored due to a lack of comprehensive evaluation\\nbenchmarks, the rapid development of LLMs, and the complexity of financial\\ntasks. In this paper, we introduce FinBen, the first extensive open-source\\nevaluation benchmark, including 36 datasets spanning 24 financial tasks,\\ncovering seven critical aspects: information extraction (IE), textual analysis,\\nquestion answering (QA), text generation, risk management, forecasting, and\\ndecision-making. FinBen offers several key innovations: a broader range of\\ntasks and datasets, the first evaluation of stock trading, novel agent and\\nRetrieval-Augmented Generation (RAG) evaluation, and three novel open-source\\nevaluation datasets for text summarization, question answering, and stock\\ntrading. Our evaluation of 15 representative LLMs, including GPT-4, ChatGPT,\\nand the latest Gemini, reveals several key findings: While LLMs excel in IE and\\ntextual analysis, they struggle with advanced reasoning and complex tasks like\\ntext generation and forecasting. GPT-4 excels in IE and stock trading, while\\nGemini is better at text generation and forecasting. Instruction-tuned LLMs\\nimprove textual analysis but offer limited benefits for complex tasks such as\\nQA. FinBen has been used to host the first financial LLMs shared task at the\\nFinNLP-AgentScen workshop during IJCAI-2024, attracting 12 teams. Their novel\\nsolutions outperformed GPT-4, showcasing FinBen's potential to drive innovation\\nin financial LLMs. All datasets, results, and codes are released for the\\nresearch community: https:\\/\\/github.com\\/The-FinAI\\/PIXIU.\\n\\n\"},{\"title\":\"Gated recurrent neural network with TPE Bayesian optimization for\\n  enhancing stock index prediction accuracy\",\"update_date\":\"2024-06-06T00:00:00.000\",\"authors\":\"Bivas Dinda\",\"text\":\"Title: Gated recurrent neural network with TPE Bayesian optimization for\\n  enhancing stock index prediction accuracy\\nDate: 2024-06-06 00:00:00\\nAuthors: Bivas Dinda\\nAbstract:   The recent advancement of deep learning architectures, neural networks, and\\nthe combination of abundant financial data and powerful computers are\\ntransforming finance, leading us to develop an advanced method for predicting\\nfuture stock prices. However, the accessibility of investment and trading at\\neveryone's fingertips made the stock markets increasingly intricate and prone\\nto volatility. The increased complexity and volatility of the stock market have\\ndriven demand for more models, which would effectively capture high volatility\\nand non-linear behavior of the different stock prices. This study explored\\ngated recurrent neural network (GRNN) algorithms such as LSTM (long short-term\\nmemory), GRU (gated recurrent unit), and hybrid models like GRU-LSTM, LSTM-GRU,\\nwith Tree-structured Parzen Estimator (TPE) Bayesian optimization for\\nhyperparameter optimization (TPE-GRNN). The aim is to improve the prediction\\naccuracy of the next day's closing price of the NIFTY 50 index, a prominent\\nIndian stock market index, using TPE-GRNN. A combination of eight influential\\nfactors is carefully chosen from fundamental stock data, technical indicators,\\ncrude oil price, and macroeconomic data to train the models for capturing the\\nchanges in the price of the index with the factors of the broader economy.\\nSingle-layer and multi-layer TPE-GRNN models have been developed. The models'\\nperformance is evaluated using standard matrices like R2, MAPE, and RMSE. The\\nanalysis of models' performance reveals the impact of feature selection and\\nhyperparameter optimization (HPO) in enhancing stock index price prediction\\naccuracy. The results show that the MAPE of our proposed TPE-LSTM method is the\\nlowest (best) with respect to all the previous models for stock index price\\nprediction.\\n\\n\"},{\"title\":\"Optimizing Broker Performance Evaluation through Intraday Modeling of\\n  Execution Cost\",\"update_date\":\"2024-06-05T00:00:00.000\",\"authors\":\"Zoltan Eisler and Johannes Muhle-Karbe\",\"text\":\"Title: Optimizing Broker Performance Evaluation through Intraday Modeling of\\n  Execution Cost\\nDate: 2024-06-05 00:00:00\\nAuthors: Zoltan Eisler and Johannes Muhle-Karbe\\nAbstract:   Minimizing execution costs for large orders is a fundamental challenge in\\nfinance. Firms often depend on brokers to manage their trades due to limited\\ninternal resources for optimizing trading strategies. This paper presents a\\nmethodology for evaluating the effectiveness of broker execution algorithms\\nusing trading data. We focus on two primary cost components: a linear cost that\\nquantifies short-term execution quality and a quadratic cost associated with\\nthe price impact of trades. Using a model with transient price impact, we\\nderive analytical formulas for estimating these costs. Furthermore, we enhance\\nestimation accuracy by introducing novel methods such as weighting price\\nchanges based on their expected impact content. Our results demonstrate\\nsubstantial improvements in estimating both linear and impact costs, providing\\na robust and efficient framework for selecting the most cost-effective brokers.\\n\\n\"},{\"title\":\"Deep Reinforcement Learning Strategies in Finance: Insights into Asset\\n  Holding, Trading Behavior, and Purchase Diversity\",\"update_date\":\"2024-07-16T00:00:00.000\",\"authors\":\"Alireza Mohammadshafie, Akram Mirzaeinia, Haseebullah Jumakhan, Amir\\n  Mirzaeinia\",\"text\":\"Title: Deep Reinforcement Learning Strategies in Finance: Insights into Asset\\n  Holding, Trading Behavior, and Purchase Diversity\\nDate: 2024-07-16 00:00:00\\nAuthors: Alireza Mohammadshafie, Akram Mirzaeinia, Haseebullah Jumakhan, Amir\\n  Mirzaeinia\\nAbstract:   Recent deep reinforcement learning (DRL) methods in finance show promising\\noutcomes. However, there is limited research examining the behavior of these\\nDRL algorithms. This paper aims to investigate their tendencies towards holding\\nor trading financial assets as well as purchase diversity. By analyzing their\\ntrading behaviors, we provide insights into the decision-making processes of\\nDRL models in finance applications. Our findings reveal that each DRL algorithm\\nexhibits unique trading patterns and strategies, with A2C emerging as the top\\nperformer in terms of cumulative rewards. While PPO and SAC engage in\\nsignificant trades with a limited number of stocks, DDPG and TD3 adopt a more\\nbalanced approach. Furthermore, SAC and PPO tend to hold positions for shorter\\ndurations, whereas DDPG, A2C, and TD3 display a propensity to remain stationary\\nfor extended periods.\\n\\n\"},{\"title\":\"MTRGL:Effective Temporal Correlation Discerning through Multi-modal\\n  Temporal Relational Graph Learning\",\"update_date\":\"2024-02-07T00:00:00.000\",\"authors\":\"Junwei Su, Shan Wu, Jinhui Li\",\"text\":\"Title: MTRGL:Effective Temporal Correlation Discerning through Multi-modal\\n  Temporal Relational Graph Learning\\nDate: 2024-02-07 00:00:00\\nAuthors: Junwei Su, Shan Wu, Jinhui Li\\nAbstract:   In this study, we explore the synergy of deep learning and financial market\\napplications, focusing on pair trading. This market-neutral strategy is\\nintegral to quantitative finance and is apt for advanced deep-learning\\ntechniques. A pivotal challenge in pair trading is discerning temporal\\ncorrelations among entities, necessitating the integration of diverse data\\nmodalities. Addressing this, we introduce a novel framework, Multi-modal\\nTemporal Relation Graph Learning (MTRGL). MTRGL combines time series data and\\ndiscrete features into a temporal graph and employs a memory-based temporal\\ngraph neural network. This approach reframes temporal correlation\\nidentification as a temporal graph link prediction task, which has shown\\nempirical success. Our experiments on real-world datasets confirm the superior\\nperformance of MTRGL, emphasizing its promise in refining automated pair\\ntrading strategies.\\n\\n\"}]\n"
     ]
    }
   ],
   "source": [
    "print(ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66843429-c3c8-4717-99af-923d288e3cff",
   "metadata": {},
   "source": [
    "### Let's break the complex question in multiple sub questions\n",
    "\n",
    "Next we have broken the above query asked into set of simpler questions which can be asked separately to get more detailed responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e26c9c88-ce3c-416c-bc6b-c18168e39480",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response: 0h 0m 6.6926s \n",
      "\n",
      "Here are the simpler questions that can help break down the complex question:\n",
      "\n",
      "**Section 1: Understanding the Context**\n",
      "\n",
      "1. What is the investment strategy of your Hedge Fund (e.g., long-short equity, global macro, event-driven)?\n",
      "2. What are your current data sources for making investment decisions?\n",
      "3. What are your goals for using Streaming Analytics and AI (e.g., improve predictive models, increase trading efficiency, enhance risk management)?\n",
      "\n",
      "**Section 2: Structured Data (Market Tick Data)**\n",
      "\n",
      "1. What type of market tick data do you have access to (e.g., stocks, options, futures, forex)?\n",
      "2. How do you currently process and analyze market tick data (e.g., time-series analysis, statistical models)?\n",
      "3. What specific insights or alpha-generating opportunities do you hope to uncover from market tick data using Streaming Analytics and AI?\n",
      "\n",
      "**Section 3: Unstructured Data (News Feeds, Twitter, 10-K Reports)**\n",
      "\n",
      "1. What types of unstructured data do you want to incorporate into your analysis (e.g., news articles, social media posts, company filings)?\n",
      "2. How do you plan to preprocess and normalize the unstructured data for analysis (e.g., text processing, sentiment analysis)?\n",
      "3. What specific insights or alpha-generating opportunities do you hope to uncover from unstructured data using Streaming Analytics and AI?\n",
      "\n",
      "**Section 4: Streaming Analytics and AI**\n",
      "\n",
      "1. What Streaming Analytics technologies are you considering (e.g., Apache Kafka, Apache Storm, Amazon Kinesis)?\n",
      "2. What AI techniques are you interested in applying (e.g., machine learning, deep learning, natural language processing)?\n",
      "3. How do you plan to integrate Streaming Analytics and AI with your existing data infrastructure and investment decision-making processes?\n",
      "\n",
      "**Section 5: Implementation and Integration**\n",
      "\n",
      "1. What is your expected timeline for implementing Streaming Analytics and AI in your Hedge Fund?\n",
      "2. What resources (e.g., personnel, budget, infrastructure) do you have available for this project?\n",
      "3. How do you plan to measure the success of your Streaming Analytics and AI initiatives in generating alpha?\n",
      "\n",
      "By answering these simpler questions, you'll be able to break down the complex question into manageable components and develop a clearer understanding of how to generate alpha with Streaming Analytics and AI applied to structured and unstructured data.\n",
      "CPU times: user 39.6 ms, sys: 4.94 ms, total: 44.5 ms\n",
      "Wall time: 6.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Q = 'I am running a Hedge Fund, tell me how to generate alpha with Streaming Analytics and AI applied on structured data (market tick data) and unstructured data (news feeds, twitter, 10-K reports...) ?'\n",
    "\n",
    "answer = llm('''\n",
    "Break the following complex question in multiple simpler questions:\n",
    "%s\n",
    "''' % Q, model=LLM, temperature=TEMPERATURE).choices[0].message.content\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11821fff-2886-4c3d-a7ee-f7574a5b52ba",
   "metadata": {},
   "source": [
    "### Convert the list of sub questions to JSON so we can process it\n",
    "\n",
    "The above list of sub questions are converted into a JSON list to be processed.  \n",
    "Please note that choosing the right context differs from one LLM model to another to get the desired results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cdd5a30d-a602-4151-9d9b-dd002d7d5926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response: 0h 0m 5.3478s \n",
      "\n",
      "CPU times: user 19.5 ms, sys: 16.5 ms, total: 36 ms\n",
      "Wall time: 5.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "questions = llm('''\n",
    "Return the questions below only as a JSON list of strings with no other context:\n",
    "%s\n",
    "''' % answer, model=LLM, temperature=TEMPERATURE).choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4cc08726-4c3d-4e3a-b993-440f39be5121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What is the investment strategy of your Hedge Fund (e.g., long-short equity, global macro, event-driven)?', 'What are your current data sources for making investment decisions?', 'What are your goals for using Streaming Analytics and AI (e.g., improve predictive models, increase trading efficiency, enhance risk management)?', 'What type of market tick data do you have access to (e.g., stocks, options, futures, forex)?', 'How do you currently process and analyze market tick data (e.g., time-series analysis, statistical models)?', 'What specific insights or alpha-generating opportunities do you hope to uncover from market tick data using Streaming Analytics and AI?', 'What types of unstructured data do you want to incorporate into your analysis (e.g., news articles, social media posts, company filings)?', 'How do you plan to preprocess and normalize the unstructured data for analysis (e.g., text processing, sentiment analysis)?', 'What specific insights or alpha-generating opportunities do you hope to uncover from unstructured data using Streaming Analytics and AI?', 'What Streaming Analytics technologies are you considering (e.g., Apache Kafka, Apache Storm, Amazon Kinesis)?', 'What AI techniques are you interested in applying (e.g., machine learning, deep learning, natural language processing)?', 'How do you plan to integrate Streaming Analytics and AI with your existing data infrastructure and investment decision-making processes?', 'What is your expected timeline for implementing Streaming Analytics and AI in your Hedge Fund?', 'What resources (e.g., personnel, budget, infrastructure) do you have available for this project?', 'How do you plan to measure the success of your Streaming Analytics and AI initiatives in generating alpha?']\n"
     ]
    }
   ],
   "source": [
    "questions = json.loads(questions)\n",
    "\n",
    "print(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "47d8818c-cdf0-47fc-8101-eddb5e5d805d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the investment strategy of your Hedge Fund (e.g., long-short equity, global macro, event-driven)?'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e7e32d-65a1-402f-8db7-43a75bb9793b",
   "metadata": {},
   "source": [
    "### Take the first sub question and augment it to improve the accuracy of the context retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b01973ea-952a-4484-9998-067bd4e60529",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response: 0h 0m 7.6494s \n",
      "\n",
      "What is the investment strategy of your Hedge Fund (e.g., long-short equity, global macro, event-driven)?\n",
      "\n",
      "Our hedge fund, which we'll call \"AlphaQuest,\" employs a multi-strategy approach that combines elements of long-short equity, global macro, and event-driven investing. Our investment objective is to generate absolute returns with a focus on capital preservation, while also providing a hedge against market downturns.\n",
      "\n",
      "**Long-Short Equity:**\n",
      "We maintain a long-short equity portfolio that seeks to capitalize on mispricings in the market. Our long book focuses on high-conviction, growth-oriented stocks with strong fundamentals, while our short book targets companies with deteriorating fundamentals, excessive valuations, or other negative catalysts. We use a combination of quantitative models and fundamental research to identify attractive long and short opportunities.\n",
      "\n",
      "**Global Macro:**\n",
      "Our global macro strategy involves making directional bets on various asset classes, including currencies, commodities, and interest rates. We use a top-down approach to identify macroeconomic trends and themes, and then allocate capital to the most attractive opportunities. This strategy allows us to capitalize on broad market movements and diversify our portfolio.\n",
      "\n",
      "**Event-Driven:**\n",
      "Our event-driven strategy focuses on investing in companies undergoing significant corporate events, such as mergers and acquisitions, spin-offs, or bankruptcies. We seek to profit from the mispricing of securities surrounding these events, often by taking a long or short position in the affected companies.\n",
      "\n",
      "**Risk Management:**\n",
      "Risk management is a critical component of our investment strategy. We employ a variety of techniques to manage risk, including:\n",
      "\n",
      "1. **Position sizing:** We carefully manage the size of each position to ensure that no single investment dominates the portfolio.\n",
      "2. **Diversification:** We maintain a diversified portfolio across various asset classes, sectors, and geographies to minimize exposure to any one particular market or sector.\n",
      "3. **Hedging:** We use derivatives and other hedging strategies to mitigate potential losses and protect the portfolio from adverse market movements.\n",
      "4. **Stop-losses:** We set stop-loss levels for each position to limit potential losses if the investment does not perform as expected.\n",
      "\n",
      "**Investment Process:**\n",
      "Our investment process involves a combination of quantitative models, fundamental research, and macroeconomic analysis. We use a variety of data sources, including financial statements, market data, and economic indicators, to inform our investment decisions. Our investment team, which includes experienced portfolio managers and analysts, works together to identify attractive investment opportunities and manage the portfolio.\n",
      "\n",
      "Overall, our investment strategy is designed to provide a balanced approach to investing, with a focus on generating absolute returns while managing risk. By combining elements of long-short equity, global macro, and event-driven investing, we aim to deliver strong performance across various market conditions.\n",
      "CPU times: user 42 ms, sys: 9.06 ms, total: 51 ms\n",
      "Wall time: 7.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "q = questions[0]\n",
    "\n",
    "answer = llm('''\n",
    "Answer the question:\n",
    "%s\n",
    "''' % q, model=LLM, temperature=TEMPERATURE).choices[0].message.content\n",
    "\n",
    "print(q + '\\n\\n' + answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0260cb3f-5a54-4d43-8d18-c0d312c5db62",
   "metadata": {},
   "source": [
    "### Try Augmented RAG on the first sub question\n",
    "\n",
    "Here we have tried Augmented RAG on the first question itself by passing the augment value as True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e2b39929-6576-4901-9596-24f4fdf67749",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response: 0h 0m 8.2693s \n",
      "\n",
      "Embedding the User Query: 0h 0m 0.0138s \n",
      "\n",
      "KDB.AI Similarity Search: 0h 0m 13.0958s \n",
      "\n",
      "LLM Response: 0h 0m 8.2159s \n",
      "\n",
      "Total RAG response time: 0h 0m 29.5958s \n",
      "\n",
      "---------------------------------------------- \n",
      "\n",
      "Assistant: Based on the provided JSON context, I can infer that the investment strategy of our hedge fund is a combination of long-short equity, global macro, and event-driven investing, with a focus on generating absolute returns and minimizing risk.\n",
      "\n",
      "For example, the paper \"Combining Independent Smart Beta Strategies for Portfolio Optimization\" (2018-08-13, Phil Maguire, Karl Moffett, Rebecca Maguire) discusses the idea of combining multiple smart beta strategies to generate beta-neutral returns. This approach is similar to our hedge fund's long-short equity strategy, which aims to identify mispricings in the market and generate absolute returns.\n",
      "\n",
      "Another example is the paper \"Intelligent Systematic Investment Agent: an ensemble of deep learning and evolutionary strategies\" (2022-03-25, Prasang Gupta, Shaz Hoda, Anand Rao), which proposes a new approach for developing long-term investment strategies using an ensemble of evolutionary algorithms and a deep learning model. This approach is similar to our hedge fund's global macro strategy, which involves making tactical bets on macroeconomic trends and using a combination of top-down and bottom-up approaches to identify opportunities and risks.\n",
      "\n",
      "Finally, the paper \"Trade the Event: Corporate Events Detection for News-Based Event-Driven Trading\" (2021-05-31, Zhihan Zhou, Liqian Ma, Han Liu) discusses the idea of detecting corporate events from news articles and using this information to make stock predictions. This approach is similar to our hedge fund's event-driven strategy, which focuses on identifying opportunities arising from corporate events.\n",
      "\n",
      "Overall, our hedge fund's investment strategy is a combination of these approaches, with a focus on generating absolute returns and minimizing risk.\n",
      "\n",
      "References:\n",
      "\n",
      "* Maguire, P., Moffett, K., & Maguire, R. (2018, August 13). Combining Independent Smart Beta Strategies for Portfolio Optimization.\n",
      "* Gupta, P., Hoda, S., & Rao, A. (2022, March 25). Intelligent Systematic Investment Agent: an ensemble of deep learning and evolutionary strategies.\n",
      "* Zhou, Z., Ma, L., & Liu, H. (2021, May 31). Trade the Event: Corporate Events Detection for News-Based Event-Driven Trading.\n",
      "CPU times: user 11.1 s, sys: 2.16 s, total: 13.3 s\n",
      "Wall time: 29.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "K = 10\n",
    "\n",
    "answer, ctx = prompt(q, k=K, filter=[[\"like\",\"text\",\"*trading*\"]], augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "51c8a881-7159-4dd2-89c4-6407bf6d83d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[{\"title\":\"A Deep Deterministic Policy Gradient-based Strategy for Stocks '\n",
      " 'Portfolio\\\\n  '\n",
      " 'Management\",\"update_date\":\"2021-03-23T00:00:00.000\",\"authors\":\"Huanming '\n",
      " 'Zhang, Zhengyong Jiang, Jionglong Su\",\"text\":\"Title: A Deep Deterministic '\n",
      " 'Policy Gradient-based Strategy for Stocks Portfolio\\\\n  Management\\\\nDate: '\n",
      " '2021-03-23 00:00:00\\\\nAuthors: Huanming Zhang, Zhengyong Jiang, Jionglong '\n",
      " 'Su\\\\nAbstract:   With the improvement of computer performance and the '\n",
      " 'development of\\\\nGPU-accelerated technology, trading with machine learning '\n",
      " 'algorithms has\\\\nattracted the attention of many researchers and '\n",
      " 'practitioners. In this\\\\nresearch, we propose a novel portfolio management '\n",
      " 'strategy based on the\\\\nframework of Deep Deterministic Policy Gradient, a '\n",
      " 'policy-based reinforcement\\\\nlearning framework, and compare its performance '\n",
      " 'to that of other trading\\\\nstrategies. In our framework, two Long Short-Term '\n",
      " 'Memory neural networks and\\\\ntwo fully connected neural networks are '\n",
      " 'constructed. We also investigate the\\\\nperformance of our strategy with and '\n",
      " 'without transaction costs. Experimentally,\\\\nwe choose eight US stocks '\n",
      " 'consisting of four low-volatility stocks and four\\\\nhigh-volatility stocks. '\n",
      " 'We compare the compound annual return rate of our\\\\nstrategy against seven '\n",
      " 'other strategies, e.g., Uniform Buy and Hold,\\\\nExponential Gradient and '\n",
      " 'Universal Portfolios. In our case, the compound annual\\\\nreturn rate is '\n",
      " '14.12%, outperforming all other strategies. Furthermore, in\\\\nterms of '\n",
      " 'Sharpe Ratio (0.5988), our strategy is nearly 33% higher than that of\\\\nthe '\n",
      " 'second-best performing strategy.\\\\n\\\\n\"},{\"title\":\"Quant 4.0: Engineering '\n",
      " 'Quantitative Investment with Automated,\\\\n  Explainable and Knowledge-driven '\n",
      " 'Artificial '\n",
      " 'Intelligence\",\"update_date\":\"2023-01-11T00:00:00.000\",\"authors\":\"Jian Guo, '\n",
      " 'Saizhuo Wang, Lionel M. Ni, Heung-Yeung Shum\",\"text\":\"Title: Quant 4.0: '\n",
      " 'Engineering Quantitative Investment with Automated,\\\\n  Explainable and '\n",
      " 'Knowledge-driven Artificial Intelligence\\\\nDate: 2023-01-11 '\n",
      " '00:00:00\\\\nAuthors: Jian Guo, Saizhuo Wang, Lionel M. Ni, Heung-Yeung '\n",
      " \"Shum\\\\nAbstract:   Quantitative investment (``quant'') is an \"\n",
      " 'interdisciplinary field combining\\\\nfinancial engineering, computer science, '\n",
      " 'mathematics, statistics, etc. Quant\\\\nhas become one of the mainstream '\n",
      " 'investment methodologies over the past\\\\ndecades, and has experienced three '\n",
      " 'generations: Quant 1.0, trading by\\\\nmathematical modeling to discover '\n",
      " 'mis-priced assets in markets; Quant 2.0,\\\\nshifting quant research pipeline '\n",
      " \"from small ``strategy workshops'' to large\\\\n``alpha factories''; Quant 3.0, \"\n",
      " 'applying deep learning techniques to discover\\\\ncomplex nonlinear pricing '\n",
      " 'rules. Despite its advantage in prediction, deep\\\\nlearning relies on '\n",
      " \"extremely large data volume and labor-intensive tuning of\\\\n``black-box'' \"\n",
      " 'neural network models. To address these limitations, in this\\\\npaper, we '\n",
      " 'introduce Quant 4.0 and provide an engineering perspective '\n",
      " 'for\\\\nnext-generation quant. Quant 4.0 has three key differentiating '\n",
      " 'components.\\\\nFirst, automated AI changes quant pipeline from traditional '\n",
      " 'hand-craft modeling\\\\nto the state-of-the-art automated modeling, practicing '\n",
      " 'the philosophy of\\\\n``algorithm produces algorithm, model builds model, and '\n",
      " \"eventually AI creates\\\\nAI''. Second, explainable AI develops new techniques \"\n",
      " 'to better understand and\\\\ninterpret investment decisions made by machine '\n",
      " 'learning black-boxes, and\\\\nexplains complicated and hidden risk exposures. '\n",
      " 'Third, knowledge-driven AI is a\\\\nsupplement to data-driven AI such as deep '\n",
      " 'learning and it incorporates prior\\\\nknowledge into modeling to improve '\n",
      " 'investment decision, in particular for\\\\nquantitative value investing. '\n",
      " 'Moreover, we discuss how to build a system that\\\\npractices the Quant 4.0 '\n",
      " 'concept. Finally, we propose ten challenging research\\\\nproblems for quant '\n",
      " 'technology, and discuss potential solutions, research\\\\ndirections, and '\n",
      " 'future trends.\\\\n\\\\n\"},{\"title\":\"Concepts, Components and Collections of '\n",
      " 'Trading Strategies and Market\\\\n  '\n",
      " 'Color\",\"update_date\":\"2020-01-14T00:00:00.000\",\"authors\":\"Ravi '\n",
      " 'Kashyap\",\"text\":\"Title: Concepts, Components and Collections of Trading '\n",
      " 'Strategies and Market\\\\n  Color\\\\nDate: 2020-01-14 00:00:00\\\\nAuthors: Ravi '\n",
      " 'Kashyap\\\\nAbstract:   This paper acts as a collection of various trading '\n",
      " 'strategies and useful\\\\npieces of market information that might help to '\n",
      " 'implement such strategies. This\\\\nlist is meant to be comprehensive (though '\n",
      " 'by no means exhaustive) and hence we\\\\nonly provide pointers and give '\n",
      " 'further sources to explore each strategy\\\\nfurther. To set the stage for '\n",
      " 'this exploration, we consider the factors that\\\\ndetermine good and bad '\n",
      " 'trades, the notions of market efficiency, the real\\\\nprospect amidst the '\n",
      " 'seemingly high expectations of homogeneous expectations\\\\nfrom human beings '\n",
      " 'and the catch-22 connotations that arise while comprehending\\\\nthe true '\n",
      " 'meaning of rational investing. We can broadly classify trading ideas\\\\nand '\n",
      " 'client market color material into Delta-One and Derivative strategies '\n",
      " 'since\\\\nthis acts as a natural categorization that depends on the expertise '\n",
      " 'of the\\\\nvarious trading desks that will implement these strategies. For '\n",
      " 'each strategy,\\\\nwe will have a core idea and we will present different '\n",
      " 'flavors of this central\\\\ntheme to demonstrate that we can easily cater to '\n",
      " 'the varying risk appetites,\\\\nregional preferences, asset management styles, '\n",
      " 'investment philosophies,\\\\nliability constraints, investment horizons, '\n",
      " 'notional trading size, trading\\\\nfrequency and other preferences of '\n",
      " 'different market participants.\\\\n\\\\n\"},{\"title\":\"Combining Independent Smart '\n",
      " 'Beta Strategies for Portfolio '\n",
      " 'Optimization\",\"update_date\":\"2018-08-13T00:00:00.000\",\"authors\":\"Phil '\n",
      " 'Maguire, Karl Moffett, Rebecca Maguire\",\"text\":\"Title: Combining Independent '\n",
      " 'Smart Beta Strategies for Portfolio Optimization\\\\nDate: 2018-08-13 '\n",
      " '00:00:00\\\\nAuthors: Phil Maguire, Karl Moffett, Rebecca '\n",
      " 'Maguire\\\\nAbstract:   Smart beta, also known as strategic beta or factor '\n",
      " 'investing, is the idea of\\\\nselecting an investment portfolio in a simple '\n",
      " 'rule-based manner that\\\\nsystematically captures market inefficiencies, '\n",
      " 'thereby enhancing risk-adjusted\\\\nreturns above capitalization-weighted '\n",
      " 'benchmarks. We explore the idea of\\\\napplying a smart strategy in reverse, '\n",
      " 'yielding a \\\\\"bad beta\\\\\" portfolio which can\\\\nbe shorted, thus allowing '\n",
      " 'long and short positions on independent smart beta\\\\nstrategies to generate '\n",
      " 'beta neutral returns. In this article we detail the\\\\nconstruction of a '\n",
      " 'monthly reweighted portfolio involving two independent smart\\\\nbeta '\n",
      " 'strategies; the first component is a long-short beta-neutral '\n",
      " 'strategy\\\\nderived from running an adaptive boosting classifier on a suite '\n",
      " 'of momentum\\\\nindicators. The second component is a minimized volatility '\n",
      " 'portfolio which\\\\nexploits the observation that low-volatility stocks tend '\n",
      " 'to yield higher\\\\nrisk-adjusted returns than high-volatility stocks. Working '\n",
      " 'off a market\\\\nbenchmark Sharpe Ratio of 0.42, we find that the market '\n",
      " 'neutral component\\\\nachieves a ratio of 0.61, the low volatility approach '\n",
      " 'achieves a ratio of 0.90,\\\\nwhile the combined leveraged strategy achieves a '\n",
      " 'ratio of 0.96. In six months\\\\nof live trading, the combined strategy '\n",
      " 'achieved a Sharpe Ratio of 1.35. These\\\\nresults reinforce the effectiveness '\n",
      " 'of smart beta strategies, and demonstrate\\\\nthat combining multiple '\n",
      " 'strategies simultaneously can yield better performance\\\\nthan that achieved '\n",
      " 'by any single component in isolation.\\\\n\\\\n\"},{\"title\":\"Intelligent '\n",
      " 'Systematic Investment Agent: an ensemble of deep learning\\\\n  and '\n",
      " 'evolutionary '\n",
      " 'strategies\",\"update_date\":\"2022-03-25T00:00:00.000\",\"authors\":\"Prasang '\n",
      " 'Gupta, Shaz Hoda and Anand Rao\",\"text\":\"Title: Intelligent Systematic '\n",
      " 'Investment Agent: an ensemble of deep learning\\\\n  and evolutionary '\n",
      " 'strategies\\\\nDate: 2022-03-25 00:00:00\\\\nAuthors: Prasang Gupta, Shaz Hoda '\n",
      " 'and Anand Rao\\\\nAbstract:   Machine learning driven trading strategies have '\n",
      " 'garnered a lot of interest\\\\nover the past few years. There is, however, '\n",
      " 'limited consensus on the ideal\\\\napproach for the development of such '\n",
      " 'trading strategies. Further, most\\\\nliterature has focused on trading '\n",
      " 'strategies for short-term trading, with\\\\nlittle or no focus on strategies '\n",
      " 'that attempt to build long-term wealth. Our\\\\npaper proposes a new approach '\n",
      " 'for developing long-term investment strategies\\\\nusing an ensemble of '\n",
      " 'evolutionary algorithms and a deep learning model by\\\\ntaking a series of '\n",
      " 'short-term purchase decisions. Our methodology focuses on\\\\nbuilding '\n",
      " 'long-term wealth by improving systematic investment planning '\n",
      " '(SIP)\\\\ndecisions on Exchange Traded Funds (ETF) over a period of time. We '\n",
      " 'provide\\\\nempirical evidence of superior performance (around 1% higher '\n",
      " 'returns) using our\\\\nensemble approach as compared to the traditional daily '\n",
      " 'systematic investment\\\\npractice on a given ETF. Our results are based on '\n",
      " 'live trading decisions made\\\\nby our algorithm and executed on the Robinhood '\n",
      " 'trading platform.\\\\n\\\\n\"},{\"title\":\"Balancing Profit, Risk, and '\n",
      " 'Sustainability for Portfolio '\n",
      " 'Management\",\"update_date\":\"2022-07-06T00:00:00.000\",\"authors\":\"Charl Maree '\n",
      " 'and Christian W. Omlin\",\"text\":\"Title: Balancing Profit, Risk, and '\n",
      " 'Sustainability for Portfolio Management\\\\nDate: 2022-07-06 '\n",
      " '00:00:00\\\\nAuthors: Charl Maree and Christian W. Omlin\\\\nAbstract:   Stock '\n",
      " 'portfolio optimization is the process of continuous reallocation of\\\\nfunds '\n",
      " 'to a selection of stocks. This is a particularly well-suited problem '\n",
      " 'for\\\\nreinforcement learning, as daily rewards are compounding and '\n",
      " 'objective\\\\nfunctions may include more than just profit, e.g., risk and '\n",
      " 'sustainability. We\\\\ndeveloped a novel utility function with the Sharpe '\n",
      " 'ratio representing risk and\\\\nthe environmental, social, and governance '\n",
      " 'score (ESG) representing\\\\nsustainability. We show that a state-of-the-art '\n",
      " 'policy gradient method -\\\\nmulti-agent deep deterministic policy gradients '\n",
      " '(MADDPG) - fails to find the\\\\noptimum policy due to flat policy gradients '\n",
      " 'and we therefore replaced gradient\\\\ndescent with a genetic algorithm for '\n",
      " 'parameter optimization. We show that our\\\\nsystem outperforms MADDPG while '\n",
      " 'improving on deep Q-learning approaches by\\\\nallowing for continuous action '\n",
      " 'spaces. Crucially, by incorporating risk and\\\\nsustainability criteria in '\n",
      " 'the utility function, we improve on the\\\\nstate-of-the-art in reinforcement '\n",
      " 'learning for portfolio optimization; risk and\\\\nsustainability are essential '\n",
      " 'in any modern trading strategy and we propose a\\\\nsystem that does not '\n",
      " 'merely report these metrics, but that actively optimizes\\\\nthe portfolio to '\n",
      " 'improve on them.\\\\n\\\\n\"},{\"title\":\"Multi-Factor Inception: What to Do with '\n",
      " 'All of These '\n",
      " 'Features?\",\"update_date\":\"2023-07-27T00:00:00.000\",\"authors\":\"Tom Liu, '\n",
      " 'Stefan Zohren\",\"text\":\"Title: Multi-Factor Inception: What to Do with All of '\n",
      " 'These Features?\\\\nDate: 2023-07-27 00:00:00\\\\nAuthors: Tom Liu, Stefan '\n",
      " 'Zohren\\\\nAbstract:   Cryptocurrency trading represents a nascent field of '\n",
      " 'research, with growing\\\\nadoption in industry. Aided by its decentralised '\n",
      " 'nature, many metrics\\\\ndescribing cryptocurrencies are accessible with a '\n",
      " 'simple Google search and\\\\nupdate frequently, usually at least on a daily '\n",
      " 'basis. This presents a promising\\\\nopportunity for data-driven systematic '\n",
      " 'trading research, where limited\\\\nhistorical data can be augmented with '\n",
      " 'additional features, such as hashrate or\\\\nGoogle Trends. However, one '\n",
      " 'question naturally arises: how to effectively\\\\nselect and process these '\n",
      " 'features? In this paper, we introduce Multi-Factor\\\\nInception Networks '\n",
      " '(MFIN), an end-to-end framework for systematic trading with\\\\nmultiple '\n",
      " 'assets and factors. MFINs extend Deep Inception Networks (DIN) to\\\\noperate '\n",
      " 'in a multi-factor context. Similar to DINs, MFIN models '\n",
      " 'automatically\\\\nlearn features from returns data and output position sizes '\n",
      " 'that optimise\\\\nportfolio Sharpe ratio. Compared to a range of rule-based '\n",
      " 'momentum and\\\\nreversion strategies, MFINs learn an uncorrelated, '\n",
      " 'higher-Sharpe strategy that\\\\nis not captured by traditional, hand-crafted '\n",
      " 'factors. In particular, MFIN\\\\nmodels continue to achieve consistent returns '\n",
      " 'over the most recent years\\\\n(2022-2023), where traditional strategies and '\n",
      " 'the wider cryptocurrency market\\\\nhave '\n",
      " 'underperformed.\\\\n\\\\n\"},{\"title\":\"Trade the Event: Corporate Events '\n",
      " 'Detection for News-Based Event-Driven\\\\n  '\n",
      " 'Trading\",\"update_date\":\"2021-05-31T00:00:00.000\",\"authors\":\"Zhihan Zhou, '\n",
      " 'Liqian Ma, Han Liu\",\"text\":\"Title: Trade the Event: Corporate Events '\n",
      " 'Detection for News-Based Event-Driven\\\\n  Trading\\\\nDate: 2021-05-31 '\n",
      " '00:00:00\\\\nAuthors: Zhihan Zhou, Liqian Ma, Han Liu\\\\nAbstract:   In this '\n",
      " 'paper, we introduce an event-driven trading strategy that predicts\\\\nstock '\n",
      " 'movements by detecting corporate events from news articles. '\n",
      " 'Unlike\\\\nexisting models that utilize textual features (e.g., bag-of-words) '\n",
      " 'and\\\\nsentiments to directly make stock predictions, we consider corporate '\n",
      " 'events as\\\\nthe driving force behind stock movements and aim to profit from '\n",
      " 'the temporary\\\\nstock mispricing that may occur when corporate events take '\n",
      " 'place. The core of\\\\nthe proposed strategy is a bi-level event detection '\n",
      " \"model. The low-level event\\\\ndetector identifies events' existences from \"\n",
      " 'each token, while the high-level\\\\nevent detector incorporates the entire '\n",
      " \"article's representation and the\\\\nlow-level detected results to discover \"\n",
      " 'events at the article-level. We also\\\\ndevelop an elaborately-annotated '\n",
      " 'dataset EDT for corporate event detection and\\\\nnews-based stock prediction '\n",
      " 'benchmark. EDT includes 9721 news articles with\\\\ntoken-level event labels '\n",
      " 'as well as 303893 news articles with minute-level\\\\ntimestamps and '\n",
      " 'comprehensive stock price labels. Experiments on EDT indicate\\\\nthat the '\n",
      " 'proposed strategy outperforms all the baselines in winning rate,\\\\nexcess '\n",
      " 'returns over the market, and the average return on each '\n",
      " 'transaction.\\\\n\\\\n\"},{\"title\":\"Towards Evology: a Market Ecology Agent-Based '\n",
      " 'Model of US Equity Mutual\\\\n  '\n",
      " 'Funds\",\"update_date\":\"2022-10-26T00:00:00.000\",\"authors\":\"Aymeric Vie, '\n",
      " 'Maarten Scholl, Alissa M. Kleinnijenhuis, J. Doyne Farmer\",\"text\":\"Title: '\n",
      " 'Towards Evology: a Market Ecology Agent-Based Model of US Equity Mutual\\\\n  '\n",
      " 'Funds\\\\nDate: 2022-10-26 00:00:00\\\\nAuthors: Aymeric Vie, Maarten Scholl, '\n",
      " 'Alissa M. Kleinnijenhuis, J. Doyne Farmer\\\\nAbstract:   The profitability of '\n",
      " 'various investment styles in investment funds depends on\\\\nmacroeconomic '\n",
      " 'conditions. Market ecology, which views financial markets as\\\\necosystems of '\n",
      " 'diverse, interacting and evolving trading strategies, has shown\\\\nthat '\n",
      " 'endogenous interactions between strategies determine market behaviour '\n",
      " \"and\\\\nstyles' performance. We present Evology: a heterogeneous, \"\n",
      " 'empirically\\\\ncalibrated multi-agent market ecology agent-based model to '\n",
      " 'quantify endogenous\\\\ninteractions between US equity mutual funds, '\n",
      " 'particularly Value and Growth\\\\ninvestment styles. We outline the model '\n",
      " 'design, validation and calibration\\\\napproach and its potential for '\n",
      " 'optimising investment strategies using machine\\\\nlearning '\n",
      " 'algorithms.\\\\n\\\\n\"},{\"title\":\"Learning the Market: Sentiment-Based Ensemble '\n",
      " 'Trading Agents\",\"update_date\":\"2024-02-05T00:00:00.000\",\"authors\":\"Andrew '\n",
      " 'Ye, James Xu, Yi Wang, Yifan Yu, Daniel Yan, Ryan Chen, Bosheng\\\\n  Dong, '\n",
      " 'Vipin Chaudhary, Shuai Xu\",\"text\":\"Title: Learning the Market: '\n",
      " 'Sentiment-Based Ensemble Trading Agents\\\\nDate: 2024-02-05 '\n",
      " '00:00:00\\\\nAuthors: Andrew Ye, James Xu, Yi Wang, Yifan Yu, Daniel Yan, Ryan '\n",
      " 'Chen, Bosheng\\\\n  Dong, Vipin Chaudhary, Shuai Xu\\\\nAbstract:   We propose '\n",
      " 'the integration of sentiment analysis and deep-reinforcement\\\\nlearning '\n",
      " 'ensemble algorithms for stock trading, and design a strategy capable\\\\nof '\n",
      " 'dynamically altering its employed agent given concurrent market '\n",
      " 'sentiment.\\\\nIn particular, we create a simple-yet-effective method for '\n",
      " 'extracting news\\\\nsentiment and combine this with general improvements upon '\n",
      " 'existing works,\\\\nresulting in automated trading agents that effectively '\n",
      " 'consider both\\\\nqualitative market factors and quantitative stock data. We '\n",
      " 'show that our\\\\napproach results in a strategy that is profitable, robust, '\n",
      " 'and risk-minimal --\\\\noutperforming the traditional ensemble strategy as '\n",
      " 'well as single agent\\\\nalgorithms and market metrics. Our findings determine '\n",
      " 'that the conventional\\\\npractice of switching ensemble agents every '\n",
      " 'fixed-number of months is\\\\nsub-optimal, and that a dynamic sentiment-based '\n",
      " 'framework greatly unlocks\\\\nadditional performance within these agents. '\n",
      " 'Furthermore, as we have designed\\\\nour algorithm with simplicity and '\n",
      " 'efficiency in mind, we hypothesize that the\\\\ntransition of our method from '\n",
      " 'historical evaluation towards real-time trading\\\\nwith live data should be '\n",
      " 'relatively simple.\\\\n\\\\n\"}]')\n"
     ]
    }
   ],
   "source": [
    "pprint(ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f112a3c-af69-49ee-85ba-b877a6e08fed",
   "metadata": {},
   "source": [
    "### Answer all sub questions with Augmented RAG and keep track of the history of the conversation\n",
    "\n",
    "Now we try to answer all the sub-questions with Augmented RAG and generate the result together by saving the answers of each question repeated and then displaying the result in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "011070fc-2977-4e89-8d13-9b379c60f5d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is the investment strategy of your Hedge Fund (e.g., long-short equity, global macro, event-driven)?\n",
      "\n",
      "LLM Response: 0h 0m 8.2130s \n",
      "\n",
      "Embedding the User Query: 0h 0m 0.0120s \n",
      "\n",
      "KDB.AI Similarity Search: 0h 0m 13.0806s \n",
      "\n",
      "LLM Response: 0h 0m 8.1677s \n",
      "\n",
      "Total RAG response time: 0h 0m 29.4742s \n",
      "\n",
      "---------------------------------------------- \n",
      "\n",
      "Assistant: Based on the provided JSON context, I can infer that the investment strategy of our hedge fund is a combination of long-short equity, global macro, and event-driven investing, with a focus on generating absolute returns and minimizing risk.\n",
      "\n",
      "For example, the paper \"Combining Independent Smart Beta Strategies for Portfolio Optimization\" (2018-08-13, Phil Maguire, Karl Moffett, Rebecca Maguire) discusses the idea of combining multiple smart beta strategies to generate beta-neutral returns. This approach is similar to our hedge fund's long-short equity strategy, which aims to identify mispricings in the market and generate absolute returns.\n",
      "\n",
      "Another example is the paper \"Intelligent Systematic Investment Agent: an ensemble of deep learning and evolutionary strategies\" (2022-03-25, Prasang Gupta, Shaz Hoda, Anand Rao), which proposes a new approach for developing long-term investment strategies using an ensemble of evolutionary algorithms and a deep learning model. This approach is similar to our hedge fund's global macro strategy, which involves making tactical bets on macroeconomic trends and using a combination of top-down and bottom-up approaches to identify opportunities and risks.\n",
      "\n",
      "Finally, the paper \"Trade the Event: Corporate Events Detection for News-Based Event-Driven Trading\" (2021-05-31, Zhihan Zhou, Liqian Ma, Han Liu) discusses the idea of detecting corporate events from news articles and using this information to make stock predictions. This approach is similar to our hedge fund's event-driven strategy, which focuses on identifying opportunities arising from corporate events.\n",
      "\n",
      "Overall, our hedge fund's investment strategy is a combination of these approaches, with a focus on generating absolute returns and minimizing risk.\n",
      "\n",
      "References:\n",
      "\n",
      "* Maguire, P., Moffett, K., & Maguire, R. (2018, August 13). Combining Independent Smart Beta Strategies for Portfolio Optimization.\n",
      "* Gupta, P., Hoda, S., & Rao, A. (2022, March 25). Intelligent Systematic Investment Agent: an ensemble of deep learning and evolutionary strategies.\n",
      "* Zhou, Z., Ma, L., & Liu, H. (2021, May 31). Trade the Event: Corporate Events Detection for News-Based Event-Driven Trading.\n",
      "\n",
      "\n",
      "\n",
      "User: What are your current data sources for making investment decisions?\n",
      "\n",
      "LLM Response: 0h 0m 7.1175s \n",
      "\n",
      "Embedding the User Query: 0h 0m 0.0130s \n",
      "\n",
      "KDB.AI Similarity Search: 0h 0m 13.0854s \n",
      "\n",
      "LLM Response: 0h 0m 5.5505s \n",
      "\n",
      "Total RAG response time: 0h 0m 25.7680s \n",
      "\n",
      "---------------------------------------------- \n",
      "\n",
      "Assistant: As a quantitative trader, my current data sources for making investment decisions include publicly available news articles, social media data, and financial time series data.\n",
      "\n",
      "For instance, I use news articles to extract sentiment scores and employ tools from information theory to quantify the information transfer from public news articles to the U.S. stock market, as described in the paper \"On the impact of publicly available news and information transfer to financial markets\" by Metod Jazbec, Barna Pásztor, Felix Faltings, Nino Antulov-Fantulin, and Petter N. Kolm (2020-10-26).\n",
      "\n",
      "I also utilize social media data, such as tweets, to label stocks as Buy or Sell dependent on whether the stock price discussed rose or fell over the following hour, and build stock-specific dictionaries for individual companies, as mentioned in the paper \"Using Stock Prices as Ground Truth in Sentiment Analysis to Generate Profitable Trading Signals\" by Ellie Birbeck and Dave Cliff (2018-11-08).\n",
      "\n",
      "Additionally, I leverage financial time series data, such as stock prices and trading volumes, to develop and evaluate trading strategies, including those that utilize data augmentation methods, as discussed in the paper \"Evaluating data augmentation for financial time series classification\" by Elizabeth Fons, Paula Dawson, Xiao-jun Zeng, John Keane, and Alexandros Iosifidis (2020-10-29).\n",
      "\n",
      "These data sources provide me with valuable insights and information to inform my investment decisions and develop profitable trading strategies.\n",
      "\n",
      "\n",
      "\n",
      "User: What are your goals for using Streaming Analytics and AI (e.g., improve predictive models, increase trading efficiency, enhance risk management)?\n",
      "\n",
      "LLM Response: 0h 0m 8.5077s \n",
      "\n",
      "Embedding the User Query: 0h 0m 0.0122s \n",
      "\n",
      "KDB.AI Similarity Search: 0h 0m 13.0851s \n",
      "\n",
      "LLM Response: 0h 0m 6.8601s \n",
      "\n",
      "Total RAG response time: 0h 0m 28.4660s \n",
      "\n",
      "---------------------------------------------- \n",
      "\n",
      "Assistant: As a quantitative trader, my goals for using Streaming Analytics and AI are to improve predictive models, increase trading efficiency, and enhance risk management.\n",
      "\n",
      "**Improve predictive models:**\n",
      "\n",
      "I aim to enhance my forecasting and predictive analytics capabilities to better anticipate market trends and potential risks. For instance, the paper \"Combining Machine Learning Classifiers for Stock Trading with Effective Feature Extraction\" (2023-08-14, A. K. M. Amanat Ullah et al.) demonstrates the effectiveness of combining machine learning classifiers for stock trading. By using ensemble learning with four classifiers, the authors achieved a 54.35% profit in daily trades between July 2011 and January 2019.\n",
      "\n",
      "**Increase trading efficiency:**\n",
      "\n",
      "I seek to automate trading decisions and optimize portfolio management using real-time data and AI-driven insights. The paper \"Learning the Market: Sentiment-Based Ensemble Trading Agents\" (2024-02-05, Andrew Ye et al.) presents a strategy that integrates sentiment analysis and deep-reinforcement learning ensemble algorithms for stock trading. The authors show that their approach outperforms traditional ensemble strategies and single-agent algorithms, achieving a profitable, robust, and risk-minimal performance.\n",
      "\n",
      "**Enhance risk management:**\n",
      "\n",
      "I aim to identify potential risks and anomalies in real-time, enabling proactive measures to mitigate losses and ensure regulatory compliance. The paper \"The AI Revolution: Opportunities and Challenges for the Finance Sector\" (2023-09-01, Carsten Maple et al.) highlights the importance of risk management in the finance sector, particularly in the context of AI adoption. The authors emphasize the need for effective regulation to harness the benefits of AI while mitigating its potential risks.\n",
      "\n",
      "By leveraging Streaming Analytics and AI, I can improve my predictive models, increase trading efficiency, and enhance risk management, ultimately leading to better trading outcomes and reduced risks.\n",
      "\n",
      "\n",
      "\n",
      "User: What type of market tick data do you have access to (e.g., stocks, options, futures, forex)?\n",
      "\n",
      "LLM Response: 0h 0m 4.3229s \n",
      "\n",
      "Embedding the User Query: 0h 0m 0.0125s \n",
      "\n",
      "KDB.AI Similarity Search: 0h 0m 13.1236s \n",
      "\n",
      "LLM Response: 0h 0m 3.7965s \n",
      "\n",
      "Total RAG response time: 0h 0m 21.2564s \n",
      "\n",
      "---------------------------------------------- \n",
      "\n",
      "Assistant: Based on the provided JSON context, I have access to tick data for cryptocurrencies, specifically Bitcoin and Ethereum.\n",
      "\n",
      "For example, the paper \"Analysis of inter-transaction time fluctuations in the cryptocurrency market\" by Jarosław Kwapień, Marcin Wątorek, Marija Bezbradica, Martin Crane, Tai Tan Mai, and Stanisław Drożdż (2022-09-05) analyzes tick-by-tick data for major cryptocurrencies traded on different cryptocurrency trading platforms.\n",
      "\n",
      "Another example is the paper \"Decomposing cryptocurrency high-frequency price dynamics into recurring and noisy components\" by Marcin Wątorek, Maria Skupień, Jarosław Kwapień, and Stanisław Drożdż (2023-08-22), which investigates the temporal patterns of activity in the cryptocurrency market with a focus on Bitcoin, Ethereum, Dogecoin, and WINkLink.\n",
      "\n",
      "These papers demonstrate that I have access to tick data for cryptocurrencies, which can be used for analysis and trading purposes.\n",
      "\n",
      "\n",
      "\n",
      "User: How do you currently process and analyze market tick data (e.g., time-series analysis, statistical models)?\n",
      "\n",
      "LLM Response: 0h 0m 8.7500s \n",
      "\n",
      "Embedding the User Query: 0h 0m 0.0122s \n",
      "\n",
      "KDB.AI Similarity Search: 0h 0m 13.1096s \n",
      "\n",
      "LLM Response: 0h 0m 9.9591s \n",
      "\n",
      "Total RAG response time: 0h 0m 31.8317s \n",
      "\n",
      "---------------------------------------------- \n",
      "\n",
      "Assistant: As a quantitative trader, I can attest that processing and analyzing market tick data is a crucial task in our field. Based on the provided JSON context, I can see that several researchers have proposed various methods for analyzing market tick data.\n",
      "\n",
      "For instance, the paper \"Integrating Tick-level Data and Periodical Signal for High-frequency Market Making\" by Jiafa He, Cong Zheng, and Can Yang (2023-07-03) proposes a deep reinforcement learning approach that fuses tick-level data with periodic prediction signals to develop a more accurate and robust market making strategy.\n",
      "\n",
      "Another example is the paper \"Compatible deep neural network framework with financial time series data, including data preprocessor, neural network model and trading strategy\" by Mohammadmahdi Ghahramani and Hamid Esmaeili Najafabadi (2022-05-18), which introduces a new deep neural network architecture and a novel idea of how to prepare financial data before feeding them to the model.\n",
      "\n",
      "In terms of statistical models, the paper \"A Study on Stock Forecasting Using Deep Learning and Statistical Models\" by Himanshu Gupta and Aditya Jaiswal (2024-02-13) reviews various deep learning algorithms for stock price forecasting and compares their performance with statistical models like ARIMA and Moving Averages.\n",
      "\n",
      "Furthermore, the paper \"Learning Non-Stationary Time-Series with Dynamic Pattern Extractions\" by Xipei Wang et al. (2021-11-23) proposes a combination of seq2seq model based on RNN, along with an attention mechanism and an enriched set features extracted via dynamic time warping and zigzag peak valley indicators, to predict future trends of non-stationary time-series sequences.\n",
      "\n",
      "These papers demonstrate the various approaches that can be used to process and analyze market tick data, including time-series analysis, statistical models, and machine learning techniques.\n",
      "\n",
      "References:\n",
      "\n",
      "* He, J., Zheng, C., & Yang, C. (2023-07-03). Integrating Tick-level Data and Periodical Signal for High-frequency Market Making.\n",
      "* Ghahramani, M., & Najafabadi, H. E. (2022-05-18). Compatible deep neural network framework with financial time series data, including data preprocessor, neural network model and trading strategy.\n",
      "* Gupta, H., & Jaiswal, A. (2024-02-13). A Study on Stock Forecasting Using Deep Learning and Statistical Models.\n",
      "* Wang, X., Zhang, H., Zhang, Y., Wang, M., Song, J., Lai, T., & Khushi, M. (2021-11-23). Learning Non-Stationary Time-Series with Dynamic Pattern Extractions.\n",
      "\n",
      "\n",
      "\n",
      "User: What specific insights or alpha-generating opportunities do you hope to uncover from market tick data using Streaming Analytics and AI?\n",
      "\n",
      "LLM Response: 0h 0m 9.1152s \n",
      "\n",
      "Embedding the User Query: 0h 0m 0.0128s \n",
      "\n",
      "KDB.AI Similarity Search: 0h 0m 13.0569s \n",
      "\n",
      "LLM Response: 0h 0m 9.3261s \n",
      "\n",
      "Total RAG response time: 0h 0m 31.5119s \n",
      "\n",
      "---------------------------------------------- \n",
      "\n",
      "Assistant: Based on the provided JSON context, I hope to uncover insights and alpha-generating opportunities from market tick data using Streaming Analytics and AI in the following areas:\n",
      "\n",
      "1. **Market Making Strategies**: The paper \"Integrating Tick-level Data and Periodical Signal for High-frequency Market Making\" (2023-07-03, Jiafa He, Cong Zheng, and Can Yang) proposes a deep reinforcement learning approach that fuses tick-level data with periodic prediction signals to develop a more accurate and robust market making strategy.\n",
      "\n",
      "2. **High-Frequency Trading (HFT) Strategies**: The paper \"Harnessing Deep Q-Learning for Enhanced Statistical Arbitrage in High-Frequency Trading: A Comprehensive Exploration\" (2023-11-21, Soumyadip Sarkar) explores the integration of reinforcement learning in statistical arbitrage strategies tailored for HFT scenarios, which can be applied to tick data analysis.\n",
      "\n",
      "3. **Intraday Trading Opportunities**: The paper \"DeepScalper: A Risk-Aware Reinforcement Learning Framework to Capture Fleeting Intraday Trading Opportunities\" (2022-08-23, Shuo Sun, Wanqi Xue, Rundong Wang, Xu He, Junlei Zhu, Jian Li, Bo An) proposes a deep reinforcement learning framework for intraday trading, which can be applied to tick data analysis to capture fleeting intraday investment opportunities.\n",
      "\n",
      "4. **Market Microstructure Analysis**: The paper \"Microstructure-Empowered Stock Factor Extraction and Utilization\" (2023-08-17, Xianfeng Jiao, Zizhong Li, Chang Xu, Yang Liu, Weiqing Liu, Jiang Bian) proposes a novel framework that aims to effectively extract essential factors from order flow data for diverse downstream tasks across different granularities and scenarios, which can be applied to tick data analysis.\n",
      "\n",
      "5. **Alpha Mining**: The paper \"Alpha-GPT: Human-AI Interactive Alpha Mining for Quantitative Investment\" (2023-08-02, Saizhuo Wang, Hang Yuan, Leon Zhou, Lionel M. Ni, Heung-Yeung Shum, Jian Guo) proposes a new alpha mining paradigm by introducing human-AI interaction, and a novel prompt engineering algorithmic framework to implement this paradigm by leveraging the power of large language models, which can be applied to tick data analysis to mine new alphas.\n",
      "\n",
      "These papers provide examples of how Streaming Analytics and AI can be applied to market tick data to uncover insights and generate alpha in various areas of quantitative trading.\n",
      "\n",
      "\n",
      "\n",
      "User: What types of unstructured data do you want to incorporate into your analysis (e.g., news articles, social media posts, company filings)?\n",
      "\n",
      "LLM Response: 0h 0m 8.6313s \n",
      "\n",
      "Embedding the User Query: 0h 0m 0.0125s \n",
      "\n",
      "KDB.AI Similarity Search: 0h 0m 13.1215s \n",
      "\n",
      "LLM Response: 0h 0m 4.8183s \n",
      "\n",
      "Total RAG response time: 0h 0m 26.5846s \n",
      "\n",
      "---------------------------------------------- \n",
      "\n",
      "Assistant: Based on the JSON context, the types of unstructured data that can be incorporated into analysis include news articles and tweets.\n",
      "\n",
      "For example, the paper \"On the impact of publicly available news and information transfer to financial markets\" by Metod Jazbec, Barna Pásztor, Felix Faltings, Nino Antulov-Fantulin, and Petter N. Kolm (2020-10-26) uses news archives from the Common Crawl to extract publicly available information and quantify the propagation and absorption of large-scale publicly available news articles from the World Wide Web to financial markets.\n",
      "\n",
      "Another example is the paper \"Mining Features Associated with Effective Tweets\" by Jian Xu and Nitesh Chawla (2017-06-26), which presents a systematic review of tweet time, entities, composition, and user account features to identify features associated with higher effectiveness in tweets.\n",
      "\n",
      "Additionally, the paper \"Using Stock Prices as Ground Truth in Sentiment Analysis to Generate Profitable Trading Signals\" by Ellie Birbeck and Dave Cliff (2018-11-08) uses tweets labelled as Buy or Sell dependent on whether the stock price discussed rose or fell over the following hour to generate stock predictions.\n",
      "\n",
      "These examples demonstrate the potential of incorporating news articles and tweets into analysis to gain insights into financial markets and make profitable trading decisions.\n",
      "\n",
      "\n",
      "\n",
      "User: How do you plan to preprocess and normalize the unstructured data for analysis (e.g., text processing, sentiment analysis)?\n",
      "\n",
      "LLM Response: 0h 0m 10.2578s \n",
      "\n",
      "Embedding the User Query: 0h 0m 0.0125s \n",
      "\n",
      "KDB.AI Similarity Search: 0h 0m 13.0516s \n",
      "\n",
      "LLM Response: 0h 0m 10.6650s \n",
      "\n",
      "Total RAG response time: 0h 0m 33.9878s \n",
      "\n",
      "---------------------------------------------- \n",
      "\n",
      "Assistant: To preprocess and normalize unstructured data for analysis, such as text processing and sentiment analysis, we can follow a structured approach. According to the JSON context, several papers provide insights into how to handle unstructured data, especially in the context of financial data analysis and sentiment analysis.\n",
      "\n",
      "Firstly, data collection is crucial. As mentioned in the paper \"Mining Features Associated with Effective Tweets\" by Jian Xu and Nitesh Chawla (2017-06-26), collecting a large dataset of tweets is essential for analyzing the effectiveness of tweets.\n",
      "\n",
      "Once the data is collected, preprocessing is necessary. The paper \"Financial data analysis application via multi-strategy text processing\" by Hongyin Zhu (2022-04-26) highlights the importance of text preprocessing, including tokenization, stemming, and lemmatization, to extract meaningful features from financial text data.\n",
      "\n",
      "Normalization is also a critical step. The paper \"FinLlama: Financial Sentiment Classification for Algorithmic Trading Applications\" by Thanos Konstantinidis et al. (2024-03-20) discusses the use of normalization techniques, such as converting all text to lowercase, to ensure consistency and reduce dimensionality.\n",
      "\n",
      "For sentiment analysis, labeling the data is essential. The paper \"Intelligent Trading Systems: A Sentiment-Aware Reinforcement Learning Approach\" by Francisco Caio Lima Paiva et al. (2022-05-10) mentions the importance of labeling data as positive, negative, or neutral for sentiment analysis.\n",
      "\n",
      "Finally, model selection and training are critical steps. The paper \"Leveraging Deep Learning and Online Source Sentiment for Financial Portfolio Management\" by Paraskevi Nousi et al. (2023-10-25) discusses the use of deep learning models, such as LSTM networks, for sentiment analysis and financial portfolio management.\n",
      "\n",
      "In conclusion, preprocessing and normalizing unstructured data for analysis, such as text processing and sentiment analysis, involves several steps, including data collection, preprocessing, normalization, labeling, and model selection and training. By following these steps and leveraging appropriate tools and technologies, we can effectively analyze unstructured data and make informed decisions.\n",
      "\n",
      "References:\n",
      "\n",
      "* Xu, J., & Chawla, N. (2017-06-26). Mining Features Associated with Effective Tweets.\n",
      "* Zhu, H. (2022-04-26). Financial data analysis application via multi-strategy text processing.\n",
      "* Konstantinidis, T., et al. (2024-03-20). FinLlama: Financial Sentiment Classification for Algorithmic Trading Applications.\n",
      "* Paiva, F. C. L., et al. (2022-05-10). Intelligent Trading Systems: A Sentiment-Aware Reinforcement Learning Approach.\n",
      "* Nousi, P., et al. (2023-10-25). Leveraging Deep Learning and Online Source Sentiment for Financial Portfolio Management.\n",
      "\n",
      "\n",
      "\n",
      "User: What specific insights or alpha-generating opportunities do you hope to uncover from unstructured data using Streaming Analytics and AI?\n",
      "\n",
      "LLM Response: 0h 0m 7.3552s \n",
      "\n",
      "Embedding the User Query: 0h 0m 0.0137s \n",
      "\n",
      "KDB.AI Similarity Search: 0h 0m 13.1060s \n",
      "\n",
      "LLM Response: 0h 0m 7.6029s \n",
      "\n",
      "Total RAG response time: 0h 0m 28.0794s \n",
      "\n",
      "---------------------------------------------- \n",
      "\n",
      "Assistant: As a quantitative trader, I hope to uncover insights and alpha-generating opportunities from unstructured data using Streaming Analytics and AI, particularly in the context of financial markets and trading.\n",
      "\n",
      "One specific insight I aim to uncover is the relationship between tweet features and tweeting effectiveness, as discussed in the paper \"Mining Features Associated with Effective Tweets\" by Jian Xu and Nitesh Chawla (2017-06-26). By analyzing the text of tweets, I can identify patterns and features that are associated with higher engagement and effectiveness, which can inform my trading decisions.\n",
      "\n",
      "Another opportunity I hope to explore is the use of news-based trading strategies, as proposed by Stefan Feuerriegel and Helmut Prendinger in their paper \"News-based trading strategies\" (2018-07-19). By analyzing textual news in real-time, I can identify novel information entering the market and make informed trading decisions.\n",
      "\n",
      "Furthermore, I am interested in leveraging sentiment-aware reinforcement learning approaches, as described in the paper \"Intelligent Trading Systems: A Sentiment-Aware Reinforcement Learning Approach\" by Francisco Caio Lima Paiva, Leonardo Kanashiro Felizardo, Reinaldo Augusto da Costa Bianchi, and Anna Helena Reali Costa (2022-05-10). By incorporating market sentiment momentum into my trading strategy, I can improve profit stability and adapt to changing market conditions.\n",
      "\n",
      "Overall, by applying Streaming Analytics and AI to unstructured data, I can uncover valuable insights and opportunities that can inform my trading decisions and drive alpha generation.\n",
      "\n",
      "References:\n",
      "\n",
      "* Xu, J., & Chawla, N. (2017-06-26). Mining Features Associated with Effective Tweets.\n",
      "* Feuerriegel, S., & Prendinger, H. (2018-07-19). News-based trading strategies.\n",
      "* Paiva, F. C. L., Felizardo, L. K., Bianchi, R. A. C., & Costa, A. H. R. (2022-05-10). Intelligent Trading Systems: A Sentiment-Aware Reinforcement Learning Approach.\n",
      "\n",
      "\n",
      "\n",
      "User: What Streaming Analytics technologies are you considering (e.g., Apache Kafka, Apache Storm, Amazon Kinesis)?\n",
      "\n",
      "LLM Response: 0h 0m 6.9648s \n",
      "\n",
      "Embedding the User Query: 0h 0m 0.0123s \n",
      "\n",
      "KDB.AI Similarity Search: 0h 0m 13.0012s \n",
      "\n",
      "LLM Response: 0h 0m 4.6025s \n",
      "\n",
      "Total RAG response time: 0h 0m 24.5818s \n",
      "\n",
      "---------------------------------------------- \n",
      "\n",
      "Assistant: Based on the JSON context, I am considering Apache Kafka and Apache Spark Structured Streaming for streaming analytics technologies.\n",
      "\n",
      "According to the JSON context, Apache Kafka is mentioned in the paper \"A Comparative Study of Data Storage and Processing Architectures for the Smart Grid\" by Mar{\\\\i}a Arenas-Mart{\\\\i}nez et al. (2020-06-05), which explores system architectures for storing and processing Smart Meter reading data.\n",
      "\n",
      "Apache Spark Structured Streaming is mentioned in the paper \"An Artificial Neural Network-based Stock Trading System Using Technical Analysis and Big Data Framework\" by O.B. Sezer et al. (2017-12-29), which presents a neural network-based stock price prediction and trading system using technical analysis indicators and Apache Spark big data framework.\n",
      "\n",
      "These two technologies are suitable for real-time data processing and analytics, which is essential for quantitative trading applications.\n",
      "\n",
      "References:\n",
      "\n",
      "* Mar{\\\\i}a Arenas-Mart{\\\\i}nez et al. (2020-06-05). A Comparative Study of Data Storage and Processing Architectures for the Smart Grid.\n",
      "* O.B. Sezer et al. (2017-12-29). An Artificial Neural Network-based Stock Trading System Using Technical Analysis and Big Data Framework.\n",
      "\n",
      "\n",
      "\n",
      "User: What AI techniques are you interested in applying (e.g., machine learning, deep learning, natural language processing)?\n",
      "\n",
      "LLM Response: 0h 0m 6.2757s \n",
      "\n",
      "Embedding the User Query: 0h 0m 0.0119s \n",
      "\n",
      "KDB.AI Similarity Search: 0h 0m 13.0550s \n",
      "\n",
      "LLM Response: 0h 0m 7.6956s \n",
      "\n",
      "Total RAG response time: 0h 0m 27.0391s \n",
      "\n",
      "---------------------------------------------- \n",
      "\n",
      "Assistant: As a quantitative trader, I'm interested in applying AI techniques to improve trading strategies and optimize portfolio management. Based on the provided JSON context, I'm particularly interested in the following techniques:\n",
      "\n",
      "1. **Deep Learning**: I'm interested in applying deep learning techniques to analyze complex financial data, such as stock prices and trading volumes. For example, the paper \"Leveraging Deep Learning and Online Source Sentiment for Financial Portfolio Management\" (2023-10-25, Paraskevi Nousi et al.) demonstrates the use of deep learning for financial portfolio management.\n",
      "2. **Reinforcement Learning**: I'm interested in applying reinforcement learning to optimize trading strategies and make decisions in complex financial environments. For instance, the paper \"Quantitative Trading using Deep Q Learning\" (2023-12-21, Soumyadip Sarkar) explores the use of reinforcement learning for quantitative trading.\n",
      "3. **Model-based Deep Reinforcement Learning**: I'm interested in applying model-based deep reinforcement learning to optimize portfolio management and make autonomous trading decisions. The paper \"Model-based Deep Reinforcement Learning for Dynamic Portfolio Optimization\" (2019-01-28, Pengqian Yu et al.) presents a model-based deep reinforcement learning approach for dynamic portfolio optimization.\n",
      "\n",
      "These AI techniques have the potential to improve trading strategies, optimize portfolio management, and provide a competitive edge in the financial markets.\n",
      "\n",
      "References:\n",
      "\n",
      "* Nousi, P., Avramelou, L., Rodinos, G., Tzelepi, M., Manousis, T., Tsampazis, K., ... & Tefas, A. (2023-10-25). Leveraging Deep Learning and Online Source Sentiment for Financial Portfolio Management.\n",
      "* Sarkar, S. (2023-12-21). Quantitative Trading using Deep Q Learning.\n",
      "* Yu, P., Lee, J. S., Kulyatin, I., Shi, Z., & Dasgupta, S. (2019-01-28). Model-based Deep Reinforcement Learning for Dynamic Portfolio Optimization.\n",
      "\n",
      "\n",
      "\n",
      "User: How do you plan to integrate Streaming Analytics and AI with your existing data infrastructure and investment decision-making processes?\n",
      "\n",
      "LLM Response: 0h 0m 9.9246s \n",
      "\n",
      "Embedding the User Query: 0h 0m 0.0137s \n",
      "\n",
      "KDB.AI Similarity Search: 0h 0m 13.0532s \n",
      "\n",
      "LLM Response: 0h 0m 14.4842s \n",
      "\n",
      "Total RAG response time: 0h 0m 37.4767s \n",
      "\n",
      "---------------------------------------------- \n",
      "\n",
      "Assistant: To integrate Streaming Analytics and AI with existing data infrastructure and investment decision-making processes, we can follow a structured approach that involves assessment, planning, data preparation, integration of streaming analytics and AI, and continuous monitoring and evaluation.\n",
      "\n",
      "According to the paper \"AlertMix: A Big Data platform for multi-source streaming data\" (Ayush Singhal, Rakesh Pant, Pradeep Sinha, 2018-06-27), a Big Data platform can be designed to process multi-source streaming data, which is essential for real-time decision-making in investment.\n",
      "\n",
      "For data preparation, we need to ensure that all relevant data sources are integrated, and data quality and governance policies are in place. As mentioned in the paper \"Data Extraction, Transformation, and Loading Process Automation for Algorithmic Trading Machine Learning Modelling and Performance Optimization\" (Nassi Ebadifard, Ajitesh Parihar, Youry Khmelevsky, Gaetan Hains, Albert Wong, Frank Zhang, 2023-12-21), data warehousing and data lakes can be used to efficiently prepare data for analysis.\n",
      "\n",
      "For streaming analytics integration, we can use tools like Apache Kafka or cloud-based services like AWS Kinesis. As mentioned in the paper \"Qlib: An AI-oriented Quantitative Investment Platform\" (Xiao Yang, Weiqing Liu, Dong Zhou, Jiang Bian and Tie-Yan Liu, 2020-09-24), Qlib is an AI-oriented quantitative investment platform that can be used for real-time data processing and analysis.\n",
      "\n",
      "For AI and machine learning integration, we can use tools like TensorFlow or PyTorch. As mentioned in the paper \"Compatible deep neural network framework with financial time series data, including data preprocessor, neural network model and trading strategy\" (Mohammadmahdi Ghahramani, Hamid Esmaeili Najafabadi, 2022-05-18), a deep neural network framework can be designed to predict price movements in financial markets.\n",
      "\n",
      "Finally, for integration with investment decision-making processes, we can automate decision-making processes using AI-driven insights. As mentioned in the paper \"Intelligent Systematic Investment Agent: an ensemble of deep learning and evolutionary strategies\" (Prasang Gupta, Shaz Hoda and Anand Rao, 2022-03-25), an intelligent systematic investment agent can be designed to make investment decisions using an ensemble of deep learning and evolutionary strategies.\n",
      "\n",
      "In conclusion, integrating Streaming Analytics and AI with existing data infrastructure and investment decision-making processes requires a structured approach that involves assessment, planning, data preparation, integration of streaming analytics and AI, and continuous monitoring and evaluation. By following this approach, we can design a system that can process multi-source streaming data, predict price movements, and make investment decisions in real-time.\n",
      "\n",
      "References:\n",
      "\n",
      "* Ayush Singhal, Rakesh Pant, Pradeep Sinha. (2018-06-27). AlertMix: A Big Data platform for multi-source streaming data.\n",
      "* Nassi Ebadifard, Ajitesh Parihar, Youry Khmelevsky, Gaetan Hains, Albert Wong, Frank Zhang. (2023-12-21). Data Extraction, Transformation, and Loading Process Automation for Algorithmic Trading Machine Learning Modelling and Performance Optimization.\n",
      "* Xiao Yang, Weiqing Liu, Dong Zhou, Jiang Bian and Tie-Yan Liu. (2020-09-24). Qlib: An AI-oriented Quantitative Investment Platform.\n",
      "* Mohammadmahdi Ghahramani, Hamid Esmaeili Najafabadi. (2022-05-18). Compatible deep neural network framework with financial time series data, including data preprocessor, neural network model and trading strategy.\n",
      "* Prasang Gupta, Shaz Hoda and Anand Rao. (2022-03-25). Intelligent Systematic Investment Agent: an ensemble of deep learning and evolutionary strategies.\n",
      "\n",
      "\n",
      "\n",
      "User: What is your expected timeline for implementing Streaming Analytics and AI in your Hedge Fund?\n",
      "\n",
      "LLM Response: 0h 0m 8.2658s \n",
      "\n",
      "Embedding the User Query: 0h 0m 0.0121s \n",
      "\n",
      "KDB.AI Similarity Search: 0h 0m 13.1020s \n",
      "\n",
      "LLM Response: 0h 0m 8.2883s \n",
      "\n",
      "Total RAG response time: 0h 0m 29.6690s \n",
      "\n",
      "---------------------------------------------- \n",
      "\n",
      "Assistant: Based on the provided JSON context, I would estimate the timeline for implementing Streaming Analytics and AI in a hedge fund to be around 6-12 months. This timeline is supported by the various research papers and projects mentioned in the JSON context, which highlight the complexity and scope of such implementations.\n",
      "\n",
      "For example, the paper \"Qlib: An AI-oriented Quantitative Investment Platform\" by Xiao Yang et al. (2020-09-24) discusses the development of a platform for quantitative investment, which involves integrating AI technologies with financial data and models. The paper mentions that the development of such a platform requires a significant amount of time and resources, which supports the estimated timeline of 6-12 months.\n",
      "\n",
      "Another example is the paper \"Deep Learning for Portfolio Optimization\" by Zihao Zhang et al. (2021-01-26), which presents a deep learning framework for portfolio optimization. The paper mentions that the development of such a framework requires a significant amount of data preprocessing, model training, and testing, which can take several months to complete.\n",
      "\n",
      "Additionally, the paper \"Model-based Deep Reinforcement Learning for Dynamic Portfolio Optimization\" by Pengqian Yu et al. (2019-01-28) discusses the development of a model-based deep reinforcement learning architecture for dynamic portfolio optimization. The paper mentions that the development of such an architecture requires a significant amount of time and resources, including data collection, model training, and testing.\n",
      "\n",
      "Overall, based on the examples and references provided in the JSON context, I estimate the timeline for implementing Streaming Analytics and AI in a hedge fund to be around 6-12 months.\n",
      "\n",
      "References:\n",
      "\n",
      "* Yang, X., Liu, W., Zhou, D., Bian, J., & Liu, T. Y. (2020). Qlib: An AI-oriented Quantitative Investment Platform. (2020-09-24)\n",
      "* Zhang, Z., Zohren, S., & Roberts, S. (2021). Deep Learning for Portfolio Optimization. (2021-01-26)\n",
      "* Yu, P., Lee, J. S., Kulyatin, I., Shi, Z., & Dasgupta, S. (2019). Model-based Deep Reinforcement Learning for Dynamic Portfolio Optimization. (2019-01-28)\n",
      "\n",
      "\n",
      "\n",
      "User: What resources (e.g., personnel, budget, infrastructure) do you have available for this project?\n",
      "\n",
      "LLM Response: 0h 0m 7.6581s \n",
      "\n",
      "Embedding the User Query: 0h 0m 0.0120s \n",
      "\n",
      "KDB.AI Similarity Search: 0h 0m 13.0832s \n",
      "\n",
      "LLM Response: 0h 0m 8.4325s \n",
      "\n",
      "Total RAG response time: 0h 0m 29.1867s \n",
      "\n",
      "---------------------------------------------- \n",
      "\n",
      "Assistant: Based on the provided JSON context, the resources available for the project can be inferred from the various papers and research studies mentioned. Here's a breakdown of the resources that can be identified:\n",
      "\n",
      "**Personnel:**\n",
      "\n",
      "* Researchers and authors from various institutions, such as Syeda ZarAfshan Gohera, Peter Bloodsworth, Raihan Ur Rasool, and Richard McClatchey, who have worked on projects related to cloud computing and resource management (Source: \"Cloud Provider Capacity Augmentation Through Automated Resource Bartering\", 2018-03-20).\n",
      "* Experts in the field of energy management, such as Katayoun Rahbar, Mohammad R. Vedady Moghadam, Sanjib Kumar Panda, and Thomas Reindl, who have researched energy storage systems and demand response (Source: \"Energy Management for Demand Responsive Users with Shared Energy Storage System\", 2016-08-16).\n",
      "\n",
      "**Budget:**\n",
      "\n",
      "* No specific budget information is mentioned in the provided JSON context. However, it can be inferred that the researchers and institutions involved in the studies have access to funding for their projects.\n",
      "\n",
      "**Infrastructure:**\n",
      "\n",
      "* Cloud computing infrastructure, such as datacenters and virtual machines, which are used in the studies on cloud computing and resource management (Source: \"Cloud Provider Capacity Augmentation Through Automated Resource Bartering\", 2018-03-20).\n",
      "* Energy storage systems and smart grids, which are used in the studies on energy management and demand response (Source: \"Energy Management for Demand Responsive Users with Shared Energy Storage System\", 2016-08-16).\n",
      "\n",
      "**Other Resources:**\n",
      "\n",
      "* Access to data and information, such as energy consumption patterns and market data, which are used in the studies on energy management and demand response (Source: \"Energy Management for Demand Responsive Users with Shared Energy Storage System\", 2016-08-16).\n",
      "* Partnerships with external organizations, such as the Linux operating system community, which are mentioned in the study on operational resilience (Source: \"Operational resilience: concepts, design and analysis\", 2019-12-24).\n",
      "\n",
      "In summary, the resources available for the project include personnel with expertise in cloud computing, energy management, and demand response, access to cloud computing infrastructure and energy storage systems, and partnerships with external organizations.\n",
      "\n",
      "\n",
      "\n",
      "User: How do you plan to measure the success of your Streaming Analytics and AI initiatives in generating alpha?\n",
      "\n",
      "LLM Response: 0h 0m 7.7910s \n",
      "\n",
      "Embedding the User Query: 0h 0m 0.0120s \n",
      "\n",
      "KDB.AI Similarity Search: 0h 0m 13.1186s \n",
      "\n",
      "LLM Response: 0h 0m 11.4582s \n",
      "\n",
      "Total RAG response time: 0h 0m 32.3807s \n",
      "\n",
      "---------------------------------------------- \n",
      "\n",
      "Assistant: To measure the success of Streaming Analytics and AI initiatives in generating alpha, we can employ a combination of metrics and methodologies. According to the JSON context, several papers provide insights into evaluating the performance of quantitative trading strategies.\n",
      "\n",
      "Firstly, we can use the Sharpe Ratio, which is mentioned in multiple papers as a key performance metric. For instance, \"A Deep Deterministic Policy Gradient-based Strategy for Stocks Portfolio Management\" by Huanming Zhang, Zhengyong Jiang, and Jionglong Su (2021-03-23) uses the Sharpe Ratio to evaluate the performance of their proposed strategy. They report a Sharpe Ratio of 0.5988, which is nearly 33% higher than that of the second-best performing strategy.\n",
      "\n",
      "Secondly, we can use the Information Ratio, which is mentioned in \"Balancing Profit, Risk, and Sustainability for Portfolio Management\" by Charl Maree and Christian W. Omlin (2022-07-06). They propose a novel utility function that incorporates the Sharpe Ratio and the environmental, social, and governance score (ESG) to evaluate the performance of their portfolio management strategy.\n",
      "\n",
      "Thirdly, we can use the Sortino Ratio, which is mentioned in \"High-performance stock index trading: making effective use of a deep LSTM neural network\" by Chariton Chalvatzis and Dimitrios Hristu-Varsakelis (2019-05-09). They use the Sortino Ratio to evaluate the risk-adjusted performance of their proposed trading strategy.\n",
      "\n",
      "Lastly, we can use real-time analytics to monitor performance and make swift adjustments. According to \"TradAO: A Visual Analytics System for Trading Algorithm Optimization\" by Ka Wing Tsang, Haotian Li, Fuk Ming Lam, Yifan Mu, Yong Wang, and Huamin Qu (2020-08-27), a visual analytics system can be used to comprehensively explore the performances of a trading algorithm with different parameter settings.\n",
      "\n",
      "In conclusion, to measure the success of Streaming Analytics and AI initiatives in generating alpha, we can use a combination of metrics such as the Sharpe Ratio, Information Ratio, Sortino Ratio, and real-time analytics. By employing these metrics and methodologies, we can effectively evaluate the performance of our quantitative trading strategies and make data-driven decisions to optimize our investments.\n",
      "\n",
      "References:\n",
      "\n",
      "* Zhang, H., Jiang, Z., & Su, J. (2021-03-23). A Deep Deterministic Policy Gradient-based Strategy for Stocks Portfolio Management.\n",
      "* Maree, C., & Omlin, C. W. (2022-07-06). Balancing Profit, Risk, and Sustainability for Portfolio Management.\n",
      "* Chalvatzis, C., & Hristu-Varsakelis, D. (2019-05-09). High-performance stock index trading: making effective use of a deep LSTM neural network.\n",
      "* Tsang, K. W., Li, H., Lam, F. M., Mu, Y., Wang, Y., & Qu, H. (2020-08-27). TradAO: A Visual Analytics System for Trading Algorithm Optimization.\n",
      "\n",
      "\n",
      "\n",
      "CPU times: user 2min 50s, sys: 28.9 s, total: 3min 18s\n",
      "Wall time: 7min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "K = 10\n",
    "\n",
    "for q in questions:\n",
    "    print('User: ' + q + '\\n')\n",
    "    answer, ctx = prompt(q, k=K, filter=[[\"like\",\"text\",\"*trading*\"]], augment=True)\n",
    "    HISTORY += 'User: %s\\n\\nAssistant: %s\\n\\n' % (q, answer.choices[0].message.content)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585dd420-951e-41aa-92eb-e3e39805f26b",
   "metadata": {},
   "source": [
    "### Executive summary\n",
    "\n",
    "Next based on the above answers we ask the LLM to create an Executive Summary of the result obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5c853943-7c12-4e36-88ef-3ffb8802e850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response: 0h 0m 7.6237s \n",
      "\n",
      "**Executive Summary**\n",
      "\n",
      "This conversation revolves around the integration of Streaming Analytics and AI in a hedge fund to generate alpha. The discussion covers various aspects, including the investment strategy, data sources, market tick data analysis, unstructured data analysis, AI techniques, and resource allocation.\n",
      "\n",
      "**Key Takeaways**\n",
      "\n",
      "1. **Investment Strategy**: The hedge fund aims to combine long-short equity, global macro, and event-driven investing strategies to generate absolute returns and minimize risk.\n",
      "2. **Data Sources**: The fund will utilize market tick data, news articles, social media posts, and company filings to inform investment decisions.\n",
      "3. **Market Tick Data Analysis**: The fund will apply time-series analysis, statistical models, and machine learning techniques to analyze market tick data and identify trading opportunities.\n",
      "4. **Unstructured Data Analysis**: The fund will use natural language processing (NLP) and sentiment analysis to extract insights from unstructured data sources, such as news articles and social media posts.\n",
      "5. **AI Techniques**: The fund will employ deep learning, reinforcement learning, and model-based deep reinforcement learning to optimize portfolio management and make autonomous trading decisions.\n",
      "6. **Resource Allocation**: The fund will allocate resources, including personnel, budget, and infrastructure, to support the integration of Streaming Analytics and AI.\n",
      "\n",
      "**Implementation Timeline**\n",
      "\n",
      "The implementation timeline for the project is estimated to be around 6-12 months, considering the complexity and scope of the project.\n",
      "\n",
      "**Success Metrics**\n",
      "\n",
      "The success of the project will be measured using metrics such as the Sharpe Ratio, Information Ratio, Sortino Ratio, and real-time analytics.\n",
      "\n",
      "**Conclusion**\n",
      "\n",
      "The integration of Streaming Analytics and AI in a hedge fund has the potential to generate alpha and improve investment decisions. By leveraging advanced technologies and techniques, the fund can stay ahead of the competition and achieve its investment objectives.\n",
      "CPU times: user 44.4 ms, sys: 5.34 ms, total: 49.7 ms\n",
      "Wall time: 7.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "answer = llm(HISTORY + 'Summarize the conversation in an Executive Summary.', model=LLM, temperature=TEMPERATURE)\n",
    "\n",
    "print(answer.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a8da44-f1ce-407b-95bd-2dd04fee1d19",
   "metadata": {},
   "source": [
    "### Thank You"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
